[
{
		"title": "DF Definitions",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-definitions/",
		"content": "more definition in [[Ethereum and DeFi Glossary.pdf]]\npegged cryptocurrency: cryptocurrency whose value is linked to a specific bank-issued currency, financial instrument or tradable commodity\n\ne.g. pay back to buy BTC and holds it for you\n\nKnow your customer ( #short KYC): means verifying who you are when joining a crypto exchange\nAnti-money laundering ( #short AML): helping to break criminal networks and minimise the impact of illicit transactions on affected economies.\nwashtrading: occurs when an investor buys and sells the same or a similar security investment at the same time (e.g. can be done by using flash loans)\n(Fractional) reserve: bank's reserve ratio = (money held by bank) / (money deposited by bank customers)\nExchange traded fund ( #short ETF): security/asset\n\ntracking an index/sector/commodity\ntradable on an exchange\ntypically, lower fees than buying individual stocks\nEFT types: bond, stock, industry, commodity, currency, inverse, etc\ne.g. SPDR S&amp;P 500 ETF tracks the S&amp;P 500 index\n\ndecentralised autonomous organisation ( #short DAO): e.g. <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/lectures/df-l6/#maker-dao-pasted-image-20240405232329-png\">MakerDAO</a>)\naddress verification service ( #short AVS): to prevent fraud by detecting suspicious transactions (e.g. for credit cards)\n\nLending\n\ncollateral: assets that serve as a security deposit\nOver-collateralisation: Borrower has to provide value(collateral assets) &gt; value(granted loan)\nUnder-collateralisation: value(collateral) &lt; value(debt)\nLiquidation: selling collateral from the borrower\n\nE.g., if value(collateral) &lt;= 150% x value(debt)\nAnyone can liquidate the debt position\n\nHealth factor\n\n0 &lt; liquidation threshold &lt; 1\nliquidation threshold provides a &quot;secure&quot; margin\nwhen health factor &lt; 1 =&gt; borrowing position becomes liquidatable\ne.g.\n\nLiquidation Spread #short LS: bonus, or discount, that a liquidator can collect when liquidating collateral\n\nùëâùëéùëôùë¢ùëí ùëúùëì ùê∂ùëúùëôùëôùëéùë°ùëíùëüùëéùëô ùë°ùëú ùê∂ùëôùëéùëñùëö = ùëâùëéùëôùë¢ùëí ùëúùëì ùê∑ùëíùëèùë° ùë°ùëú ùëÖùëíùëùùëéùë¶ √ó (1 + ùêøùëÜ)\n\nClose Factor #short CF: the maximum proportion of the debt that is allowed to be repaid in a single fixed spread liquidation\nùëâùëéùëôùë¢ùëí ùëúùëì ùê∑ùëíùëèùë° ùë°ùëú ùëÖùëíùëùùëéùë¶ &lt; ùê∂ùêπ √ó ùëáùëúùë°ùëéùëô ùëâùëéùëôùë¢ùëí ùëúùëì ùê∑ùëíùëèùë°ùë†",
		"tags": ["short", "short", "short", "short", "short", "short", "short", "note"]
},

{
		"title": "Decentralised Finance",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/decentralised-finance/",
		"content": "Promises\n\nInclusivity and Access:\n\nprovide financial services to individuals globally, including those who are unbanked or underbanked\npotentially bridge the gap between traditional financial systems and individuals who lack access to banking services\n\nPermissionless Innovation:\n\nplatforms are often open-source and permissionless, allowing developers to create and deploy financial applications without requiring approval from centralized authorities =&gt; rapid innovation and the creation of diverse financial products\n\nReduced Costs:\n\neliminating intermediaries and automating processes through smart contracts\npotential to reduce transaction costs associated with traditional financial services, such as remittances, loans, and trading\n\nDecentralized Identity and Privacy:\n\nleverage decentralized identity solutions, enhancing user privacy and reducing the reliance on centralized entities for identity verification\nUsers can control access to their personal information\n\nFinancial Empowerment:\n\nempower individuals by providing them with greater control over their financial assets\nUsers have custody of their private keys and can engage in financial activities without relying on traditional intermediaries\n\nTransparency: Blockchain technology, provides transparency by allowing users to trace transactions on a public ledger =&gt; enhance trust and accountability within the financial system\nInteroperability: platforms often operate on open and interoperable blockchain networks =&gt; allows different DeFi applications to seamlessly integrate with each other, creating a more interconnected and efficient financial ecosystem\nLiquidity Provision: platforms often use decentralized exchanges and liquidity pools, allowing users to provide liquidity and earn returns =&gt; creates new opportunities for individuals to participate in the financial ecosystem\n\nBank run\n\nin CeFi\n\ndangerous if fractional reserve\nmost clients don't receive assets\n\nin DeFi\n\nevent: USDT blacklists a pool, stablecoin de-pegs\ntraders will exit pools\nthose who exit first receive the best prices\ntry to build blacklist detection bots",
		"tags": [ "note"]
},

{
		"title": "Decentralised autonomous organisation",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/decentralised-autonomous-organisation/",
		"content": "#short DAO\n\nA decentralised organisation that has internal capital, automated processing at its core and human processing at its edges.\n- Vitalik Buterin (2014)\n\nproperties\n\nexpensive: a lot of (in)direct costs\nrich: a lot of money\ninfluential: impact on decentralised finance\nmostly centralised (voting power in most DAOs controlled by 10isch people)\nvulnerable\n\nToken acquisition attacks e.g. token purchase\nbribing and coalition attacks e.g. vote buying protocols\nhuman-computer interaction attacks e.g. user interface issues\n\nevolving e.g. through initiatives, voting\n\noptimising governance\n\nmore on optimism governance",
		"tags": ["short", "note"]
},

{
		"title": "Financial Markets",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/financial-markets/",
		"content": "Some things\nWhy?\nFinancial market serves several purposes, including:\n\nRaising capital: The financial market provides a platform for companies and governments to raise funds from investors in the form of equity or debt, which can be used to finance their operations or investment projects.\nPrice discovery: The financial market facilitates the determination of the prices of financial assets, based on the supply and demand of these assets. This price discovery process helps investors and market participants make informed investment decisions.\nLiquidity: The financial market provides liquidity to investors, allowing them to easily buy and sell financial assets such as stocks, bonds, and currencies. This enables investors to quickly and easily adjust their portfolios in response to changing market conditions.\nRisk management: The financial market allows investors to hedge against risks such as market volatility, inflation, and interest rate changes, by trading financial instruments such as options, futures, and swaps.\nEconomic growth: The financial market plays a crucial role in promoting economic growth by providing capital to companies and governments, which can be used to finance new projects and create jobs. This, in turn, can lead to increased economic activity and higher standards of living for individuals.\n\nMain stakeholders\n\nInvestors: Investors are individuals or entities who provide capital to companies and governments in exchange for financial assets, such as stocks, bonds, and other securities. Investors can be individual or institutional, such as pension funds, insurance companies, and mutual funds.\nIssuers: Issuers are companies or governments that offer financial assets to investors in order to raise capital. Issuers can issue debt in the form of bonds or equity in the form of stocks.\nIntermediaries: Intermediaries are entities that facilitate the trading of financial assets between investors and issuers. Examples of intermediaries include banks, broker-dealers, and stock exchanges.\nRegulators: Regulators are government agencies that oversee the financial market to ensure that it operates fairly and efficiently. Regulators set rules and guidelines for financial institutions and investors, and monitor the market to detect and prevent fraud and misconduct.\nMarket data providers: Market data providers are entities that collect and disseminate information about the financial market, including prices, trading volume, and other market data. This information is used by investors, issuers, and regulators to make informed decisions about the market.\n\nUnderlying assumptions from Economics\n\n(1) Rational Expectations: Based on perfect information\n\nEconomic actors will not make systematic mistakes in predicting the future (risks)\nEveryone uses the ¬´right¬ª model for forecasting\nThe future can be inferred from the past and present\n\n(2) Efficient Financial Market Theory: Asset prices represent the best possible estimates of the risks attached to them\n\nThe risk characteristics from financial markets can be inferred from mathematical analysis.\nMarket discipline can be used as an efficient tool in constraining harmful risk taking. Markets are self-correcting.\n\nWhy vulnerable?\nThe financial market is vulnerable to a variety of factors and risks, including:\n\nSystemic risks: These are risks that affect the entire financial system, rather than individual institutions or investors. Systemic risks can arise from a variety of sources, such as market volatility, geopolitical events, or regulatory changes.\nMarket risks: Market risks refer to the risk of losses due to changes in market conditions, such as changes in interest rates, exchange rates, or commodity prices.\nCredit risks: Credit risks refer to the risk of default by borrowers or issuers of debt securities. This can be due to factors such as financial distress, economic downturns, or changes in the creditworthiness of borrowers.\nOperational risks: Operational risks refer to the risk of losses due to internal failures of financial institutions, such as fraud, errors, or system failures.\nLiquidity risks: Liquidity risks refer to the risk that investors will not be able to buy or sell financial assets at fair market value due to a lack of market liquidity. This can lead to losses or a decrease in portfolio value.\nCybersecurity risks: With the increasing use of technology in the financial market, cybersecurity risks have become a significant concern. Cyber attacks on financial institutions can lead to the loss of sensitive data, financial theft, and disruption of market activity.\nOverall, the financial market is vulnerable to a wide range of risks, and investors and financial institutions must take steps to manage these risks in order to protect themselves and the broader financial system.",
		"tags": [ "note"]
},

{
		"title": "DF L1",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l1/",
		"content": "#disclaimer Not exam relevant!\n\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/financial-markets/\">Financial Markets</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/decentralised-finance/\">Decentralised Finance</a>",
		"tags": ["disclaimer", "note"]
},

{
		"title": "DF L10",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l10/",
		"content": "Decentralised Finance security\n\nmultiple layers can be affected\ne.g. sandwich attacks against taker\n\nAttacker\n\nfor attacker (to see transactions earlier) on a P2P network it's better to\n\nbe closer (physically) to victim\nwallet provider\n\naccelerated &amp; front-run attacks\nbut attackers are quite vulnerable (when transactions are not executed atomically) bc. if these transactions are not executed in this order, the attack fails\n\nattack\n\nattack lifecycle\n\nDefense\n\nincident response time (of whitehat hackers) are still very slow\nin some protocols, it's possible to trigger emergency pauses =&gt; would be good to do these automatic e.g. on the basis of analysis\n\nhere some bytecode similarity analysis on adversarial/victim contracts\n\nRandom\n\nprobably ETH community aggreed that white hat hacker gets around 10% of bounty\nDeFi-attacks make around 1000M+ USD/year\narbitrage, liquidation, sandwich attacks make around 500M USD/year\nresearch on (preventing) attacks is quite different of different layers\nmisbehaving of nodes loses them\n\nin proof of work: investments made in electricity (don't earn anything)\nin proof of stake: investments made in tokens\n\nif network merge (e.g. a computer runs two blockchains) it's possible to define that they always loose the &quot;bigger&quot;/more valuable token\n\nStaking\n\nliquid staking\n\nSend tokens to LST smart contract (Lido, RocketPool) and get LST in return (stETH, rETH)\nLST smart contract will stake on Ethereum and anoint operators from its ‚Äúblessed pool‚Äù\nBlessed operators run Ethereum nodes with the stake from step #2\nEthereum rewards are given back to LST smart contract (Ethereum doesn‚Äôt know about actual stakers)\nLST smart contract gives rewards back to stakers\n\nliquid restaking\n\nEnter Liquid Restaking Tokens (Ether.fi, Puffer, KelpDAO, RIO, Renzo, Inception, Swell)\nRestaking smart contract will stake on EigenLayer and anoint operators from its ‚Äúblessed pool‚Äù\nBlessed operators run AVS nodes with the stake from step #2\nAVS rewards are given back to restaking smart contract (AVS‚Äôs doesn‚Äôt know about actual restakers)\nLRT smart contract gives rewards back to restakers\n\nPlatypus\n\nprivacy-preserving central bank digital currency\nno blockchain\n\nRequirements\n\nprivacy: anonymous sender, recipient, private amount\nscalability: throughput, latency, light clients\nregulation: e.g. anonymous receiving limits ($10k per month)\n\nExamples\n\nZcash (2014): strong privacy (e.g. zero-knowledge proofs for show correctness of payments), but bad scalability due to client side computation and download\nE-cash (1983): good scalability, but limited privacy\n\nWhat does platypus do (better)?\n\nzero-knowledge proofs: proof a statement regarding a secret without revealing the secret\ncommitments: commit to a value and hen reveal value\n\nbinding: once committed, value cannot be changed\nhiding: commitment doesn't reveal the value\npublish both committed value and blinding factor -&gt; verification\n\ncentral unit (e.g. CB) can then verify and proof such transactions (with privacy in mind) where\n\nsender, recipient, value are hidden e.g. bc. content doesn't reveal it and serial number is pseudorandomly chosen\nbut transaction is unlinkable\n\nscalability bc.\n\nbank: little computations and can be parallelised (care when multiple users interact with one entry, but nothing new compared to other databases)\nuser: just need to state things over own balance\n\nguest lecturer argument on central bank digital currencies\nwhere bad = false/bad argument and fair = true/some truth in argument\n\nAgainst\n\nBig brother money‚Äù, tool of mass surveillance (bad)\nPerfect way to conduct crime, launder money (bad)\nHigh complexity, difficult to implement, communicate to the public (fair)\nCurrent payments and financial system work ‚Äî ‚Äúif not broken, don‚Äôt fix it‚Äù (fair)\n\nIn support\n\nSovereign solution for central banks (fair)\nImproved payment privacy for users, less fees for merchants (fair)\nFinancial innovation, e.g., ‚Äúprogrammable money‚Äù (?)\n\nQuiz\n\nWhat are all the actions that a P2P attacker can do against a P2P transaction?\n\nfront-run\nback-run\nfront- and back-run [correct]\nnothing\n\nWhat are all the actions that a P2P attacker can do against a PBS transaction?\n\nfront-run\nback-run [correct]\nfront- and back-run\nnothing\n\nHow much USD is lost to DeFi attacks every year (in M USD)?\n\n1'000",
		"tags": ["2", "2", "note"]
},

{
		"title": "DF L2",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l2/",
		"content": "&lt;![[Ethereum and DeFi Glossary.pdf]]\nQuiz\n\nA valid signed transaction of an account can be used to computer\n\nthe private key of the account\nthe address of the account [true]\n(both are true)\n(both are false)\n\nRunning a node in the Ethereum network\n\nwill earn you money\nwill cost you proof-of-work mining energy\nneeds an excellent internet connection (because you constantly need to be connected to 5'000 other nodes)\n(none of the above) [true]\n\nAn Ethereum smart contract can be programmed to\n\ninteract with a normal (not Ethereum) computer program through remote procedure calls.\nautomatically run every hour.\n(both are ture)\n(both are false) [true]\n\nLayer 2 protocols\n\nare not realy (only exist in reseach)\nare considered illegal (by the Ethereum foundation)\nhave been co-invented at ETH Zurich [true]\n(none of the above)\n\nIgnore fees, how many bananas do you get when you send 10 apples to a CPMM that holds a liquidity of 30 apples and 56 bananas?\n\nHow to calculate?\n\nconstant product = 30 [apples] * 56 [bananas] = 168\nand afterwards there has to be the same again thus 40 (30 + 10 new) [apples] * x [bananas] = 168\nsolve for x\n\nalternative: calculate ratio after adding 56 [bananas] / 40 [apples] = 7 / 5 =&gt; now multiply with number of apples and you get bananas 7 [bananas] / 5 [apples] * 10 [apples] = 14 [bananas]",
		"tags": [ "note"]
},

{
		"title": "DF L3",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l3/",
		"content": "DF and CF\nDF stack\n\nExample where smart contract on blockchain uses external data\n\nOracle\n\nReasons for need of oracles for blockchains\n\nblockchain is isolated DB\nblockchains lack\n\naccess to real-world data\nno API-query possible\ncannot browse the internet\n\nSolution: transactions\nDefinition\n\nGeneral: System that connects a blockchain with other systems.\nSpecific: Actors relaying data on-chain.\n\nDesign\nChallenges\n\nminers (provider of data) can lie/cheat\nnetwork providing data for miners can lie/cheat\nsource or oracle outage\n=&gt; have multiple miners and sources to prevent outage\n=&gt; have consensus so possibility of false data is minimised\n\nCensorship\n\ncan happen on multiple layers e.g. application, transaction, consensus\n\nMixers\n\nbreaks connection to person who put it in =&gt; but observations/analysis of transaction can help with finding out who gave/took coins\n(in best case) just fixed values e.g. 1 ETH possible, so less\n\nImplications\n\nConfirmation latency: slows down transaction confirmations\nDenial of Service: A lot of (fake) transactions can slow node down or even completely take it down\n\nproposer/builder separation\nattack nodes who apply censorship\n\nfor censorship, nodes have to put in work to extract information but then cannot do transactions and don't earn anything bc. transaction with a censored value is not allowed =&gt; DDoS attack possible to spam node with censored coins\n\nQuiz\n\nWhich of the following DeFi applications is most likely to require external oracle data?\n\nToken management contracts, such as ERC20\nBetting on real world events [correct]\nUniswap, Curve, and other Automated Market Maker Decentralised Exchanges\nOn-chain games that do not require randomness\n\nIs the context of blockchain oracles, which of the following statements is NOT TRUE?\n\nBecause block generation is centralised process, incorporating an oracle into the consensus protocol does not work because miners may lie or cheat.\nOracles have to receive very concise and short data representations to minimise blockchain fees.\nFor each oracle update, a minimum subset of all nodes in the oracle committee should send a report to the miner. [correct bc. one node is enough]\nMultiple sources /website (redundancy) are required due to website outages and data corruption possibilities\n\nWhat is the anonymity set of Tronado Cach pool with 1000 deposits\n\n100\n1000 [correct]\n999\n1001\n\nWhat are the computational implications if a miner censors a transaction, what is correct?\n\nNo implication bc. the miner doesn't need to verify the transaction.\nNo implications bc. the miner doesn't need to execute the transaction.\nThe minder must spend computational resources to execute the transaction but cannot claim transaction fees. [correct]\nThe miner must spend computational resources but is paid the regular transaction fees.\n\nAssumed an oracle committee has five nodes (A,B,C,D,E) and it's agreed to report the median value. Node E is a malicious node and E observes the following values from the other four nodes (A:1000, B: 1010, C: 1020, D: 1030). What are the upper and lower bounds of the aggregated value to which E can manipulate.\n\n1000 - 1005\n1010-1020 [correct bc. median is middle number and you can choose a number between (including borders) 1010 to 1020 and it will be chosen]\n1000 - 1030\nno upper/lower bounds",
		"tags": [ "note"]
},

{
		"title": "DF L4",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l4/",
		"content": "Decentralised Exchange\n(Example LOB Dex)\n\n(Dis) advantages:\n\n+ No KYC/AML\n+ no fees paid to the exchange\n+ no impermanent loss\n- fees for deposit, withdraw, trade creation/cancel\n- slow execution\n- not fully decentralised (mediating server)\n\ntrading volume: around 70 billion (recent months)\nWhy?\n\nSystems Architecture\nAutomated market maker\n#short AMM\n\nLiquidity pool idea: Let a smart contract do the market making. liquidity provider (LP) token:\nformula x‚àóy=k where x = asset X quantity, y = asset Y quantity, k = constant\nproperties\n\ninstant liquidity, irrespective of the trade size\npurchase of asset X increases price of X and decreases the price of Y\nratio of asset X and Y sets the price\nknown as constant product ( #short CP) AMM\n\n(dis)advantages\n\nno order book maintenance: but arbitrage required\n\nsimple implementation for CP AMM: low gas costs\n\ndanger of impermanent loss/coin de-peg: total loss of funds possible\n\nhigh slippage for low liquidity markets\n\nusers vulnerable to sandwich attacks\n\nExample:\n\nSlippage\n\n(un)expected increase or decrease in price based on trading volume and available liquidity\neffects\n\nworse/better execution price\n\npossible to introduce a slippage protection by configuring a threshold to prevent unacceptable slippage\n\nImpermanent loss\n#short IL\n\nimpermanent == not permanet: realised upon withdraw only\ncan result in total loss\n\ntrading fees may compensate\nliquidity mining may compensate\nsimilar to a de-peg of stablecoin\n\nExchange Transaction propagation\nStablecoin AMM pros/cons\n\nbetter prices for bigger volumes i.e. more liquidity\n\nexample shows significant differences among exchanges\n\npotentially higher gas costs\n\ndanger of a de-peg of a stablecoin\n\npegged/stablecoin prices move in expectation together\n\nexchange rate should ideally remain 1:1\ndefault CP AMM is not optimised for such cases\n\nWhat if a coin gets\n\nde-pug\n\nas bank run in CeFi: no money returned\n&quot;bank run&quot; in DeFi\n\npool may get blacklisted\nfirst come, first served\npool formula penalises destabilising a pool\nincreasingly worse price for late-comers\n\nblacklisted\n\ne.g. USDT and USDC have built-in code to\n\nblacklist addresses\ndestroy coins\ne.g. USDT blacklisted 500+ accounts, destroyed 50M+ USDT\n\nAMM arbitrage\n\nbeginning: multiple markets with\n\nthe same assets X and Y\ndifferent prices for X and Y\n\nprices are synchronised by &quot;arbitrageurs&quot;\n\nthey gain profit from price difference: also referred to as &quot;spread&quot;\nrequires to perform at least one transaction\n\ne.g.\n\narbitrageur can also do it with a flash loan\n\nhow to detect arbitrage/profitable opportunities?\n\nBellman Ford Algorithm\n\nNegative cycle detection\nWorks among multiple markets\nUsed in traditional finance and DeFi\n\nTheorem Solver (SMT tools aim to solve the satisfiability modulo theories ( #short SMT) problem)\n\nNeeds to encode the DeFi model\nApply heuristics for path pruning\n\nSandwich attacks\n\nP1 changes X to Y (value of X decreases and of Y increases)\nP2 changes also X to Y (value of X decreases even more and of Y increases more)\nP1 changes Y to X (gets more X out bc. Y is more valuable then before)\n\nprotection\n\noptimised trade execution\n\n+ simple\n- limited scope\n\ntrusted third party ordering\n\n+ efficient\n- no decentralisation\n\ncommittee ordering\n\n+ fairly efficient\n- reduced decentralisation\n\ncommit &amp; reveal\n\n+ secure\n- costly &amp; delay\n\nQuiz\n\nWhich of the following properties is NOT a desired property for AMM?\n\nno pool fees [correct bc. AMM pool should have some fees]\ninstant liquidity, irrespective of the trade size\npurchase of an asset decreases the asset supply in AMM, and increases its market price\nthe expected increase or decrease in price is based on the trading volume and available liquidity\n\nWhich of the following is a property for a typical on-chain order book?\n\nno fees for order placements\nfront running resistance\nimpermanent loss [there is no impermanent loss in an order book bc. market makers can fill the orders and thus liquidity cannot just be removed; this is rather in an AMM]\nnon-custodian ( #german Verwalter/Aufseher) settlement [correct bc. swapping of assets is non-custodial meaning you own your coins with your private key, there is no custodian doing the settlement]\n\nWhich of the following statements is incorrect\n\nUnexpected slippage can only cause a worse execution price [correct]\nunexpected slippage is caused by price change after a trade has been broadcast but before it has been confirmed\ntrades can configure a slippage protection threshold to limit the total slippage (expected + unexpected)\nThe concept of slippage is typically unavoidable in financial markets\n\nWhat is TURE about impermanent loss?\n\nimpermanent loss cannot result in the total loss of funds.\nTrading fees can never compensate the impermanent loss.\nImpermanent loss is impermanent bc. it's only realised upon a withdrawal from a liquidity pool. [correct]\nImpermanent loss is only a fictive accounting phenomenon and never materialises in a loss.\n\nBack-running describes the process where an adversary attempts to execute its own transaction immediately after the victim's transaction executes. For example, given two exchange markets A and B, both trading ETH/USD at a price of 1000. If a victim's trad (with a as price of 100GWei) is expected to push exchange A's price to 1100 ETH/USD, the adversay can attempt to back-run the victim to perform arbitrage between A and Ab. Which of the following method will have the highest back-running success rate?\n\nBroadcast the back-running transaction immediately after the victim's transaction with 99GWei\nBroadcast the back-running transaction immediately after the victim's transaction, with 100GWei\nSend a private back-running transaction to private relayer services, and bribe the miners to perform the back-run\n(i) broadcast the back-running transaction immediately after the victim with 100GWei, and also (ii) send the transaction to private relayer services and bribe the miners [correct]",
		"tags": ["short", "short", "short", "short", "german", "note"]
},

{
		"title": "DF L5 Lending & Stablecoins",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l5-lending-and-stablecoins/",
		"content": "added multiple things in <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/df-definitions/\">DF Definitions</a>\n\nHow economic machine works\n#video How The Economic Machine Works by Ray Dalio\n\nTransaction: money, credit &lt;=&gt; goods, services, financial assets\n\ntransactions drive economy\nneeds buyers and sellers\n\nspecial actors\n\ncentral bank:\n\ncan print money\nsets interest rates\n\nstate: greatest buyer\n\ncredit\n\nmost important part bc. biggest and most volatile part\nneeds lenders and borrowers\n\nprincipal: amount lend\ninterest: additional amount to pay back for principal\n\ndebt is created with it\ncredit creates spending =&gt; drive economy\nwithout credit: growth can just come from more productivity\nwith credit: growth can come from more productivity and more spending through borrowing/credit =&gt; creates cycle\nbad when it supports overconsumption and cannot be paid bad e.g. big TV\ngood when it efficiently allocates resources e.g. tractor to harvest more crops\n\neconomic growth due to cycle of: (more) income =&gt; borrowing =&gt; spending =&gt; productivity =&gt; ...\ninflation when prices rise\n\ntoo much inflation causes problems =&gt; central bank rises interest rates =&gt; fewer people can borrow money =&gt; borrow less =&gt; less spending =&gt; prices go down =&gt; deflation =&gt; recession =&gt; decrease interest rates =&gt; more borrowing =&gt; inflation =&gt; ...\n\ndeflation when prices decrease\ndeleveraging\n\nworse than recession bc. lowering interest rates doesn't work (not rly. possible to go under 0%)\nbeautiful deleveraging through properly applying counter actions =&gt; debt declines same as income\n\ndeflationary (cut spending and dept + redistribution) and inflationary (printing money) actions are in balance\nincome needs to grow faster than debt grows =&gt; people are creditworthy again\ngrowth is slow but debt shrinks\n\npossible counter actions\n\ncut spending: has opposite effects bc. less spending =&gt; less income (for another person) =&gt; lower wages and unemployment =&gt; can pay back less\n\nand lenders notice that borrowers probably cannot pay back everything =&gt; don't lend anything anymore\n\ncut dept\n\nlenders don't want that and &quot;alternatives&quot; are: less paid back, over longer time frame, reduced interest rate\nalso deflationary bc. everything loses value and so borrowers still, also with less debt, won't have enough to pay back (even less)\n\nredistribution: government has to pay for unemployment and want's to set economic stimulus =&gt; needs more money generally tries to raise taxes for wealthy (bc. wealth is concentrated), but wealthy don't like that too much...\n\nrevolution/class conflict evolves =&gt; maybe army and/or (strong) political change e.g. Hitler after 1930s in Germany\n\nprint money: last alternative bc. interest rates are already lowered as much as possible\n\ninflationary and stimulates economy\nto buy financial assets and government bonds\n\njust helps those who own financial assets bc. central bank can only buy financial assets\n\ncentral bank can cooperate with central government through buying government bonds to spend money on goods and services =&gt; money for people\n\nvery risky\n\ndoesn't have to result in inflation, when credit shrinks the same amount and thus spending is not higher\n\nreflation (after deleveraging)\n\nca. 7-10 year (lost decade) (maybe just after a &quot;beatauiful&quot; deleveraging)\n\nLecture (graphics)\n\neffects one-by-one\neffects combined\n\nLending\nOn-Chain lending &amp; borrowing\n\nFlash loan\n\nflash loan should be taken and repaid in one single transaction\n\nnot directly time bound rather has to happen within one block building process\nif it cannot be paid back =&gt; entire transaction is invalid\n\nlender is secure\n\nUse cases\n\nDeFi attacks\n\nprice oracle manipulation\npump and dump (buy another coin to make them look like as more valuable/have more transactions for a short amount of time)\n\n(risk-free) arbitrage\nwashtrading\nflash mining\ncollateral swapping\nliquidation\n\nwhen liquidator doesn't have cryptocurrency upfront to repay\nonly works when liquidation completes in one transaction\ne.g.\n\nLiquidation\nin traditional finance\n\npass resolution for voluntary liquidation can be done by board of executives\nadministration of liquidation are e.g. the not paid electricity bills\ntakes a long time maybe even years\n\nFixed spread liquidation\n\ncan be completed in 1 transaction\nrepays debts of borrowing position\nacquires collateral at a discounted price from the position in return\n\ntypically discounts are e.g. 5-15% (called fixed spread) in Aave ( #disclaimerN probably meant average with it)\n\nprice oracles for getting prices: on and off chain oracles possible/depending on currency\n\nQuiz\n\nHow long does a flash loan last?\n\nDuring one block\nDuring one transaction [correct]\nFrom transaction signature until the transaction is mined\nas long as you want\n\nWhat is TRUE?\n\nLiquidations are typically done optimally.\nThe close factor is the minimum proportion of debt that can be repaid in a liquidation. [false bc. it's the maximum proportion... and you can also liquidate less]\nA flash loan has no fees\nTransaction fees for a flash loan are on the order of 100 USD, even if the loan amounts can grow beyond 1B USD. [correct]\n\nWhat can flash loans be used for?\n\nWashtrading [correct]\npumping a coin [false bc. you can just do pumping and dumping together, not individually]\ndumping a coin\nforking a blockchain\n\nWhich of the following liquidation strategies best describes an optimal fixed spread liquidation strategy?\n\nthe liquidation first performs an oracle price update, and then atomically performs the liquidation\nthe liquidator liquidates the position up to the close factor (when the close factor drops below 1, the position becomes available for liquidation)\nperform two liquidations. The first one keeps the close factor below 1, such that the second liquidation can also successfully execute [correct ]\nperform three liquidations, two keeping the CF below 1, while the last one also successfully executes\n\nWe define a borrowing position as a bad debt if it is financially rational for neither the borrowers nor the lending platform to close the position. Which of the following is not a cause for bad debt?\n\nif the collateral value falls below the value of the debt.\nif the value of excess asset used for over-liquidation cannot cover the liquidation transaction fee.\nif the debt has not been repaid for a long time. [correct bc. time component has no impact on bad dept]\nif the value of the debt grows more than the value of the collateral.",
		"tags": ["video", "disclaimerN", "note"]
},

{
		"title": "DF L6",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l6/",
		"content": "Economic models\n\nrepresents (often simplifies) an economic process\ncontains <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/lectures/df-l6/#variables\">#Variables</a>\nlogical/quantitative relationships between variables\nexample: inflation\n\nmeasuring inflation requires a behaviour model bc. it depends on behaviour of individuals e.g. what/how much food they buy =&gt; how money is used\ndifferentiate relative vs. inflation price change\n\nVariables\n\nInterest rate(s) in CeFi and DeFi\ncryptocurrency price\ncollateral ratio\nDeFi protocol fees\nblockchain transaction fees\nnumber of users\nblockchain transaction throughput\n...\n\nExogenous vs. endogenous\n\nExogenous variable == outside force\n\ndetermined outside model, imposed on model\ne.g. in MakerDAO, asset price of collateral (e.g. ETH), is independent of the MakerDAO system\n\nEndogenous variable == inside the model\n\nStablecooins\nTypes\n\nTypes\n\nReserved-based e.g. USDC by a bank\ncollateral-based: e.g. MakerDAO\nalgorithmic e.g. AMPL\n\nMakerDAO\n\nto be profitable: assumption that ETH goes up and you can get even more with this DAI =&gt; with drawn DAI get even more ETH =&gt; later change back and have more in all\n\nAmpleforth\n#short AMPL\n\nsystemic implications #ToDo don't know yet\n\nUSDC and USDT\n\ndestroys coins\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/decentralised-finance/#bank-run\">Decentralised Finance#Bank run</a>\n\nQuiz\n\nWhich stable coin is the most stable? ( #remarkN atm)\n\nUSDC [correct]\nDAI\nAMPL\nETH\n\nWhich of the following statements is False?\n\nSeveral algorithmic stablecoins have depegged.\nDAI is a collateral based stablecoin, where e.g. ETH is used as collateral\nWBTC token prices should be pegged to BTC price\nETH is more stable than USDC [correct]\n\nWhat happens in AMPL system when 1 AMPL is worth less than 1 USD\n\nThe supply of AMPL is increase (expansion)\nThe supply of AMPL is decreased (contraction) [correct: if AMPL is more scarce, it should be worth more =&gt; less difference to USD]\nno action is taken (equilibrium)\nadditional collateral is required\n\nHow does the AMPL stablecoin reduce or increase the account balances of the token holders?\n\nThe ERC20 contract controls the balances and can modify them. [correct]\nThe ERC71 contract controls the balances and can modify them.\nevery user must individually approve each account balance change before rebalancing\nAMPL rebalances the token supply through arbitrage with USDC.\n\nIf the reserve ratio of a bank is 0.2 and the total money deposited by bank customers is $500,000, how much money is held by the bank?\n\n$100,000 [correct bc. 0.2 = 100'000/500'000 or 0.2 * 500'000 = 100'000]\n$250,000\n$400,000\n$1,000,000",
		"tags": ["Variables", "short", "ToDo", "remarkN", "note"]
},

{
		"title": "DF L7",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l7/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/smart-contract-programming/\">Smart Contract Programming</a>\nQuiz\nno quiz",
		"tags": [ "note"]
},

{
		"title": "DF L9 Central Bank Digital Currencies",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/lectures/df-l9-central-bank-digital-currencies/",
		"content": "To look at blockchains\n\n#remarkN probably not done in this lecture but don't remember when we've done it <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/decentralised-autonomous-organisation/\">Decentralised autonomous organisation</a>\n\nCentral Bank Digital Currencies\n#short CBDC\n\nTrends\n\ndigitalisation reduces cash demand\nmore DeFi (applications)\n\npossible actions by governments/central banks\n\nregulation of privately issued digital currencies\nintroduction of a central bank digital currency\n\nforms of CBDC\n\nMoney\n\n#Def money from an economist's perspective: any (financial) asset that functions as unit of account, medium of exchange and store of value.\npublic has access to two monies: cash and bank deposits\n\ncash: issued by central bank ( #short CB), physical, legal tender, more private, created by CB\nbank deposits: commercial banks, generally bear default risk of the issuing bank, digital, claim (against bank), generally subject to interest payments, created by commercial banks (mainly when granting loans)\n\nreserves\n\nCB provides banks with electronic central bank money so-called reserves\nused to settle interbank deposit flows which arise when depositors transfer their funds from one bank to another\nwholesale CBDC would essentially be a technologically advanced version of reserves\n\nretail CBDC\n#short rCBDC\nis an electronic form of the national currency available to the public\n\navailable to everyone\nnew: &quot;digital cash&quot;\n\nphysical cash can still exist\n\nmotivation: different ones e.g. financial inclusion, payments efficiency, payments safety/robustness, financial stability\npotential implications where CB has to find out proper balance\n\neconomic efficiency: more efficient, robust payment system, higher financial inclusion, tighter competition by banks for deposits\nfinancial stability: faster, more frequent bank runs, less risk-taking by banks, CBDC flows as financial stability indicator\nmonetary policy: direct interest rate pass-through to the real economy, bank disintermediation and/or increase in banks' funding costs\nhigher demand for domestic currency\n\ndesign questions\n\nAccess: Who can hold rCBDC?\nAvailability: How much can individual hold?\nRemuneration (store of value): Interest on it and if so how?\npayment functionalities (medium of exchange): What transactions are executable?\nPrivacy: What information can CB see?\nInfrastructure: How is access provided by CB?\n\nmonetary system with retail CBDC\n\ndifferent types of CBDC (with multiple tiers)\n\nwholesale CBDC\n\nonly for financial institutions\nsimilar to current system as technologically advances reserves\npotentially enhances (cross-border) payments-efficiency\n\ntogether with tokenised deposits\npossible created of a &quot;unified ledger&quot;\n\neliminates transaction risks (immediate final settlement)\nfaster and cheaper (cross-border) transactions\nintroduces programmable money (&quot;smart contracts&quot;)\nless disruptive to today's system than a (full-scale) retail CBDC\n\ntokenised deposits\nis a form of traditional bank deposits with rules (e.g. what asses can(not) do) and information (e.g. where it comes from, who owns it...)\nDistributed ledger technology\n#short DLT\nQuiz\n\nWhat is the purpose of the SELFDESTRUCT opcode in the EVM?\n\nto create a new smart contract\nto call a function in another smart contract\nto remove a smart contract and send its remaining balance to a designated address [correct]\nto pause the execution of a smart contract\n\nHow do you hide smart contract calls in a transaction?\n\ncall functions with private modifiers only\ncall into the targeted smart contract from another smart contract (internal transaction)\nuse a public layer 2 system\nnot possible to hide [correct]\n\nWhich of the following is NOT a valid type in the EVM?\n\nuint256\nbytes32\nstring\nfloat64 [correct]\n\nWhat happens when a smart contract runs out of gas during execution in the EVM?\n\ntransaction is reverted and the gas is refunded to the send\ntransaction is reverted but gas is consumed [correct]\ntransaction continues executing with the remaining gas\ntransaction is put on hold until more gas is provided\n\nWhat is the maximum stack size of the EVM?\n\n1024 #remark like a normal stack of any programming language\n\nWhat is the target gas limit (unit of gas) for a block in the Ethereum EVM?\n\n15'000'000\n\nThe voting power in most DAOs is controlled by how many addresses\n\n10isch [correct]\n100isch\n1000isch\neven more\n\nAccepted proposals in a DAO are always\n\nexecuted immediately\nexecuted fully on-chain\nvoted for by a majority of existing governance tokens\nnone of the above [correct]",
		"tags": ["remarkN", "short", "Def", "short", "short", "short", "remark", "note"]
},

{
		"title": "Smart Contract Programming",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/smart-contract-programming/",
		"content": "Ethereum\n\ncontent: address, balance, code, memory on the VM\ntransactions\n\ndirect transfer of Ether: sender, receiver, amount/Ether, maybe some input (text saved to the blockchain), signed with private key of sender, gas price\n\nto contracts: sender, receiver = contract address, amount/Ether, signed with private key of sender, gas price\n\ncontract creation: sender, receiver = 0x0..0, amound/Ether, input = code of the contract being created (bytecode), signed with the private key of the sender, gas price =&gt; creates new address for contract and stores code, memory, money at that address\ncontract function call: sender, receiver = contract address, possible some amount/Ether, input = functionName(input1, input2, ...), signed with private key of sender, gas price\n\nSolidity\n\nobject(contract)-oriented language\nconstructor function\n\nVariables\n\npublic, private",
		"tags": [ "note"]
},

{
		"title": "Unit type",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/atoms/unit-type/",
		"content": "#source #wikipedia Unit type\n\nIn the area of mathematical logic and computer science known as type theory, a unit type is a type that allows only one value (and thus can hold no information)\n\nProgramming languages\nHaskell\n\nThe () type can be thought of as a zero-element tuple. It's a type that can only have one value, and thus it's used where you need to have a type, but you don't actually need to convey any information. Here's a couple of uses for this.\n- #stackoverflow Neil Brown on StackOverflow\n\n#stackoverflow Longer explanation, also on types and expression language, besides ()",
		"tags": ["source", "wikipedia", "stackoverflow", "stackoverflow", "note"]
},

{
		"title": "FMFP Interpreters",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/fmfp-interpreters/",
		"content": "conceptually simple: read =&gt; evaluate =&gt; print\nconcretisation less trivial:\n\nMini-Haskell interpreter\nParsing\n\nparser constructs an abstract syntax tree ( #short AST)\n\nin Haskell: element of data type\nfurther processing depend on application but in general: conversion happens between data types e.g.\n\nCompiler: AST ‚Üí CODE\nCalculator: AST ‚Üí Int\nMini-Haskell: AST ‚Üí AST\n\nin ghci there are additional phases such as dependency analysis, type checking, ...\n\nCombinatory parsing\n\nIdea: modular construction and composition of parser functions\n\nuses lazy &amp; higher-order programming\nuses monads to package &quot;higher-order plumbing&quot;\n\nParser type\n\nparser is a function taking a string as input\nresult is an element of type a (typically a data type like Expr)\nparser may process only part of input, leaving a remainder\n\nsupport composition: pparses first part and q continues\n\nallow multiple results from parsing via list of successes\n\ndata Parser a = Prs (String -&gt; [(a,String)])\n\nparse::Parser a -&gt; String -&gt; String -&gt; [(a,String)]\nparse (Prs p) inp = p inp\n\n-- interested in result of first complete parse\ncompleteParse :: Parser a -&gt; String -&gt; a\ncompleteParse p inp\n\t| results == [] = error &quot;Parse unsuccessful&quot;\n\t| otherwise = head results\n\twhere results = [res | (res,&quot;&quot;) &lt;- parse p inp]\n\ncomplete parse if pair with remainder &quot;&quot;\n\nprimitive parsers\n\nserving as basic building blocks\n\n-- Fails trivially ([] signifies ‚Äòunsuccessful parse‚Äô):\nfailure :: Parser a\nfailure = Prs (\\inp -&gt; [])\n\n-- Succeeds trivially without progress:\nreturn :: a -&gt; Parser a\nreturn x = Prs (\\inp -&gt; [(x,inp)])\n\n--Succeeds trivially with progress:\nitem :: Parser Char\nitem = Prs (\\inp -&gt; case inp of\n\t\t\t\t\t\t&quot;&quot; -&gt; []\n\t\t\t\t\t\t(x:xs) -&gt; [(x,xs)])\n\n-- Parse a single character with property p\nsat :: (Char -&gt; Bool) -&gt; Parser Char\nsat p = Prs (\\inp -&gt; case inp of\n\t\t\t\t\t\t&quot;&quot; -&gt; []\n\t\t\t\t\t\t(x:xs) -&gt; if p x then [(x,xs)] else [])\n\n--Chars and Strings (including simpler definition of sat)\nsat :: (Char -&gt; Bool) -&gt; Parser Char\nsat p = item &gt;&gt;= \\x -&gt; if p x then return x else failure\n\nchar :: Char -&gt; Parser Char\nchar x = sat (==x)\n\nstring :: String -&gt; Parser String\nstring &quot;&quot; = return &quot;&quot;\nstring (x:xs) = char x &gt;&gt; string xs &gt;&gt; return (x:xs)\n\n-- Repetition\nmany :: Parser a -&gt; Parser [a] -- 0 or more repetitions of p\nmany p = many1 p ||| return []\n\nmany1 :: Parser a -&gt; Parser [a] -- 1 or more repetitions of p\nmany1 p = p &gt;&gt;= \\t -&gt; many p &gt;&gt;= \\ts -&gt; return (t:ts)\n\n-- more readable use of &gt;&gt;-\nmany1 p = do t &lt;- p\n\t\t\t ts &lt;- many p\n\t\t\t return (t:ts)\n\nnumPos :: Parser Int\nnumPos = do ts &lt;- many1 (sat isDigit)\nreturn (read ts) --- read maps numeric string to number\n\nnumNeg :: Parser Int\nnumNeg = do char ‚Äô-‚Äô\n\t\t\tt &lt;- numPos\n\t\t\treturn (-t)\n\t\t\t\nnum :: Parser Int\nnum = numPos ||| numNeg -- or: numPos +++ numNeg\n\nGluing parsers together\n-- Mutual selection: Apply both first and second parser\n(|||) :: Parser a -&gt; Parser a -&gt; Parser a\np ||| q = Prs (\\s -&gt; parse p s ++ parse q s)\n\n-- Alternative selection: If first parser fails, apply second parser\n(+++) :: Parser a -&gt; Parser a -&gt; Parser a\np +++ q = Prs (\\s -&gt; case parse p s of\n[] -&gt; parse q s\n\n-- Sequencing: first parser p then parser q to results\n(&gt;&gt;) :: Parser a -&gt; Parser b -&gt; Parser b\np &gt;&gt; q = Prs (\\s -&gt; [ (u,s‚Äô‚Äô) | (t,s‚Äô) &lt;- parse p s,\n\t\t\t\t\t\t\t\t(u,s‚Äô‚Äô) &lt;- parse q s‚Äô ])\n-- but above results of first parser (t above) is lost bc. we just use the remainder further\n-- Solution: use as second argument a ‚Äúparser generator‚Äù that takes as input the result of the first parser\n(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b\np &gt;&gt;= g = Prs (\\s -&gt; [ (u,s‚Äô‚Äô) | (t,s‚Äô ) &lt;- parse p s,\n\t\t\t\t\t\t\t\t (u,s‚Äô‚Äô) &lt;- parse (g t) s‚Äô ])\n\nambiguous grammars\n\nProblem: How should 2-3+4 be parsed?\nSolution\n\ndisambiguate grammar using associativity and precedence\ngive user ability to override defaults using parentheses\ncareful: left-recursive grammars lead to non-terminating recursion\n\nConcrete\n\nparse repeated operation/atom pairs after initial atom\nobtain left associativity using fold-left over list of these pairs\nuse concrete grammar to build abstract syntax tree of type data Expr = Lit Int | Add Expr Expr | Sub Expr Expr\n\nŒª-calculus\n\nprograms are terms\nformalising core\n\nenough to construct all others\n\nParsing Œª-terms\n\ndata type for Œª-calculus terms\n\ndata Term = Id String | Ap Term Term | Lam String Term\n\t\t\tderiving Show\n\natom = ident ||| lamb ||| paren\n\nident = do id &lt;- identifier\n\t\t\treturn (Id id)\n\nterm= do t &lt;- atom -- t\n\t\tts &lt;- many atom -- [t1 t2 ... tn]\n\t\treturn (foldl Ap t ts)-- Ap(Ap(Ap(t t1) t2) ... tn)\n\nlamb= do token &quot;%&quot;\n\t\t ids &lt;- many1 identifier -- [x1, x2, ..., xn]\n\t\t token &quot;.&quot;\n\t\t t &lt;- term -- t\n\t\t return (foldr Lam t ids) -- Lam x1 (Lam x2 (...(Lam xn t)))\n\nparen = do token &quot;(&quot;\n\t\t t &lt;- term\n\t\t token &quot;)&quot;\n\t\t return t\n\nstr2term s = completeParse term s\n\napplication t1t2 produces left recursion (prefix-syntax simpler)\nsyntax without left-recursion\n\nWe use % and . instead of \\ and -&gt;, respectively\nExplicit parentheses\nEvery parsing starts with an identifier, or symbols ‚Äò%‚Äô or ‚Äò(‚Äô\n\nExamples\n\nSubstitution in Haskell\n\nmust respect free and bound variables\n\ne.g.\n\nHaskell implementation below (Alternative: use Haskell library Data.Set to implement free)\n\nfree :: Term -&gt; [String]\nfree (Id v) = sing v -- free (x) = {x}\nfree (Ap s t) = union (free s) (free t) -- free (M N ) = free(M ) ‚à™ free(N )\nfree (Lam v t) = diff (free t) (sing v) -- free (Œªx. M ) = free(M ) \\ { x }\n\nempty = []\nsing a = [a]\n\nmember [] _ = False\nmember (x:xs) a\n\t| x &lt; a = member xs a\n\t| x == a = True\n\t| otherwise = False\n\nunion [] ys = ys\nunion xs [] = xs\nunion (x:xs) (y:ys)\n\t| x &lt; y = x : union xs (y:ys)\n\t| x == y = x : union xs ys\n\t| otherwise = y : union (x:xs) ys\n\ndiff [] _ = []\ndiff xs [] = xs\ndiff (x:xs) (y:ys)\n\t| x &lt; y = x : diff xs (y:ys)\n\t| x == y = diff xs ys\n\t| otherwise = diff (x:xs) ys\n\n-- subst t v s = t[v -&gt; s]\nsubst :: Term -&gt; String -&gt; Term -&gt; Term\nsubst (Id x) v s = if x == v then s else Id x\nsubst (Ap t1 t2) v s = Ap (subst t1 v s) (subst t2 v s)\nsubst (Lam x t) v s\n\t| x == v = Lam x t\n\t| not (member (free s) x) = Lam x (subst t v s)\n\t| otherwise = Lam z (subst (subst t x (Id z)) v s)\n\twhere z = fresh (union (free t) (free s))\n\t\tfresh m = (foldr max &quot;&quot; m) ++ &quot;‚Äô&quot; -- returns id not in m\n\nSubstitution\nŒ≤-reduction\n\nŒ≤-reduction is rule for simplifying redexes: (Œªx.M)N‚Ü™M[x‚Ü¶N]\n\nredex is a term like (Œªx.M)N\ncontractrum is the result i.e. M[x‚Ü¶N]\n\ne.g. (Œªx.f(xx))N‚Ü™f(NN)\n\nEvaluation strategies\n\nt1t2 represents the first application of a function to an argument\n\nfirst evaluate t1:t1‚Ü™r1\nIf r1‚â†Œªx.r then throw an exception (or return application)\n\nstrategy 1: Eager\n\nevaluate t2 prior to Œ≤-reduction: t2‚Ü™r2 meaning (Œªx.r)r2‚Ü™r[x‚Ü¶r2]\nevaluation carried out under an abstraction (Œªx.t)\n\nstrategy 2: Lazy\n\napply Œ≤-reduction to r1t2 i.e. substitute t2 without evaluation meaning (Œªx.r)t2‚Ü™r[x‚Ü¶t2]\nno evaluation under an abstraction\nresult of Œ≤-reduction is then further evaluated\n\nbeta (Lam x t) t‚Äô = subst t x t‚Äô\neager :: Term -&gt; Term\neager (Id x) = (Id x)\neager (Ap t t‚Äô) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; eager (beta r r‚Äô)\n\t\t\t\t\t_ -&gt; Ap r r‚Äô\n\twhere r = eager t\n\t\t r‚Äô = eager t‚Äô\neager (Lam x t) = Lam x (eager t)\n\nlazy :: Term -&gt; Term\nlazy (Id x) = (Id x)\nlazy (Ap t t‚Äô) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; lazy (beta r t‚Äô)\n\t\t\t\t\t_ -&gt; Ap r t‚Äô\n\twhere r = lazy t\nlazy t = t -- no evaluation under a lambda abstraction\n\neager evaluation in lazy language\n\nHaskell is lazy and doesn't fully evaluate omega, since not needed to produce result\nsolution: use strict function application f $! x is like f x but forces evaluation of its argument x (up to first constructor)\n\neager :: Term -&gt; Term\neager (Id x) = (Id x)\neager (Ap t t‚Äô) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; eager ((beta $! r) $! r‚Äô)\n\t\t\t\t\t_ -&gt; (Ap $! r) $! r‚Äô\n\twhere r = eager t\n\t\t r‚Äô = eager t‚Äô\neager (Lam x t) = Lam x $! (eager t)\n\nMore on Haskell and interpreters",
		"tags": ["short", "note"]
},

{
		"title": "Haskell",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/haskell/",
		"content": "operators\n\nhave diff. binding strength e.g.\n\n^ binds stronger than + see ? 2 + 3^2 =&gt; 11\nnot stronger than &amp;&amp; and ||\n\norder and equality return True or False of type Bool\n\nsame as in other programming languages but\n\n/= unequal\n\nTypes\nInt\n\nInt type with at least the range {‚àí229,‚Ä¶,229‚àí1}\n\nsupport for unbounded and arithmetic: Integer\n\nbool\n\nvalue: True, False\n\nChar\n\ne.g. 'a','0','\\t'\n? ord 'a' =&gt; 97 or ? chr 97 =&gt; 'a'\n\nString\n\ne.g. &quot;hello&quot;, &quot;123&quot;\n? &quot;Hello &quot; ++ &quot;there&quot; =&gt; &quot;Hello there&quot;\n\nDouble\n0.3456, -2.85e03\nTuple\n\nused to model composite objects (&quot;records&quot;)\nexample of a type constructor\n\nif T1,‚Ä¶,Tn are types, then (T1,‚Ä¶,Tn) is a (tuple) type\n\nList\n\nIf T is a type then [T] is a type\nempty list: []::[T]\nnon-empty list (x:xs)::[T] if x::T and xs::T\nabbreviations\n\n? [3..6] =&gt; [3,4,5,6]::Int\n`? [6..3] =&gt; []::Int\n[n, p..m] means count from n to m in steps of p‚àín\n\n? [7,6..3] =&gt; [7, 6, 5, 4, 3] :: [Int]\n? [0.0, 0.3 .. 1.0] =&gt; [0.0,0.3,0.6,0.8999999999999999] :: [Double]\n\nx:[y] appends an element x to a list [y]\n[x]++[y] concatenates two lists\n\nDifference lists\n\nfunction [a] -&gt; [a] that prepends a list to its argument\ne.g.\nimplementation\n\nOwn types\n\ntypes always start with a capital letter\ntype Person = String\ntype Database = [(Person,Book)]\n\nClass\n\ndefines a set of types\nelements of the class are called instances\n\nExamples\nallEqual :: Eq t =&gt; t -&gt; t -&gt; t -&gt; Bool -- where Eq is a class\n\nFunctions\n\nif argument doesn't matter use _ e.g. f a _ = a for f :: Int -&gt; Int -&gt; Int\nevaluation by\ngeneric type definition possible e.g. ownLength :: [a] -&gt; Int where a is the generic type\ndo when function has side-effects e.g. in IO\nown e.g.\n\nsumList::[Int] -&gt; Int\nsumList [] = 0 -- also handle the empty list case\nsumList (x:xs) = x + sumList xs\n\nstandard ones:\n\nlength\nappend\n[2] ++ [3,4,5] =&gt; [2,3,4,5]\n? 2 : [3,4,5] =&gt; [2,3,4,5] but ? [2] : [3,4,5] =&gt; Error\n\nHow to use\nInfix binary\nInfix binary function is also called an &quot;operator&quot; ? 7 'mod' 2\nprefix\nOperators can also be written in prefix notation: ? (+) 3 4\nExamples\n\n(e.g. for Int) +, * , ^, -, div, mod, abs\n\nevaluate by ? mod 7 2 =&gt; 1\n\nbranches\n\nif test then a else b\n\na and b have to be of same type\n\nmulti case\n\ndefined using other operators: f x y = (x || y) &amp;&amp; not (x &amp;&amp; y)\ndefined using guards\n\nf x y\n| x = not y\n| otherwise = y\n\ndefined using multiple cases (new)\n\npriority from above down\nexception, if one case is not covered but it's used\n\nf True True = False\nf True False = True\nf False True = True\nf False False = False\n\ncases can contain variables\n\nf True y = not y\nf False y = y\n\nf 0 = 1\nf 1 = 2\nf x = x*x\n\nAdvice on recursion\n\nDefining recursive functions is like riding a bicycle: it looks easy when someone else is doing it; it may seem impossible when you first try to\ndo it yourself, but becomes simple and natural with practice.‚Äù\n- G. Hutton, Programming in Haskell\n\nHigher-order functions\n\njust higher order, if function takes function(s) as input\n\nŒª-expression\n\nfor writing functions in-line\n\ngood for when functions are just used once and rather short\n\nInput-Output\n-- putStrin :: String -&gt; IO()\n\n-- getLine :: IO String\n\n-- read String :: t, where t is a type and it tries to convet String to this type\n\n-- show a =&gt; String of a\n\nfunc1 = do\nputStrLn &quot;Test&quot;\nn &lt;- getLine\nputStrLn (&quot;Text: &quot; ++ show (func2 (read n :: Int)))\n\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/monads/#input-ouput\">Monads#Input/Ouput</a>\n\nOther\nShell\n\nghci: open\n:load name-of-file.hs load modules from file\nreload loads last file again (e.g. after changing functions)\n\nLazy Evaluation\n\nHaskell uses Lazy evaluation\npossible problem of lazy evaluation is duplicated computation: avoided by simultaneously reducing both occurrences\nSummary: function arguments are evaluated only when needed and at most once\n\nCool applications\n\ncompute with infinite data in finite time\nimplementation of sieve of Eratosthenes\n\n2D layout\n\nspaces are important don't use TABs (in modern IDEs it should be okay, but this maybe a reason for an erroneous program)\nindentation determines separation of definitions\n\nall function definitions must start at same indentation level\nif a definition requires n &gt; 1 lines, indent lines 2 to n further\nrecommended layout\n\nPatterns\n\npurposes\n\nchecks if argument has proper form\nbinds values to variables\n\nRules\n\npatterns are inductively defined\npattern required to be linear i.e. each variable can occur at most once\nExamples: [(x,foo),_] , ((x,y),_) , 1:(2:(x,y))\nCounterexamples: (x ++ y, z) , [x,y,z,x]\n\nList comprehension\nNotation for sequential processing of list elements\n\nanalogous to set comprehension in set theory {2‚ãÖx|x‚ààX}\nHaskell notation [2*x| x &lt;- xs]\ncan be augmented with guards: [2*x | x &lt;- xs, pred1(x), ...]\n\nExamples\n\n(x:xs) matches with [2,3,4] as x=2 and xs=[3,4]\n? let ([x,y,z],t) = ([1,2,3],(20,30)) in x + y =&gt; 3 :: Int\n? [2*x | x &lt;- [1,2,3,4,5]] =&gt; [2,4,6, 8, 10]\n? [n ‚Äòmod‚Äò 2 == 0 | n &lt;- [2,4,7]] =&gt; [True,True,False]\n? [2*x | x &lt;- [0,1,2,3,4,5,6], x ‚Äòmod‚Äò 2 == 0, x &gt; 3] =&gt; [8,12]\neasy quick sort^^\n\nq [] = []\nq (p:xs) = q [x | x&lt;-xs, x &lt;= p] ++ [p] ++ q [x | x&lt;-xs, x &gt; p]",
		"tags": [ "note"]
},

{
		"title": "FMFP L1",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l1/",
		"content": "Functional programming\n\nbasic concepts\n\nfunction (which are values itself) #aka first order citizens\nvalues\n\nexample programming languages: Haskell\n\nAdvantages\n\neasier to reason about bc. no state (changes) anymore\n\nno side effects\n\nreferential transparency every expression with same values evaluate to same expressions\nrecursion instead of iteration\nFlexible type system: many programming errors not possible (compile time error) e.g. 3 + TRUE, polymorphism supports reusability",
		"tags": ["aka", "note"]
},

{
		"title": "FMFP L10",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l10/",
		"content": "algebraic data types\n\ndata types defines a set of terms for each type instance e.g. Tree Int correspons to {Leaf, Node 0 Leaf Leaf, ...}\nalgebraic here means the smallest set S where Leaf‚ààS and x‚ààa‚àßt1‚ààS‚àßt2‚ààS‚üπ(Node¬†xt1t2)‚ààS\nIntuition: set S is built in steps\n\nLeaf‚ààS and\n(Nodext1t2)‚ààS, where t1 and t2 in S in earlier steps\n\nStructural induction",
		"tags": [ "note"]
},

{
		"title": "FMFP L11",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l11/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/haskell/#lazy-evaluation\">Haskell#Lazy Evaluation</a> #remarkN maybe (probably, but don't know which one exactly^^) this was also done in a previous lecture\n\nArithmetic syntax tree #short AST\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/fmfp-interpreters/\">FMFP Interpreters</a>",
		"tags": ["remarkN", "short", "note"]
},

{
		"title": "FMFP L12",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l12/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/fmfp-interpreters/\">FMFP Interpreters</a>",
		"tags": [ "note"]
},

{
		"title": "FMFP L13",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l13/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/monads/\">Monads</a>",
		"tags": [ "note"]
},

{
		"title": "FMFP L14",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l14/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/monads/\">Monads</a>",
		"tags": [ "note"]
},

{
		"title": "FMFP L2",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l2/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/minigames/natural-deduction/\">Natural deduction</a>",
		"tags": [ "note"]
},

{
		"title": "FMFP L3",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l3/",
		"content": "Correctness\nWhat does it mean?\n\nTermination: important for many, but not all, programs\nFunctional behavior: function should return &quot;correct&quot; value. can be defined by another (mathematically defined) function or an input-output relation.\nCorrectness is rarely obvious =&gt; must be proven\n\nTermination\n\nif f is defined in terms of functions g1,‚Ä¶,gk(gi‚â†f) and each gi terminates, then so does f.\n\nproblem is recursion, when some gi=f\n\nsufficient condition for termination: arguments are smaller along a well-founded order on functions domain\n\nan order &gt; on a set S is well-founded ‚ü∫ there is no infinite decreasing chain x1&gt;x2,‚Ä¶ for xi‚ààS\npossible to construct new well-founded relations from existing ones\n\nCorrectness\n\nexamples for proving correctness on slides: mainly using induction\n\nDifferent reasoning strategies\n\nequational reasoning bc. functions are equations\nreasoning by cases\n\nwith inference rules\n\nExcluded Middle (TND): For all propositions P holds P‚à®¬¨P\nCase split (‚à®-E): Given Q‚à®R to prove any P we must prove\n\nP follows from Q and\nP follows from R\n\nproof by induction",
		"tags": [ "note"]
},

{
		"title": "FMFP L4",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l4/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/haskell/\">Haskell</a>",
		"tags": [ "note"]
},

{
		"title": "FMFP L7",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l7/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/mini-haskell/\">Mini-Haskell</a>",
		"tags": [ "note"]
},

{
		"title": "FMFP L8",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l8/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/haskell/\">Haskell</a>",
		"tags": [ "note"]
},

{
		"title": "FMFP L9",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l9/",
		"content": "Type classes\n\nmorphism\n\nmonomorphism: just one primitive type\npolymorphism: can take multiple primitive types\n\ntype classes restrict polymorphism\n\n-- from prelude.hs\nclass Eq a where\n\t(==) :: a -&gt; a -&gt; Bool\n\t(/=) :: a -&gt; a -&gt; Bool\n\n\tx /= y = not (x==y) -- thus in the end, a has just to be == comparable\n\t-- example with Eq\n\tallEqual :: Eq t =&gt; t -&gt; t -&gt; t -&gt; Bool\n\n-- instance example\ninstance Eq Bool where\n\tTrue == True = True\n\tFalse == False = True\n\t_ == _ = False\n\nelements of class are called instances\n\ninstance builds instances by &quot;interpreting signature functions&quot;\ninstances of primitive types like Int use built-in (primitive) qualities\n\nclass Visible t where\n\tstringOf :: t -&gt; String\n\tsize :: t -&gt; Int\n\t\ninstance Visible Char where\n\tstringOf ch = [ch]\n\tsize _ = 1\n\ninstance Visible Bool where\n\tstringOf True = &quot;Wahr&quot;\n\tstringOf False = &quot;Falsch&quot;\n\tsize b = 1\n\n? (stringOf ‚Äôe‚Äô) ++ &quot;ine &quot; ++ (stringOf True) ++ &quot;e Aussage&quot;\n&quot;eine Wahre Aussage&quot; :: [Char]\n\ninstance Visible t =&gt; Visible [t] where\n\tstringOf xs = concat (map stringOf xs)\n\tsize xs = foldr (+) 0 (map size xs)\n\t-- stringOf xs ... is not a recursive definition bc. on of them is over `[t]` and the other just over `t`\n\n? size [True,False]\n2 :: Int\n\n? stringOf [True,False]\n&quot;WahrFalsch&quot; :: [Char]\n\nif t is visible then a list of type [t] is also visible =&gt; class membership can depend on membership for other types\n\nDerived classes\nclass Eq a =&gt; Ord a where\n\t(&lt;), (&gt;), (&lt;=), (&gt;=) :: a -&gt; a -&gt; Bool\n\tmax, min :: a -&gt; a -&gt; a\n\t-- implement all operators except (&lt;=)\n\tx &lt; y = x &lt;= y &amp;&amp; x /= y\n\tx &gt;= y = y &lt;= x\n\tx &gt; y = y &lt;= x &amp;&amp; x /= y\n\nmax x y | x &lt;= y = y\n\t\t| otherwise = x\nmin x y | x &lt;= y = x\n\t\t| otherwise = y\n\nif a belong to Ord, then a must also belong to Eq\nfunctions for Eq are inherited and some new ones must be given\n\nSome type classes\n\nShow and Read\nFoldable\n\nEnumeration types (disjoint unions)\ndata Season = Spring | Summer | Fall | Winter\ndata Month = January | February | March | April | May | June | July | August |September | October | November | December\n\n-- functions can be written using pattern matching\nwhichSeason :: Month -&gt; Season\nwhichSeason January = Winter\n...\n\nSyntax\n\nstart with keyword data\nnames different (uniquely named) constructors\nfirst letter of each constructor must be upper-case\n\nDefines a set: Season = {Spring, Summer, Fall, Winter}\n\nProduct types\ndata People = Person Name Age\ntype Name = String\ntype Age = Int\n\n-- Constructors are functions\n? :type Person\nPerson :: Name -&gt; Age -&gt; Peopled\n\nshowPerson :: People -&gt; String\nshowPerson (Person n a) = n ++ &quot; who is &quot; ++ show a ++ &quot; years old&quot;\n\n? showPerson (Person &quot;Uncle George&quot; 85)\n&quot;Uncle George who is 85 years old&quot; :: [Char]\n\nan element of type People consists of a name n and an age a e.g. Person &quot;Uncle George&quot; 85\n\nProduct types versus tuples\nEnumeration and product types\n\ngeneral case\n\nIntegration with classes\n\nor in some cases, class instances can be automatically derived\n\nRecursive types\n\nrecursive functions over data types",
		"tags": [ "note"]
},

{
		"title": "Mini-Haskell",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/mini-haskell/",
		"content": "substantial simplification of Haskell, but the central core\n\nSyntax\nTyping\nProof system\nRules for core Œª-calculus\nFurther rules\nType inference\ntype inference failures\n\nSelf application",
		"tags": [ "note"]
},

{
		"title": "Evaluation",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/minigames/evaluation/",
		"content": "General\n\ninfix functions e.g. 1+2 = (+) 1 2 where + is infix\n\nand for (+a) b = b + a = (+)b a, a is the second argument and the following a\n\nfunctions are always applied to exactly one argument at a time\n\nLazy evaluation\nTo evaluate (t1t2)\n\nevaluate t1\nif the result of t1 is (Œªx.u), return u[x/t2]\nThen evaluate the result of the substitution\nTo evaluate (Œªx.t) return it unchanged\n\nEager evaluation\nTo evaluate (t1t2)\n\nevaluate t1, then evaluate t2 to t2‚Ä≤\nif the result of t1 is (Œªx.u), return u[x/t2‚Ä≤]\nThen evaluate the result of the substitution\nTo evaluate (Œªx.t), evaluate t to t‚Ä≤ and return (Œªx.t‚Ä≤)\n\nCommon mistakes/special care\n\nincorrect parenthesis at the beginning: e.g. Œªx.x(Œªy.xy)‚â¢(Œªx.x)(Œªy.xy)\nsubstitution removes the lambda (Œªx.x)(Œªy.xy)‚áùÃ∏Œª(Œªy.xy).Œªy.xy but just Œªy.xy\nin lazy evaluation there is no evaluation under lambdas\nin eager evaluation, need to evaluate argument before substitution",
		"tags": [ "note"]
},

{
		"title": "Natural deduction",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/minigames/natural-deduction/",
		"content": "Natural Deduction\n\n[!info]- Abstract example of a formal proof\n\nrules are used to construct derivations under assumptions\nproof is a derivation whose root has no assumptions (at the root on the left there is nothing)\nderivations are trees (normally done from bottom to top)\n\nPropositional logic\nSyntax\n\nIs a bird a formula? No, bc. it's about the smallest set (inductive definition), so there is not other stuff there!\n\nSemantics\n\nvaluation œÉ:V‚Üí{True,False} is a function mapping variables to truth values (truth assignment).\n\nvaluations are simple kinds of models (interpretations)\nLet Valuations be the set of valuations.\n\nSatisfiability:\nNote that œÉ‚ä≠‚ä• for every œÉ‚àà Valuations: meaning falsity is never satisfied (as it should bebn )\na formula A‚ààLP is satisfiable if œÉ‚ä®A, for some valuation œÉ\n\nvalid (a tautology) if it holds for all valuations œÉ\n\nsemantic entailment: A1,..An‚ä®A if for all œÉ, if œÉ‚ä®A1,‚Ä¶,œÉ‚ä®An then œÉ‚ä®A\n\nrequirements for deductive system\n\nsyntactic entailment ‚ä¢ (derivation rules) semantic entailment ‚ä® (truth tables) should agree\nFor Œì‚â°A1,‚Ä¶,An some collection of formulae for which holds:\n\nsoundness: If Œì‚ä¢A can be derived, then Œì‚ä®A\ncompleteness: If Œì‚ä®A, then Œì‚ä¢A can be derived\n\n(desirable, but not necessary) Decidability: What is complexity of determining:\n\nIf a proposition A is satisfied by a valuation œÉ? =&gt; linear\nIf A is satisfiable? =&gt; exponential to check all possible evaluation and it's NP-complete\nIf A is a tautology? =&gt; it's in Co-NP\n\nNatural deduction for propositional formulae\nderivation rules\nFirst-Order Logic\nSyntax\n\nsignature consists of a set of function symbols F and a set of predicate symbols P (and their arities e.g. fk to indicate function/predicate symbol f has arity k‚ààN)\n\nconstants are 0‚àíary function symbols\n\nLet V be a set of variables\nTerm, the terms of first-order logic, is the smallest set where\n\nx‚ààTerm if x‚ààV and\nfn(t1,‚Ä¶,tn)‚ààTerm if fn‚ààF and ti‚ààTerm for all 1‚â§i‚â§n\n\nForm, the formulae of first-order logic, is the smallest set where\n\n‚ä•‚ààForm\npn(t1,‚Ä¶,tn)‚ààForm if pn‚ààP and tj‚ààTerm, for all 1‚â§j‚â§n\nA‚àòB‚ààForm if A‚ààForm, B‚ààForm, and ‚àò‚àà{‚àß,‚à®,‚Üí}\nQx.A‚ààForm if A‚ààForm,x‚ààV and Q‚àà{‚àÄ,‚àÉ}\n\nbound/free\n\nnames of bound variables are irrelevant, they just encode the binding structure\nŒ±-conversion: renaming bound variables is okay\n\nOperators: omitting paranthesis:\n\nBinary operators:\n\n‚àß stronger than ‚à® stronger than ‚Üí\nassociates: ‚Üí to the right while ‚àß and ‚à® do to the left\n\nnegation stronger than binary\nquantifiers extend to the right as far as possible i.e. end of line or )\n\nSemantics\n\nstructure is a pair S=‚ü®US,IS‚ü© where US is a nonempty set, the universe, and IS is a mapping where\n\nIS(pn) is an n-ary relation on US, for pn‚ààP\nIS(fn) is an n-ary (total) function on US, for fn‚ààF\nAs shorthand, write pS for IS(p) and fS for IS(f)\n\nan interpretation is a pair I=‚ü®S,v‚ü©, where S=‚ü®US,IS‚ü© is a structure and v:V‚ÜíUS a valuation.\nThe value of a term t under the interpretation I=‚ü®S,v‚ü© is written as I(t) and defined by\n\nI(x)=v(x), for x‚ààV and\nI(f(t1,‚Ä¶,tn))=fS(I(t1),‚Ä¶,I(tn))\n\nSatisfiability\nSubstitution\n\nreplace in a formula all occurences of a free variable x with some term t e.g.\nsubstitution must avoid capture of variables: if they would have the same name, then we have to first rename bound variables with Œ±-conversion\n\nSymbols\nEquality\n\nlogical symbol wi",
		"tags": [ "note"]
},

{
		"title": "Type inference",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/minigames/type-inference/",
		"content": "Formal type inference\nStep-by-step\n\nStart with judgement ‚ä¢t::œÑ0 where œÑ0 is a fresh type variable\nBuild derivation tree bottom-up by applying rules\nintroduce fresh type variables œÑi and collect constraints if needed\nSolve constraints using unification to get possible types\n\nExample for resolving constraints\nExample unification\n\nInformal type inference\n\n(see step-by-step from formal type inference but) skip tree building and directly start unifying\n\nCommon mistakes/car\n\ncare for infix functions e.g. 1+2=(+)12\nfunctions are always applied to exactly one argument at a time\nbe careful when parsing x(&lt;) not same as (x&lt;)\nNumeric constants are polymorphic in Haskell e.g.\n\nExamples\n\nExercises with explanations by TA Ramon Wick",
		"tags": [ "note"]
},

{
		"title": "Monads",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/monads/",
		"content": "#Idea separate values from computation producing the values\n\nf :: a -&gt; b ordinary function, returns value of type b\nf :: a -&gt; M b monadic function, returns computation M b\n\nM is a type constructor satisfying certain properties (monad laws)\nby varying M, we can model different notions of computation\n\nMonad is a type constructor in the monad type class\nimagine a monad as a container which &quot;wraps&quot; a value\nexplains side-effects in a functional context and helps designing controlled side-effects\n\nfine-grained control of side effects possible\ncan model computational effects that are not present in imperative languages\n\nProperties\n\nevery monad supports 2 basic operations\n\nembedding a value into a computation\ncomposing computations\n\nclass Monad m where\n\t-- return and bind are mathematical core\n\treturn :: a -&gt; m a\n\t(&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b -- bind\n\t\n\t-- shortcut for convenience, when second computatin\n\t-- doesn't depend on result of first\n\t(&gt;&gt;) :: m a -&gt; m b -&gt; m b\n\tm1 &gt;&gt; m2 = m1 &gt;&gt;= (\\_ -&gt; m2)\n\t\n\t-- not partof mathematical concept of a monad\n\t-- called on pattern matching error in do-notation\n\tfail :: String -&gt; m a\n\n-- instances\ninstance Monad Maybe where\n\treturn x = Just x\n\tNothing &gt;&gt;= _ = Nothing\n\t(Just x) &gt;&gt;= f = f x\n\nMonad laws\nMonad operations must satisfy\n\n(1) return x &gt;&gt;= f = f x left unit\n(2) m &gt;&gt;= return = m right unit\n(3) (m &gt;&gt;= f) &gt;&gt;= g = m &gt;&gt;= (\\x -&gt; (f x &gt;&gt;= g)) associativity\n\nExamples\nmonad\ndata Maybe a = Nothing | Just a\n\n-- e.g. for making a safe division\nsafeDiv::Int -&gt; Int -&gt; Maybe Int\nsafeDiv n d\n\t| d /= 0 = Just (n `div`d)\n\t| otherwise = Nothing\n\nComputation with monads\n-- idea: computation takes a state of type s and transforms it into\n-- a result of type a and a successor state of type s\ndata State s a = State (s -&gt; (a,s)) -- here s is just a type, not an argument so in reality s on left hand side doesn't have to be s on right hand side, but they just have to be the same type!\n\n-- state access: read current value of state without changing it\nget :: State s s\nget = State (\\s -&gt; (s,s))\n\n-- state update: write a new state value ignoring the current state\nput :: s -&gt; State s ()\nput t = State (\\s -&gt; ((), t))\n\n-- auxiliary function that opens monad and\n-- runs computation from initial state s0\nrunState :: (State s a) -&gt; (s -&gt; (a, s))\nrunState (State m) s0 = m s0 -- bc. `(State m)` returns a function (see data State s a) which takes s0 as an argument; I just don't know yet, why this is not reflected in the data type of runState (why there is not another input)\n\n-- return embeds a value into a stateful computation\nreturn :: a -&gt; State s a\nreturn x = State (\\s -&gt; (x,s))\n\n-- Bind composes two stateful computations with value binding\n(&gt;&gt;=) :: State s a -&gt; (a -&gt; State s b) -&gt; State s b\nm &gt;&gt;= k = State (\\s -&gt; let (x, t) = runState m s\n\t\t\t\t\t\tin runState (k x) t)\n\napplication of state monad in counter\n\nstate monad encapsulate program composition\nrun program: invoke runState tick s0 where s0 is some initial state\n\napplication of state monad in tree renaming\n\nas reference: without state monad =&gt; ugly plumbing needed to thread state through two recursive calls\nstate monad takes care of all the plumbing\nor with more abstraction\n\nInput/Ouput\n\nproblematic bc. we don't know what we get as an input from user =&gt; reasoning would no longer be sound\n\nbc. result depends on order in which the argument are evaluated\nI/O-functions have side effects =&gt; state of world ( #disclaimerN nice name^^) changes\ne.g. IO Int not same as Int e.g. you cannot subtract bc. IO Int is monadic\n\ninputInt :: IO Int\ninputString :: IO String\noutputInt :: Int -&gt; IO ()\n\n() is the unit type in Haskell <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/fmfp/atoms/unit-type/#haskell\">Unit type#Haskell</a>\n\nBasic Actions\n\nSequencing\n\nExamples\n-- printing string on screen\nputString :: String -&gt; IO ()\nputString &quot;&quot; = return ()\nputString (x:xs) = do putChar x; putString xs\n\n-- reading string from keyboard\ngetString :: IO String\ngetString = do c &lt;- getChar\n\t\t\t\tif c == ‚Äô\\n‚Äô\n\t\t\t\tthen return &quot;&quot;\n\t\t\t\telse do cs &lt;- getString\n\t\t\t\t\treturn (c:cs)\n\t\t\t\t\t\n-- hello world (what else)\nmain :: IO ()\nmain = do putString &quot;Hi, I am HAL. Who are you?\\n&quot;\nname &lt;- getString\nputString (&quot;Hello &quot; ++ name ++ &quot;!\\n&quot;)\n\nFunctors\n\nwhen you instantiate Monad, you must instantiate Functor and Applicative too\n\nclass Functor f where\nfmap :: (a -&gt; b) -&gt; f a -&gt; f b\n\nLaws\n\nFunctor instances must satisfy two functor laws\n\nIdentity: fmap id v = v\nComposition: fmap f (fmap g v) = fmap (f . g) v\n\noperations\n\nin applicative functor mimicks function application #ToDo find symbols for LaTex\n\nclass Functor f =&gt; Applicative f where\npure :: a -&gt; f a\n(&lt;*&gt;) :: f (a -&gt; b) -&gt; f a -&gt; f b -- associates to the left\n\ninstance Applicative Maybe where\npure x = Just x\nJust f &lt;*&gt; Just x = Just (f x)\n_ &lt;*&gt; _ = Nothing\n\nApplicative functor laws\n\nIdentity pure id &lt;*&gt; v = v\nHomomorphism pure f &lt;*&gt; pure x = pure (f x)\nComposition pure (.) &lt;*&gt; u &lt;*&gt; v &lt;*&gt; w = u &lt;*&gt; (v &lt;*&gt; w)\nInterchange v &lt;*&gt; pure x = pure (\\f -&gt; f x) &lt;*&gt; v\nfmap fmap f v = pure f &lt;*&gt; v\n\ncanonical implementation for monads\n\npure x = return x\nu &lt;*&gt; v = u &gt;&gt;= \\f -&gt; v &gt;&gt;= \\x -&gt; return (f x)\n\napplicative functor laws can be derived from monad laws\n\nExamples\n\nmap function transforms all elements in a structure: type class Functor can capture this functionality\n\ninstance Functor Tree where\nfmap _ Leaf = Leaf\nfmap f (Node x l r) = Node (f x) (fmap f l) (fmap f r)\n\n-- in console\n&gt; fmap (*2) [0,1,2] = [0,2,4]\n&gt; fmap (*2) (Node 5 Leaf Leaf) = Node 10 Leaf Leaf\n\napplicative functor examples\n\nResources\n\nrecommended monad tutorials",
		"tags": ["Idea", "disclaimerN", "ToDo", "note"]
},

{
		"title": "Appendix",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/appendix/",
		"content": "Kombinatorik\n\nPermutationen: n!=n‚àó(n‚àí1)‚àó‚ãØ‚àó2‚àó1\n\nFrage: Auf wie viele Arten kann man n Objekte anordnen?\nHerleitung: erste Objekt aus n Objekten w√§hlen, zweite aus n‚àí1 usw.\n\nKombinationen (nk)=n!k!(n‚àík)!\n\nFrage: Auf wie viele Arten kann man k‚â§n aus den n Objekten ohne Zur√ºcklegen ausw√§hlen.\nHerleitung:\n\nerste Objekt aus n, zweite aus n‚àí1 w√§hlen usw. d.h. n‚àó(n‚àí1)‚àó‚ãØ‚àó(n‚àík+1)=n!(n‚àík)! Sequenzen der L√§nge k\naber wir interessieren uns nicht f√ºr die Reihenfolge und teilen dadurch durch die m√∂glichen Permuationen d.h. durch k! (siehe Permutationen)\n\nVariationen: nm\n\nFrage: Wie viele Sequenzen der L√§nge m kann man mit den n Elementen bilden?\nHerleitung: F√ºr jeden der m Pl√§tze sind jeweils n Elemente zur Auswahl.\n\nExample\n\nStandardnormalverteilung\n#short #wikipedia Standardnormalverteilungstabelle\n\nnegative Werte: œï(‚àíx)=1‚àíœï(x)\n\nStandardnormalverteilungstabelle",
		"tags": ["short", "wikipedia", "note"]
},

{
		"title": "Diskrete Wahrscheinlichkeit",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/diskrete-wahrscheinlichkeit/",
		"content": "Oft ist im Zusammenhang mit Andwendungen aus der Informatik Œ©={œâ1,‚Ä¶,œâN} endlich oder Œ©={œâ1,œâ2,‚Ä¶}abz√§hlbar. Dann...\n\nwird F=P(Œ©), d.h. jede Teilmenge von Œ© ist ein (beobachtbares Ereignis), gew√§hlt.\nist P definiert durch die Wahrscheinlichkeiten pn:=P[œân], n=1,‚Ä¶,N bzw. n‚ààN, aller Elementarereignisse. Denn f√ºr jede beliebe Menge A‚äÜŒ© gilt A‚ààF undP[A]=P[‚ãÉœân‚ààA{œân}]=‚àëœân‚ààAP[{œân}]=‚àë{n|œân‚ààA}pn\n\n[!info] #Def 1.14 Laplace Modell\nSei Œ©={œâ1,‚Ä¶,œân} mit |Œ©|=N ein endlicher Grundraum. (Œ©,F,P) heisst Laplace Modell auf Œ©, wenn\n\nF=P(Œ©)\nP ist die diskrete Gleichverteilung auf Œ©, d.h. alle Elementarereignisse sind gleich wahrscheinlich,p1=‚ãØ=pN=1N. Insbesondere gilt f√ºr belibiege A‚äÜŒ©, P[A]=|A||Œ©|",
		"tags": ["Def", "note"]
},

{
		"title": "WS L1",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l1/",
		"content": "Definitions\n\n[!info] #Def 1.2 Grundraum ( #aka Ereignisraum) ( #english sample space)\nŒ©‚â†‚àÖ ist die Menge alle m√∂glichen Ergebnisse des betrachteten Zufallsexperiments.\n\nDie Elemente w‚ààŒ© heissen Elementarereigniss #aka Ausg√§nge des Experiments #english outcomes\nWir sagen, dass ein Ereignis A eintritt, falls das realisierte Elementarereignis œâ in A liegt d.h. œâ‚ààA\n\n[!info] #Def 1.4 Die Potenzmenge ( #english power set)\nvon Œ©, P(Œ©) oder 2Œ©, ist die Menge aller Teilmengen von Œ©.\n\nEin prinzipielles Ereignis ( #english event) ist eine Teilmenge A‚äÜŒ©, also eine Kollektion von Elementarereignissen\nDie Klasse aller (beobachtbaren) Ereignisse bezeichnen wir mit F. Das ist eine Teilmenge der Potenzmenge von Œ©\n\nFalls Œ© endlich oder abz√§hlbar, dann ist oft F=P(Œ©), und das ist ein diskreter Wahrscheinlichkeitsraum.\nFalls Œ© √ºberabz√§hlbar, muss F eine echte Teilklasse von P(Œ©) sein\nIn jedem Fall muss F gewisse Axiome erf√ºllen\n\n[!Info] #Def 1.5 œÉ-Algebra (manchmal œÉ-field)\nEin Mengensystem F‚äÜP(Œ©) nennt man eine œÉ-Algebra, wenn\n\nŒ©‚ààF\nf√ºr jedes A‚ààF auch das Komplement A‚àÅ‚ààF ist\nf√ºr jede Folge (An)n‚ààN mit An‚ààF,n‚ààN, auch die Vereinigung ‚à™n‚ààNAn‚ààF ist\n\n[!info] #Def 1.9 Wahrscheinlichkeitsmass ( #english probability measure)\nSei Œ© ein Grundraum und sei F eine œÉ-Algebra. Eine Abbildung\nP:F‚Üí[0,1],mit¬†A‚Ü¶P[A]heisst Wahrscheinlichkeitsmass auf (Œ©,F), wenn die folgenden Axiome erf√ºllt sind\n\nNormiertheit: P[Œ©]=1\nœÉ-Additivit√§t: P[‚à™n‚ààNAn]=‚àën=1‚àûP[An] f√ºr paarweis disjunkte Mengen An, d.h. An‚à©Am=‚àÖ f√ºr alle n‚â†m\n\n[!info] #Proposition 1.10\nF√ºr ein Wahrscheinlichkeitsmass P auf (Œ©,F) und Mengen A,B‚ààF gelten folgende Aussagen:\n\nP[A‚àÅ]=1‚àíP[A], und insbesondere P[‚àÖ]=0\nMonotonie: wenn A‚äÜB, dann P[A]‚â§P[B]\nAdditionsregel: P[A]+P[B]=P[A‚à™B]+P[A‚à©B]\n\n[!info] #Def 1.12 Wahrscheinlichkeitsraum\nSei Œ© ein Grundraum, F eine œÉ-Algebra und P ein Wahrscheinlichkeitsmass auf (Œ©,F). Das Tripel (Œ©,F,P) heisst Wahrscheinlichkeitsmass ( #english probability space)\n\n[!info] #disclaimer 1.13 Messbarer Raum ( #english measurable space)\nAllgemein verwenden wir in der Masstheorie folgende Terminologie:\n\nF√ºr eine œÉ-Algebra A auf einer Grundmenge Œ© wird das Paar (Œ©,A) ein messbarer Raum genannt.\nElemente A‚ààA, also Teilmengen A‚äÇŒ©, die wir messen wollen, heissen messbare Mengen ( #english measurable sets).\nAuf messbaren R√§umen (bzw. den œÉ-Algebren) lassen sich Masse ( #english measures) Œº definieren. Diese sind im Allgemeinen nicht auf 1 nomiert. Man verlangt staddessen Œº(‚àÖ)=0.\nDas Tripel $(\\Omega,\\cal{A},\\mu) $ heisst Massraum ( #english measure space).\nIst das Mass normiert, Œº(Œ©)=1, dann ist das Mass ein Wahrscheinlichkeitsmass und der Messraum wird zum Wahrscheinlichkeitsraum.\n\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/ws/diskrete-wahrscheinlichkeit/\">Diskrete Wahrscheinlichkeit</a>",
		"tags": ["Def", "aka", "english", "aka", "english", "Def", "english", "english", "Def", "Def", "english", "Proposition", "Def", "english", "disclaimer", "english", "english", "english", "english", "note"]
},

{
		"title": "WS L2",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l2/",
		"content": "[!info] #Def 1.22 Bedingte Wahrscheinlichkeit\nGegeben: Wahrscheinlichkeitsraum (Œ©,F,P), P[B]&gt;0\nDann ist P[A|B]:=P[A‚à©B]P[B]\n\nP[A|A]=1\nP[A|Œ©]=P[A]\nP[A‚à©B]=P[A|B]P[B]\nP[A|B] ist nicht definiert f√ºr P[B]=0\n\n[!info] #Theorem 1.25\nGegeben: Wahrscheinlichkeitsraum (Œ©,F,P),P[B]&gt;0\nDann ist P‚àó:F‚Üí[0,1] definiert durch A‚Ü¶P‚àó[A]:=P[A|B] wieder ein Wahrscheinlichkeitsmass auf (Œ©,F)\n\nbedingte Wahrscheinlichkeit ist nicht symmetrisch in den beiden Argumenten. Insbesondere ist bei fixiertem Ereignis A die Funktion B‚Ü¶P[A|B] kein Wahrscheinlichkeitsmass\nIst Œ© endlich oder abz√§hlbar mit F=P(Œ©), dann ist P gegeben durch die Wahrscheinlichkeiten pn=P[{œân}]. Das bedingte Wahrscheinlichkeitsmass P‚àó[‚ãÖ]=P[‚ãÖ|B] ist dann durch√º√ºpn‚àó=P‚àó[{œân}]=P[{œân}|B]={pnP[B]f√ºr¬†œân‚ààB,0f√ºr¬†œân‚â†B,gegeben. Wir setzen alle Gewichte ausserhalb von B auf Null und skalieren die Gewichte in B mit einem festen Faktor, sodass ihre Summe wieder 1 ergibt.\n\n[!info] #Theorem 1.29 Satz von der totalen Wahrscheinlichkeit\nGegeben: B1,‚Ä¶,BN mit P[Bn]&gt;0 f√ºr jedes 1‚â§n‚â§N eine Partitione des Grundraums Œ©, d.h. ‚ãÉn=1NBn=Œ© mit Bn‚à©Bm=‚àÖ f√ºr n‚â†m.\nDann gilt f√ºr alle A‚ààF\nP[A]=‚àën=1NP[A|Bn]P[Bn]\n\n[!info] #Theorem 1.32 Satz von Bayes\nGegeben: B1,‚Ä¶,BN‚ààF eine Partition von Œ© mit P[Bn]&gt;0 f√ºr alle n.\nF√ºr jedes Ereignis A mit P[A]&gt;0 und jedes n‚àà{1,‚Ä¶,N} gilt\nP[Bn|A]=P[A|Bn]P[Bn]‚àëk=1NP[A|Bk]P[Bk]\n\nSpezialfall n=2 mit Œ©=B‚à™B‚àÅ so ist\nP[B|A]=P[A|B]P[B]P[A|B]P[B]+P[A|B‚àÅ]P[B‚àÅ]\n\n[!info] Unabh√§ngigkeit zweier Ereignisse\n(WS #Def 1.35)\nGegeben: (Œ©,F,P) ein Wahrscheinlichkeitsraum\nZwei Ereignisse A und B heissen (stochastisch) unabh√§ngig, falls\nP[A‚à©B]=P[A]P[B]\n\nFalls P[A]‚àà{0,1}, dann ist A unabh√§ngig von jedem Ereignis\nFalls Ereignis von sich selbst unabh√§ngig ist, dann muss P[A]‚àà{0,1} gelten. ( #disclaimerN (falls richtig) A von sich selbst unabh√§ngig ‚ü∫P[A]‚àà{0,1})\nA ist unabh√§ngig von B‚ü∫A unabh√§ngig von B‚àÅ\n\n[!info] (WS #Proposition 1.37)\nGegeben: A,B‚ààF zwei Ereignisse mit P[A],P[B]&gt;0\nDann sind folgende Aussagen √§quivalent:\n\n(i) P[A‚à©B]=P[A]P[B] d.h. A und B sind unabh√§ngig\n(ii) P[A|B]=P[A] d.h. Eintreten von B hat keinen Einfluss auf A\n(iii) P[B|A]=P[B] d.h. Eintreten von A hat keinen Einfluss auf B\n\n[!info] Unabh√§ngigkeit (WS #Def 1.40)\nGegeben: I eine beliebige Indexmenge\nEine Familie von Ereignissen ()Ai)i‚ààI heisst (stochastisch) unabh√§ngig, wenn f√ºr alle endlichen Teilmengen J‚äÇI gilt: P[‚ãÇj‚ààJAj]=‚àèj‚ààJP[Aj]\n\nfalls Menge unabh√§ngig ‚üπ Ereignisse paarweise unabh√§ngig (Umkehrung gilt nicht!)\n\n[!info] Zufallsvariable (WS #Def 2.1)\nGegeben: Wahrscheinlichkeitsraum (Œ©,F,P)\nEine (reellwertige) Zufallsvariable (Z.V.) ist eine Abbildung X:Œ©‚ÜíR, sodass f√ºr alle x‚ààR gilt,\n{œâ‚ààŒ©|X(œâ)‚â§x}‚ààF",
		"tags": ["Def", "Theorem", "Theorem", "Theorem", "Def", "disclaimerN", "Proposition", "Def", "Def", "note"]
},

{
		"title": "WS L3",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l3/",
		"content": "[!info] #Def 2.1 Zufallsvariable\nGegeben: Wahrscheinlichkeitsraum (Œ©,F,P)\nEine (reelwertige) Zufallsvariable ( #short Z.V.) ist eine Abbildung X:Œ©‚ÜíR sodass f√ºr alle x‚ààR gilt\n{œâ‚ààŒ©|X(œâ)‚â§x}‚ààF\n\n[!info] #Remark 2.5 Messbarkeit\nWenn eine (reelwertige) Funktion die Eigenschaft (2.1) erf√ºllt, heisst diese Funktion messbar ( #english measurable).\nDa wir an Ausg√§ngen von Zufallsexperimenten interessiert sind, wollen wir Wahrscheinlichkeiten der Form\n√ºP[{œâ‚ààŒ©|X(œâ)‚ààB}]¬†f√ºr bestimme Mengen¬†B‚äÇRberechnen k√∂nnen. Z.B.\n\nFalls B={2,4,6} wenn wir die Wahrscheinlichkeit f√ºr einen gerade Zahl beim W√ºrfeln m√∂chten.\nWeil das Wahrscheinlichkeitsmass P auf F definiert ist, m√ºssen die Urbilder aller dieser Mengen B,\n\nX‚àí1(B):={œâ‚ààŒ©|X(œâ)‚ààB}in F enthalten sein.\n\nIn dieser Vorlesung verlangen wir f√ºr Messbarkeit, dass X‚àí1(B)‚ààF f√ºr alle B‚ààB(R)\n\nHierbei ist B(R) die borelsche œÉ-Algebra auf R\nz.B. alle offenen, abgeschlossenen und kompakten Mengen in R oder alle Intervalle der Form (a,b),[a,b],(a,b],[a,b),(‚àí‚àû,b),(‚àí‚àû,b],(a,‚àû),[a,‚àû) f√ºr a,b‚ààR\n\n[!info] #Def 2.10 Verteilungsfunktion\nGegeben: reelwertige Zufallsvariable X, Wahrscheinlichkeitsraum (Œ©,F,P)\nDie (kumulative) Verteilungsfunktion von X ( #english cumulative distribution function) ( #short cdf) ist die Funktion FX:R‚Üí[0,1], definiert durch\nFX(x):=P[X‚â§x]\n\n[!info] #Theorem 2.13 Eigenschaften von Verteilungsfunktionen\nGegeben: Zufallsvariable X, Wahrscheinlichkeitsraum (Œ©,F,P)\nDie Verteilungsfunktion FX:R‚Üí[0,1] von X erf√ºllt folgende Eigenschaften:\n\n(i) FX ist monoton wachsend\n(ii) FX ist rechtsstetig d.h. f√ºr alle x‚ààR gilt FX(x)=limh‚Üí0FX(x+h)\n(iii) Es gelten die Grenzwerte limx‚Üí‚àí‚àûFX(x)=0 und limx‚Üí‚àûFX(x)=1\nI also found\nwikipedia\n\nP(X‚â§x)=FX(x)\nP(a&lt;X‚â§b)=FX(b)‚àíFX(a)\nP(X=b)=FX(b)‚àílimx‚Üíb‚àíFX(x)\n\nMath Stackexchange\n\nP(a&lt;X&lt;b)=P(X&lt;b)‚àíP(X‚â§a)=limx‚Üíb‚àíFX(x)‚àíFX(a)\n\n[!info] #Def 2.16 Gemeinsame Verteilungsfunktion\nGegeben: Zufallsvariablen X1,‚Ä¶,Xn\nDie gemeinsame Verteilungsfunktion von X1,‚Ä¶,Xn ist die Abbildung F:Rn‚Üí[0,1] definiert durch\n(x1,‚Ä¶,xn)‚Ü¶F(x1,‚Ä¶,xn)=P[X1‚â§x1,‚Ä¶,Xn‚â§xn]\n\n[!info] #Def 2.18 <a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Unabh√§ngigkeit</a> von Zufallsvariablen\nGegeben: Zufallsvariablen X1,‚Ä¶,Xn auf Wahrscheinlicheitsraum (Œ©,F,P). Dann heissen X1,‚Ä¶Xn unabh√§ngig, wenn f√ºr alle x1,‚Ä¶,xn‚ààR gilt\nP[X1‚â§x1,‚Ä¶,Xn‚â§xn]=P[X1‚â§x1]‚àó‚ãØ‚àóP[Xn‚â§xn]\n#Remark 2.19 X1,‚Ä¶,Xn sind genau dann unabh√§ngig, wenn f√ºr alle Intervalle I‚äÇR,‚Ä¶,In‚äÇR die Ereignisse {X1‚ààI1},‚Ä¶{Xn‚ààIn} unabh√§ngig sind.\nWenn wir eine Menge unabh√§ngiger Zufallsvariablen haben und disjunkte Gruppen solcher Zufallsvariablen bilden, dann sind diese Gruppen auch wiederum unabh√§ngig voneinander.\n\n[!info] #Theorem 2.21 Gruppierung von Zufallsvariablen\nGegeben: unabh√§ngige Zufallsvariablen X1,‚Ä¶Xn, Indexe 1‚â§i1&lt;i2&lt;‚ãØ&lt;ik‚â§n, Abbildungen œÜ1,‚Ä¶,œÜk\nDann sind\nY1:=œÜ1(X1,‚Ä¶,Xi1),Y2:=œÜ2(X1,‚Ä¶,Xi2),‚Ä¶,Yk:=œÜk(X1,‚Ä¶,Xik)unabh√§ngig.\n\n[!info] #Def 2.22. Unabh√§ngig und identisch verteilt\nEine Folge von Zufallsvariablen X1,X2 heisst\n\nunabh√§ngig falls X1,‚Ä¶,Xn f√ºr alle n‚ààN unabh√§ngig sind.\nunabh√§ngig und identisch verteilt ( #short u.i.v.) ( #english independent and identically distributed ( #short i.i.d.)) falls sie unabh√§ngig ist und die Zufallsvariablen dieselbe Verteilungsfunktion haben d.h. f√ºr alle k,l‚ààN gilt FXk=FXl",
		"tags": ["Def", "short", "Remark", "english", "Def", "english", "short", "Theorem", "Def", "Def", "Remark", "Theorem", "Def", "short", "english", "short", "note"]
},

{
		"title": "WS L4",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l4/",
		"content": "Beweis zu Satz 2.13\n\nExistenzsatz von Kolmogorov und Folgen von i.i.d. Bernoulli Zufallsvariablen\n\n[!info] #Def 2.24 Bernoulli\nGegeben: p‚àà[0,1].\nEine Zufallsvariable X heisst Bernoulli Zufallsvariable mit Parameter p, wenn gilt\nP[X=0]=1‚àíp¬†und¬†P[X=1]=pWir schreiben X‚àºBer(p).\n\n[!info] #Theorem 2.26 Existenz von Kolmogorov\nEs existiert ein Wahrscheinlichkeitsraum (Œ©,F,P) und eine unendliche Folge von i.i.d. Bernoulli Zufallsvariablen X1,X2,‚Ä¶ auf (Œ©,F,P) mit Parameter 12\n\n[!info] #Theorem 2.27.\nEine Zufallsvariable U heisst gleichverteilt auf [0,1], wir schreiben U‚àºU([0,1]), falls ihre Verteilungsfunktion gegeben ist durch\nFU(x)={0x&lt;0x0‚â§x‚â§11x&gt;1\n\nKonstruktion von gleichverteilten Zufallsvariablen auf [0,1]\n\n[!info] #Theorem 2.28\nDie Abbildung X:Œ©‚Üí[0,1] definiert in Gleichung (2.3) ist eine gleichverteilte Zufallsvariable auf [0,1].\n\n[!Info]- Beweis\nEs ist schnell sichtbar, dass f√ºr alle œâ‚ààŒ© gilt, X(œâ)‚àà[0,1]. Somit gilt f√ºr x&lt;0, dass FX(x)=P[X‚â§x]=0 und f√ºr x‚â•1, dass FX(x)=1\nSei also x‚àà[0,1) und sei {xn}n‚ààN ihre eindeutige Bin√§rdarstellung wie in Lemma 2.29. Dann gilt\n{X&gt;x}={X1&gt;x1}‚à™{{X1=x1}‚à©{X2&gt;x2}}‚à™‚Ä¶Also entweder ist die erste Ziffer gr√∂sser oder die erste Ziffer ist gleich und die zweite ist gr√∂sser usw.\n\n[!info] #Lemma 2.29 Bin√§rdarstellung\nJedes x‚àà[0,1) kann eindeutig in der Form\nx=‚àën=1‚àû2‚àínxndargestellt werden, wobei f√ºr alle n‚ààN gilt,xn‚àà{0,1}, und f√ºr jedes N‚ààN gibt es ein k&gt;N, sodass xk=0 (als odie Folge &quot;endet&quot; nicht in unendlich vielen 1-en.) Die Folge {xn}n‚ààN heisst Bin√§rdarstellung von x und wir schreiben x=(.x1x2‚Ä¶)2\n\nKonstruktion von Zufallsvariablen mit beliebiger Verteilungsfunktion F\nDa wir die Gleichverteilung auf [0,1] haben, w√ºrden wir nun gerne Zufallsvariablen mit beliebiger Verteilungsfunktion konstruieren k√∂nnen.\nGegeben: F:R‚Üí[0,1] eine Funktion, die die Eigenschaften (i)-(iii) aus Satz 2.13 erf√ºllt.\nFalls F streng monoton steigend und stetig ist, dann ist F bijektiv und es existiert eine Umkehrfunktion F‚àí1. F√ºr jedes Œ±‚àà[0,1] ist x:=F‚àí1(Œ±) die eindeutige reelle Zahl, f√ºr die F(x)=Œ± gilt.\nAllgemein kann die sogenannte verallgmeinerte inverse Verteilungsfunktion oder Quantil-Funktion f√ºr F definiert werden.\n\n[!info] #Def 2.30 Verallgemeinerte inverse Verteilungsfunktion\nDie Verallgemeinerte inverse Verteilungsfunktion von F ist eine Abbildung F‚àí1:(0,1)‚ÜíR definiert durch\nF‚àí1(Œ±)=inf{x‚ààR|F(x)‚â•Œ±}\nNach Definition des Infimums und unter Verwendung der Rechtsstetigkeit von F gilt f√ºr jedes x‚ààR und Œ±‚àà(0,1), dass\nF‚àí1(Œ±)‚â§x‚ü∫Œ±‚â§F(x)\nMithile der verallgemeinerten inversen Verteilungsfunktion k√∂nnen wir nun Zufallsvariablen mit beliebigen Verteilungsfunktionen konstruieren.\n\n[!info] #Theorem 2.31. Inversionsmethode\nGegeben: F:R‚Üí[0,1] eine Abbildung mit den Eigenschaften (i)-(iii) aus Satz 2.13, U‚àºU([0,1])\nDann hat die Zufallsvariable X:=F‚àí1(U) die Verteiungsfunktion F.\n\n[!info]- Beweis\nP[X‚â§x]=P[F‚àí1(U)‚â§x]=P[U‚â§F(x)]=F(x)‚óª\n#disclaimer 2.33\nWir bemerken, dass X=F‚àí1(U) strenggenommen nur auf einer Menge mit Wahrscheinlichkeit 1 (da P[U‚àà(0,1)]=1) aber nicht unbedingt auf ganz Œ© definiert ist. Wir beheben das Problem mittels folgender Definition\nX(œâ){F‚àí1(U(œâ))U(œâ)‚àà(0,1)0sonstDabei spielt 0 selbst keine Rolle und es kann jede beliebe reelle Zahl genommen werden.\n\nallgemeine Folgen von unabh√§ngigen Zufallsvariablen\n\n[!info] #Theorem 2.35.\nGegeben: Folge von Funktionen F1,F2 auf R‚Üí[0,1], die die Eigenschaften (i)-(iii) aus Satz 2.13 erf√ºllen.\nDann existiert ein Wahrscheinlichkeitsraum (Œ©,F,P) und eine Folge von Zufallsvariablen X1,X2,‚Ä¶ auf diesem Wahrscheinlichkeitsraum, sodass\n\nf√ºr jedes k gilt, Xk hat Verteilungsfunktion Fk und\nX1,X2,‚Ä¶ sind unabh√§ngig.\nDieser Satz erlaubt es uns, direkt mit Zufallsvariablen zu arbeiten, ohne den Wahrscheinlichkeitsraum (Œ©,F,P) genauer zu definieren.\nZ.B. k√∂nnen wir f√ºr zwei Verteilungsfunktionen F und G stets annehmen, dass X und Y existieren, die unabh√§ngig sind und Verteilungsfunktionen F und G besitzen",
		"tags": ["Def", "Theorem", "Theorem", "Theorem", "Lemma", "Def", "Theorem", "disclaimer", "Theorem", "note"]
},

{
		"title": "WS L5",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l5/",
		"content": "[!info] #Theorem 3.3. Wahrscheinlichkeit eines Punktes\nGegeben: Zufallsvariable X:Œ©‚ÜíR mit Verteilungsfunktion F.\nF√ºr jedes x‚ààR gilt P[X=x]=F(x)‚àíF(x‚àí)\n\nInterpretation: Sei x‚ààR fixiert\n\nWenn F in einem Punkt x‚ààR nicht stetig ist, dann ist die &quot;Sprungh√∂he&quot; F(x)‚àíF(x‚àí) gleich der Wahrscheinlichkeit, dass X=x\nFalls F stetig in einem Punkt x‚ààR ist, dann gilt P[X=x]=0\n\n[!info] #Def 3.4.\nGegeben: Ereignis A‚ààF\nWir sagen A tritt P-fast sicher ( #short P-f.s.) ein, falls P[A]=1 ( #english P-almost surely ( #short P-a.s.))\n\nAbk√ºrzung falls Wahrscheinlichkeitsmass P klar ist und schreiben nur &quot;fast sicher ( #short f.s.)&quot;\n#disclaimer 3.5. Erweiterung der Notation auf allgemeine Mengen A‚äÇŒ© (nicht unbedingt A‚ààF). Wir sagen, dass A fast sicher eintritt, falls ein Ereignis A‚Ä≤‚ààF existiert, sodass A‚Ä≤‚äÇA und P[A‚Ä≤]=1\ne.g. Wir schreiben X‚â§Y P-f.s., falls P[X‚â§Y]=1\nWenn wir mit stetigen ZV arbeiten, ist es oft restriktiv die Ungleichung X(œâ)‚â§Y(œâ) f√ºr alle œâ‚ààŒ© zu fordern. Deshalb fordern wir die Ungleichung nur auf einer Menge mit Mass 1.\n\nDiskrete Zufallsvariablen\n\n[!info] #Def 3.7. Diskrete Zufallsvariablen\nEine ZV X:Œ©‚ÜíR heisst diskret, falls eine endliche oder abz√§hlbare Menge W‚äÇR existiert, sodass P[X‚ààW]=1, wenn also die Werte von X fast sicher in W liegen.\n\n#disclaimer 3.8.\ngegeben: endlicher oder abz√§hlbarer Grundraum Œ©\nDann ist jede ZV X:Œ©‚ÜíR diskret. In der Tat ist das Bild\n\nX(Œ©)={x‚ààR|‚àÉœâ‚ààŒ©:X(œâ)=x}endlich oder ab√§hlbar und wir haben P[X‚ààW]=1 mit W=X(Œ©)\n\n[!info] #Def 3.9. Gewichtsfunktion\nF√ºr eine diskrete ZV X mit Wertebereich W(X)={x1,x2,‚Ä¶} und den dazugeh√∂rigen Wahrscheinlichkeiten {p1,p2,‚Ä¶} definieren wir die Gewichtsfunktion ( #short probability mass function ( #short pmf)) oder diskrete Dichte von X als\npX:W(X)‚Üí[0,1]¬†mit¬†pX(xk):=P[X=xk]=pkDie Zahlenfolge {pX(xk)}xk‚ààW(X) nennen wir auch Verteilung von X\n\n[!info] #Proposition 3.10.\nDie Gewichtsfunktion pX einer diskreten ZV X hat folgende Eigenschaften:\n\nF√ºr alle xk‚ààW(X) gilt pX(xk)‚àà[0,1]\nDie Wahrscheinlichkeiten addieren sich zu 1,\n\n‚àëxk‚ààW(X)pX(xk)=P[X‚ààW(X)]=1\n\n[!info] #disclaimer 3.11.\nUmgekehrt, wenn wir eine Folge von Zahlen (p(x)x‚ààW) mit Werten in [0,1] haben, sodass ‚àëx‚ààWp(x)=1, dann gibt es nach Satz 2.35 einen Wahrscheinlichkeitsraum (Œ©,F,P) und eine ZV X mit zugeh√∂riger Verteilung (p(x))x‚ààW.\nDiese Bebachtung ist in der Praxis wichtig, den sie erlaubt uns zu schreiben: &quot;Sei X eine diskrete ZV mit Verteilung (p(x))x‚ààW.&quot;\n\nZusammenhang Verteilungs- und Gewichtsfunktion\n\n[!info] #Theorem 3.12.\nSei X eine diskrete ZV mit Werten in W und Gewichtsfunktionen pX. Dann ist die Verteilungsfunktion von X gegeben durch\nFX(x)=P[X‚â§x]=‚àëy‚â§x,y‚ààWpX(y)\nInsbesondere ist FX also durch pX vollst√§ndig festgelegt. Mit dem gleichen Argument erh√§lt man auch f√ºr jede messbare Teilmenge B‚äÜW, P[X‚ààB]=‚àëx‚ààBpX(x)\n#disclaimer 3.13\nGleichung (3.1) dr√ºckt die Verteilungsfunktion FX in Bezug auf pX als eine st√ºckweise konstante Funktion aus.\nUmgekehrt ist eine ZV mit einer st√ºckweisen konstankten Verteilungsfunktion FX diskret. W und pX sind dann gegeben durch W={¬†Sprungstelle von¬†FX} und √∂p(x)=\"Sprungh√∂he im Punkt¬†x‚ààW\n\n[!info] #Theorem 3.19. Summe unabh√§ngiger Bernoulli-ZV\nGegeben: p‚àà[0,1], n‚ààN, unabh√§ngige X1,‚Ä¶,Xn‚àºBer(p)\nDann gilt Sn:=X1+‚ãØ+Xn‚àºBin(n,p)\n\n[!info] #Theorem 3.23\nGegeben: unendliche Folge von unabh√§ngigen Bernoulli-ZV X1,X2,‚Ä¶ mit Parameter p\nDann ist T:=inf{n‚â•1|Xn=1} eine geometrisch verteilte ZV mit Parameter p.\n\n#disclaimer 3.24. Sei z.B. T‚àºGeom(p), dann ist T&gt;n, wenn die ersten n Bernoulli-Expiremente fehlschlagen. Daher gilt P[T&gt;n]=(1‚àíp)n",
		"tags": ["Theorem", "Def", "short", "english", "short", "short", "disclaimer", "Def", "disclaimer", "Def", "short", "short", "Proposition", "disclaimer", "Theorem", "disclaimer", "Theorem", "Theorem", "disclaimer", "note"]
},

{
		"title": "WS L6",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l6/",
		"content": "[!info] #Theorem 3.25 Ged√§chtnislosigkeit der geometrischen Verteilung\nGegeben: T‚àºGeom(p), p‚àà(0,1)\nDann gilt f√ºr alle n‚â•0 und alle k‚â•1\nP[T‚â•n+k|T&gt;n]=P[T‚â•k]\nWenn wir also nach n Schritten immer noch auf den ersten Erfolg warten, dann ist die verbleibende Wartezeit wiederum Geom(p) verteilt.\n\n[!info]- Beweis\nP[T‚â•n+k|T&gt;n]=P[{T‚â•n+k}‚à©{T&gt;n}]P[T&gt;n]=P[T‚â•n+k]P[T&gt;n]=(1‚àíp)n+k‚àí1(1‚àíp)n=(1‚àíp)k‚àí1=P[T‚â•k]\n\n[!info] #Example 3.26 negativbinomiale Verteilung\nGegeben: Zufallsvariable X\nX hat eine negativbinomaile Verteilung mit Parameter r‚ààN und p‚àà[0,1], wir schreiben X‚ààNBin(r,p), wenn f√ºr alle k‚àà{r,r+1,r+2,‚Ä¶} gilt:\nP[X=k]=(k‚àí1r‚àí1)pr(1‚àíp)k‚àír\nDas ist eine Verallgemeinerung der geometrischen Verteilung, welche durch r=1 erh√§ltlich ist.\nIntuition: Warten auf den r-ten Erfolg, wobei die W'keit, dass es genau k Versuche braucht, aus zwei Teilen zusammensetzt\n\nW'keit, dass in den ersten k‚àí1 Versuchen genau r‚àí1 Erfolge eingetroffen sind\nW'keit, dass k-ter Versuch ein Erfolg ist\n\n[!info] #Theorem 3.27\nGegeben: unendliche Folge von unabh√§ngigen Bernoulli-Zufallsvariablen X1,X2 mit Parameter p\nDann hat\nTr=inf{n‚â•1|‚àël=1nXl=r}eine negativbinomiale Verteilung mit Parametern r und p\n\n#disclaimer 3.28 Sind die Zufallsvariaben X1,‚Ä¶,Xr‚àºGeom(p) und unabh√§ngig, so ist ihre Summe X=X1+‚ãØ+Xr‚àºNBin(r,p)\n\n[!info] #Example 3.29 Hypergeometrische Verteilung\nEine Zufallsvariable X heisst hypgergeometrische verteilt mit Parametern n‚ààN und m,r‚àà{1,‚Ä¶,n}, wir schreiben X‚àºH(n,r,m), wenn f√ºr alle k‚àà{0,1,‚Ä¶,min(m,r)} gilt\nP[X=k]=(rk)(n‚àírm‚àík)(nm)Diese Gewichtsfunktion kommt wie folgt zustande\n#Theorem 3.30 Seien in einer Urne n Gegenst√§nde, davon r vom Typ 1 und n‚àír vom Typ 2. Es werden m Gegenst√§nde ohne Zur√ºcklegen gezogen. Sei X nun die Anzahl der gezogenen Gegenst√§nde vom Typ 1. Dann ist X hypergeometrisch mit den Parametern von oben verteilt.\n\n#remark TA\n\nZ√§hler: Anzahl Arten genau k Gegenst√§nde von Typ 1 und m‚àík von Typ 2 zu ziehen.\nNenner: Anzahl Arten m Gegenst√§nde zu ziehen.\n\n[!info]- Beweis\n\n#Example 3.31 Lotto\nIm Schweizer Lotto, wo 6 aus 42 zahlen richtig getippt werden sollen, ist die Anzahl der richtigen getippten Zahlen bei einem einzelnen Tipp hypergeometrisch verteilt mit Parametern n=42,r=6,m=6.\n\n[!info] Poisson-Verteilung\nGegeben: positive reelle Zahl Œª&gt;0\nEine Zufallsvariable X heisst Poisson-verteilt mit Parameter Œª, wir schreiben X‚àºPoisson(Œª), wenn sie Werte N annimt und f√ºr alle k‚ààN0 gilt\nP[X=k]=Œªkk!e‚àíŒª\nGebrauch: Die Poisson-Verteilung approximiert dei Binomialverteilung f√ºr grosse n. Das ist n√ºtzlich, da die Gewichtsfunktion der Poissonverteilung deutlich einfacher zu berechnen ist.\n[!info] #Theorem 3.34 Poisson-Approximation der Binomialverteilung\nGegeben: Œª&gt;0\nF√ºr jedes n‚â•1 betrachten wir n Zufallsvariablen Xn‚àºBin(n,Œª). Sei N‚àºPoisson(Œª). Dann gilt f√ºr alle k‚ààN\n\nlimn‚Üí‚àûP[Xn=k]=P[N=k]\n#disclaimer 3.35 Diese Art von Konvergenz wird Konvergenz in Verteilung ( #english lish convergence in distribution, convergence in law)oder schwache Konvergenz ( #english weak convergence) genannt. Intuitiv besagt sie, dass Xn und N sehr √§hnliche wahrscheinlichkeitstheoretische Eigenschaften f√ºr grosse n haben.\n#Example 3.36\n\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/ws/wahrscheinlichkeit/stetige-zufallsvariablen/\">Stetige Zufallsvariablen</a>",
		"tags": ["Theorem", "Example", "Theorem", "disclaimer", "Example", "Theorem", "remark", "Example", "Theorem", "disclaimer", "english", "english", "Example", "note"]
},

{
		"title": "WS L7 Normalverteilung",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l7-normalverteilung/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/ws/wahrscheinlichkeit/normalverteilung/\">Normalverteilung</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/ws/wahrscheinlichkeit/erwartungswert/\">Erwartungswert</a>",
		"tags": [ "note"]
},

{
		"title": "WS Definitionen, Notationen",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/ws-definitionen-notationen/",
		"content": "X¬Øn ist das arithmetische Mittel der Xk und wird im Zusammenhang mit Zufallsvariablen auch Stichprobenmittel genannt. Eine Realisierung des Stichprobenmittel, X¬Øn(œâ), wird auch empirischer Mittelwert genannt.\nX‚Üí=(X1,‚Ä¶,Xn)",
		"tags": [ "note"]
},

{
		"title": "Erwartungswert",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/wahrscheinlichkeit/erwartungswert/",
		"content": "[!info] #Def 4.1 Erwartungswert (nicht negativ)\nGebenen: Zufallsvariable X:Œ©‚ÜíR+ mit nicht-negativen Werten, Verteilungsfunktion FX\nDann heisst (4.1)\nE[X]=‚à´0‚àû(1‚àíFX(x))dxder Erwartungswert von X ( #english expected value)\n\n#disclaimer 4.2 Erwartungswert in Gleichung (4.1) ist immer definiert und kann sowohl endlich als auch unendlich werden.\n\n[!info] #Theorem 4.3\nGegeben: nicht-negative Zufallsvariable X\nDann gilt E[X]‚â•0. Gleichheit gilt genau dann, wenn X=0 fast sicher gilt.\nF√ºr allgemeine Zufallsvarialben (nicht unbedingt mitkonstantem Vorzeichen) ist Erwartungswert durch Zerlegung in positiven und negativen Teil definiert.\nX+(œâ)={X(œâ)X(œâ)‚â•00X(œâ)&lt;0undX‚àí(œâ)={‚àíX(œâ)X(œâ)‚â§00X(œâ)&gt;0\nK√ºrzer: X+=max(X,0) und X‚àí=‚àímin(X,0)=max(‚àíX,0)\nAchtung X+ und X‚àí sind nicht-negative Zufallsvariablen und es gilt\n\nX=X+‚àíX‚àí\n|X|=X++X‚àí\n\n[!info] #Def 4.4 Allgemeiner Erwartungswert\nGegeben: reellwertige Zufallsvariable X\nFalls E[|X|]&lt;‚àû, dann heisst (4.2) E[X]=E[X+]‚àíE[X‚àí] der Erwartungswert von X\n\n#disclaimer 4.5\n\nE[|X|]&lt;‚àû‚üπE[X‚àí],E[X+]&lt;‚àû da |X|=X++X‚àí. Somit ist Gleichung (4.2) wohldefiniert.\nF√ºr X‚â•0 ist der Erwartungswert von X immer definiert. Er kann endlich oder unendlich sein.\nWenn X kein konstantes Vorzeichen hat und E[|X|]&lt;‚àû nicht erf√ºllt ist, dann sagen wir, der Erwartungswert von X ist undefiniert\n\nErwartungswert aus Gleichung (4.2) kann auch wie folgt ausgedr√ºckt werden E[X]=‚à´0‚àû(1‚àíFX(x))dx‚àí‚à´‚àí‚àû0FX(x)dx\n\nErwartungswert diskreter Zufallsvariablen\n\n[!info] #Theorem 4.8 Erwartungswert (diskret)\nGegeben: diskrete Zufallsvariable X:Œ©‚ÜíR deren Werte fast sicher in W (endlich oder abz√§hlbar) liegen.\nDann gilt\nE[X]=‚àëx‚ààWx‚ãÖP[X=x]=‚àëx‚ààWxpX(x)solange der Erwartungswert wohldefiniert ist.\n\n#disclaimer 4.9 Der Erwartungswert ist wohldefiniert, sofern die Reihe ‚àëx‚ààWx‚ãÖP[X=x] absolut konvergiert d.h. ‚àëx‚ààW|x|‚ãÖP[X=x]&lt;‚àû\nAndernfalls existiert der Erwartungswert nicht.\n\nBeispiele\n\n#Example 4.10 Bernoulli: X‚àºBer(p)‚üπE[X]=p\n\n#Example 4.13 Indikatorfunktion (beschreibt, ob ein Element in einer Menge ist oder nicht) 1A‚àºBer(P[A])‚üπE[+A]=P[A]\n\n#Example 4.12Poisson: X‚àºPoisson(Œª)‚üπE[X]=Œª\n\n#proof\n\n#Example 4.14 Binomialverteilung: X‚àºBin(n,p)‚üπE[X]=np\n\n#proof\n\nErwartungswert transformierte Zufallsvariablen\n\n[!info] #Theorem 4.15\nGegeben: diskrete Zufallsvariable X:Œ©‚ÜíR, Abbildung œï:R‚ÜíR\nDann gilt $$\\mathbb{E}[\\phi(x)]=\\sum\\limits_{x\\in W}\\phi(x)\\cdot \\mathbb{P}[X=x]$$\nsolange der Erwartungswert wohldefiniert ist.\n\nErwartungswert stetiger Zufallsvariablen\n\n[!info] #Theorem 4.17\nGegeben: stetige Zufallsvariable X mit Dichte fX\nDann gilt\nE[X]=‚à´‚àí‚àû‚àûxfX(x)dxsolange das Integral absolute konvergiert.\n\nFalls das Integral nicht absolut konvergiert, existert der Erwartungswert (zumindest in R) nicht.\n\n[!info] #Theorem 4.18\nGegeben: Zufallsvariable X mit Dichte fX, Abbildung œÜ:R‚ÜíR.\nDann gilt\nE[œÜ(X)]=‚à´‚àí‚àû‚àûœÜ(x)fX(x)dx\nVerteilungen\n\nGleichverteilung: f√ºr X‚àºU([a,b]),a&lt;b ist E[X]=a+b2\nExponentialverteilung: f√ºr X‚àºExp(Œª),Œª&gt;0 ist E[X]=1Œª\nNormalverteilung: f√ºr $X\\sim\\cal{N}(\\mu,\\sigma^{2}) ist $ E[X]=Œº\nCauchy-Verteilung: es existiert kein Erwartungswert, da absolute Integral ‚àû gibt.\n\nEigenschaften Erwartungswert\n\n[!info] #Theorem 4.25. Linearit√§t des Erwartungswerts\nGegeben: Zufallsvariablen X,Y:Œ©‚ÜíR, Œª‚ààR\nFalls die Erwartungswerte wohldefiniert sind, gilt\n\n(i) E[ŒªX]=ŒªE[X]\n(ii) E[X+Y]=E[X]+E[Y]\n#disclaimer 4.26\nGegeben: Zufallsvariablen Xk:Œ©‚ÜíR, Konstanten Œªk‚ààR,k‚àà{1,‚Ä¶,n}\nFalls alle Erwartungswerte wohldefiniert sind, gilt E[‚àëk=1nŒªkXk]=‚àëk=1nŒªkE[Xk]\n\n[!info] Theorem 4.29. Monotonie des Erwartungswerts\nGegeben: Zufallsvariablen X,Y sodass X‚â§Y f.s. gilt\nFalls beide Erwartungswerte wohldefiniert sind , gilt E[X]‚â§E[Y]\n\n[!info] #Theorem 4.30. Erwartungswerte bei Unabh√§ngigkeit\nGegeben: unabh√§ngige Zufallsvariablen X,Y mit endlichen Erwartungswerten\nDann gilt E[XY]=E[X]E[Y]\n\n[!info] #Theorem 4.31.\nGegeben: unabh√§ngige Zufallsvariablen X1,‚Ä¶,Xn mit endlichen Erwartungswerten\nDann gilt E[‚àèk=1nXk]=‚àèk=1nE[Xk]\n\n[!info] #Theorem 4.32\nGegeben: Zufallsvariable X, Abbildung f:R‚ÜíR+ sodass ‚à´‚àí‚àû‚àûf(x)dx=1\nDann sind folgende Aussagen √§quivalent\n\n(i) X ist stetig mit Dichte f\n(ii) f√ºr jede st√ºckweise stetige, beschr√§nkte Abbildung œÜ:R‚ÜíR gilt\n\nE[œÜ(X)]=‚à´‚àí‚àû‚àûœÜ(x)f(x)dx\n\n[!Info] #Theorem 4.33\nGegeben: Zufallsvariablen X,Y\nDie folgenden Aussagen sind √§quivalent\n\n(i) X,Y sind unabh√§ngig\n(ii) F√ºr alle st√ºckweise stetigen, beschr√§nkten Abbildungen œÜ,œà:R‚ÜíR gilt\nE[œÜ(X)œà(Y)]=E[œÜ(X)]E[œà(Y)]\n\n[!Info] #Theorem 4.34\nGegeben: Zufallsvariablen X1,‚Ä¶,Xn\nDie folgenden Aussagen sind √§quivalent\n\n(i) X1,‚Ä¶,Xn sind unabh√§ngig\n(ii) F√ºr alle st√ºckweise stetigen, beschr√§nkten Abbildungen œÜ1,‚Ä¶,œÜn:R‚ÜíR gilt\nE[œÜ1(X1)‚ãÖ‚ãØ‚ãÖœÜn(Xn)]=E[œÜ1(X1)]E[œÜn(Xn)]\n\n[!info] #Theorem 4.35 Markow-Ungleichung\nGegeben: nicht-negative Zufallsvariable X, wachsende Funktion g:X(Œ©)‚Üí[0,‚àû)\nF√ºr jedes c‚ààR mit g(c)&gt;0 gilt P[X‚â•c]‚â§E[g(X)]g(c)\n\n[!info] #Theorem 4.36 Jensensche Ungleichung\nGegeben: Zufallsvariable X, konvexe Funktion œÜ:R‚ÜíR\nFalls E[œÜ(X)] und E[X] wohldefiniert sind, gilt (4.5) $$\\varphi(\\mathbb{E}[X])\\leq \\mathbb{E}[\\varphi(X)]$$\n\n#Corollary 4.37 Dreiecksungleichung\nDie Anwedung der Jensenschen Ungleichung auf œÜ(x)=x liefert die Dreiecksungleichung $$|\\mathbb{E}[X]|\\leq \\mathbb{E}[|X|]$$\nEine weitere Folge ist der Zusammenhang zwischen dem Erwartungswert von |X| und dem Erwartungswert von X2. Die Jensensche Ungleichung liefert f√ºr die konvexe Funktion œÜ(x)=x2 $$\\mathbb{E}[|X|]\\leq \\sqrt{ \\mathbb{E}[X^{2}] }$$",
		"tags": ["Def", "english", "disclaimer", "Theorem", "Def", "disclaimer", "Theorem", "disclaimer", "Example", "Example", "Example", "proof", "Example", "proof", "Theorem", "Theorem", "Theorem", "Theorem", "disclaimer", "Theorem", "Theorem", "Theorem", "Theorem", "Theorem", "Theorem", "Theorem", "Corollary", "note"]
},

{
		"title": "Normalverteilung",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/wahrscheinlichkeit/normalverteilung/",
		"content": "[!info] #Example 3.46 Normalverteilung !\nEine stetige Zufallsvariable X heisst normalverteilt mit Parametern Œº‚ààR und œÉ2&gt;0, wir schreiben X‚àºN(Œº,œÉ2), falls ihre Dichte gegeben ist durch (3.5)\nfX(x)=1œÉ2œÄe‚àí12(x‚àíŒºœÉ)2\n\n#disclaimer 3.47 Die Funktion in Gleichung (3.5) hat u.a. folgende Bezeichnung: Gauss-Funktion, gausssche Normalverteilung, gausssche Verteilungsfunktion, Gauss-Kurve, (gausssche) Glockenkurve, Gauss-Glocke\n#disclaimer 3.48 Ein wichtiger Spezialfall ist die Standardnormalverteilung mit Œº=0 und œÉ2=1 also N(0,1).\nDie zugeh√∂rige Dichte wird meistens mit œÜ und die Verteilungsfunktion mit œï bezeichnet. Die dazugeh√∂rige Variable nennen wir meistens Z\nWeder f√ºr FX noch f√ºr œï gibt es einen geschlossenen Ausdruck, aber das Integralœï(x)=‚à´‚àí‚àûxœÜ(t)dt=12œÄ‚à´‚àí‚àûxe‚àít22dtist tabelliert (siehe Appendix =&gt; Standardnormalverteilung)\nEigenschaften ( #source TA Yanik Yanik K√ºnzi)\n\npdf ist symmetrisch mit Symmetrieachse x=Œº\nf√ºr cdf gibt es keinen geschlossenen Ausdruck =&gt; braucht Tabellen\nbeliebige normalverteilte ZV k√∂nnen auf die Standardnormalverteilung zur√ºckgef√ºhrt werden\n68-95-99-Regel\n\nEs gen√ºgt die Werte von œï zu tabellieren\n\n[!info] #Proposition 3.49 Standardnormalverteilung\nF√ºr X‚àºN(Œº,œÉ2) gilt X‚àíŒºœÉ‚àºN(0,1), also\nFX(x)=P[X‚â§x]=P[X‚àíŒºœÉ‚â§x‚àíŒºœÉ]=œï(x‚àíŒºœÉ)\n#disclaimer 3.50\nGegeben: unabh√§ngige normalverteilte Zufallsvariablen X1,‚Ä¶,Xn mit Parametern (Œº1,œÉ12),‚Ä¶,(Œºn,œÉn2). Dann gilt\n\nZ:=Œº0+‚àëk=1nakXk‚àºN(Œº0+‚àëk=1nakŒºk,‚àëk=1nak2œÉk2)\n#disclaimer 3.51 Aus Proposition 3.49 lesen wir direkt ab, dass f√ºr Œº‚ààR,œÉ2&gt;0 und Z‚àºN(0,1) giltŒº+œÉZ‚àºN(Œº,œÉ2)D.h. wenn wir z.B. X‚àºN(Œº,œÉ2) auf dem Computer simulieren wollen, reicht es ein Z‚àºN(0,1) zu simulieren und die erhaltenen Werte mit œÉ zu multiplizieren und Œº zu addieren.\n#disclaimer 3.52 F√ºr X‚àºN(Œº,œÉ2) liegt der &quot;Grossteil&quot; des Wahrscheinlichkeitsmasses im Intervall [Œº‚àí3œÉ,Œº+3œÉ]. Genauer gilt P[|X‚àíŒº|‚â•3œÉ]‚â§0.0027\n\n[!info] Transformation zur Standardnormalverteilung\nGegeben: X‚àºN(Œº,œÉ2) und Y=Œ±+Œ≤X dann gilt Y‚àºN(Œº+Œ±,Œ≤2œÉ2). Dann ist die standardnormalverteilte ZV Z:=x‚àíŒºœÉ‚àºN(0,1)\n\nIntuition",
		"tags": ["Example", "disclaimer", "disclaimer", "source", "Proposition", "disclaimer", "disclaimer", "disclaimer", "note"]
},

{
		"title": "Stetige Zufallsvariablen",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/wahrscheinlichkeit/stetige-zufallsvariablen/",
		"content": "[!info] #Def 3.37 Stetig verteilte Zufallsvariablen\nEine Zufallsvariable X:Œ©‚ÜíR heisst stetig, wenn eine nicht-negative Funktion fX:R‚ÜíR+ existiert, sodass die Verteilungsfunktion FX dargestellt werden kann als\nFX(x)=‚à´‚àí‚àûxfX(t)dtWir nennen fX die Dichte(-funktion) von X ( #english probability density function ( #short pdf)).\n\nIntuition: Der &quot;Wert&quot; fX(t)dt ist die Wahrscheinlichkeit, dass X Werte im Intervall [t,t+dt] annimmt.\nAls absolute Gr√∂sse ist das nicht sehr vielsagend, wir k√∂nnen aber so W'keiten vergleichen z.B. falls fX(x0)=2fX(x1) interpretieren wir als &quot;es ist doppelt so wahrscheinlich, dass X in der N√§he von x0 ist, wie dass X in der N√§he von x1 ist.&quot;\nDie Terminologie &quot;stetig&quot; ergibt sich aus der Tatsache, dass die Gleichung oben impliziert, dass FX eine stetige Funktion ist. Insbesondere gilt f√ºr alle x‚ààR laut Satz 3.3, P[X=x]=0\n\n[!info] #Def 3.38 St√ºckweise stetig differenzierbare Funktion\n\nIm Kontext von R wird oft gesagt, dass ein Objekt eine Eigenschaft st√ºckweise ( #english piecewise) erf√ºllt, wenn sie die Eigenschaft auf einer Partition des Definitionsbereichs erf√ºllt.\nWir sagen, eine Funktion f ist st√ºckweise stetig differenzierbar, wenn es eine Partition ‚àí‚àû=x0&lt;x1&lt;‚ãØ&lt;xn‚àí1&lt;xn=‚àû gibt, sodass f auf jedem Intervall xi,xi+1 stetig differenzierbar ist.\nIntuition: D.h. dass die Funktion f nur an den Punkten x1,‚Ä¶,xn‚àí1 &quot;Probleme&quot; machen k√∂nnte. Wir l√∂sen diese Probleme, indem wir diese Punkte effektiv entfernen und die Funktion nur auf der daraus entstehenden Partition betrachten.\n\n[!info] #Theorem 3.39\nGegeben: Zufallsvariable X, stetige und st√ºckweise differenzierbare Verteilungsfunktion FX auf einer Partition ‚àí‚àû=x0&lt;x1&lt;‚ãØ&lt;xn‚àí1&lt;xn=‚àû\nDann ist X eine stetige Zufallsvariable und die Dichtefunktion fX kann wie folgt konstruiert werden:\nfX(x){FX‚Ä≤(x)‚àÉk‚àà{0,‚Ä¶,n‚àí1}:x‚àà(xk,xk+1)akx‚àà{x1,‚Ä¶,xn‚àí1}wobei die Werte ak beliebig gew√§hlt werden d√ºrfen.\nIn anderen Worten, es gilt fX(x)=F‚Ä≤(X)(x) in allen Stetigkeitspunkten x von fX\n\n#disclaimer 3.40 Die Dichtefunktion fX ist (fast exakt) dast stetige Analogen zur Gewichtsfunktion pX einer diskreten Zufallsvariablen\n\nF√ºr messbare Mengen B‚äÇR giltP[X‚ààB]=‚à´BfX(x)dx¬†analog zu¬†P[X‚ààB]=‚àëx‚ààBpX(x)\nDa allerdings P[X=x]=0 f√ºr jedes x‚ààR, hat in diesem Sinn X keine Gewichtsfunktion wie eine diskrete Zufallsvariable.\nIst allerdings fX stetig an der Stelle x, so haben wirfX)(x)=limœµ‚Üò01œµ‚à´xx+œµfX(t)dt=limœµ‚Üò0P[x&lt;X‚â§x+œµ]œµund somit\nP[X‚àà(x,x+œµ)]‚âàœµfX(x) f√ºr kleine œµ\nEinfache Merkregel: Um vom diskreten zum stetigen Fall zu kommen, kann die Kombination (Summe, Gewichtsfunktion) systematisch durch (Integral, Dichtefunktion) ersetzt werden.\n\nBeispiele\n\n#Example 3.41 Gleichverteilung:\n\nIntuition: W√§hlt zuf√§llig einen Punkt in [a,b].\nEigenschaften:\n\n#Example 3.43 Exponentialverteilung\n\nIntuition:\nEigenschaften:\n\n#Example 3.45 Cauchy-Verteilung:\n\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/ws/wahrscheinlichkeit/normalverteilung/\">Normalverteilung</a>",
		"tags": ["Def", "english", "short", "Def", "english", "Theorem", "disclaimer", "Example", "Example", "Example", "note"]
},

{
		"title": "home page",
		"date":"Tue May 28 2024 21:27:41 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "",
		"tags": [ "note","gardenEntry"]
}
]