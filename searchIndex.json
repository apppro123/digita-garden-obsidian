[
{
		"title": "DF Definitions",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-definitions/",
		"content": "more definition in [[Ethereum and DeFi Glossary.pdf]]\npegged cryptocurrency: cryptocurrency whose value is linked to a specific bank-issued currency, financial instrument or tradable commodity\n\ne.g. pay back to buy BTC and holds it for you\n\nKnow your customer ( #short KYC): means verifying who you are when joining a crypto exchange\nAnti-money laundering ( #short AML): helping to break criminal networks and minimise the impact of illicit transactions on affected economies.\nwashtrading: occurs when an investor buys and sells the same or a similar security investment at the same time (e.g. can be done by using flash loans)\n(Fractional) reserve: bank's reserve ratio = (money held by bank) / (money deposited by bank customers)\nExchange traded fund ( #short ETF): security/asset\n\ntracking an index/sector/commodity\ntradable on an exchange\ntypically, lower fees than buying individual stocks\nEFT types: bond, stock, industry, commodity, currency, inverse, etc\ne.g. SPDR S&amp;P 500 ETF tracks the S&amp;P 500 index\n\ndecentralised autonomous organisation ( #short DAO): e.g. <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/df-l6/#maker-dao-pasted-image-20240405232329-png\">MakerDAO</a>\n\nLending\n\ncollateral: assets that serve as a security deposit\nOver-collateralisation: Borrower has to provide value(collateral assets) &gt; value(granted loan)\nUnder-collateralisation: value(collateral) &lt; value(debt)\nLiquidation: selling collateral from the borrower\n\nE.g., if value(collateral) &lt;= 150% x value(debt)\nAnyone can liquidate the debt position\n\nHealth factor\n\n0 &lt; liquidation threshold &lt; 1\nliquidation threshold provides a &quot;secure&quot; margin\nwhen health factor &lt; 1 =&gt; borrowing position becomes liquidatable\ne.g.\n\nLiquidation Spread #short LS: bonus, or discount, that a liquidator can collect when liquidating collateral\n\nğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ ğ‘œğ‘“ ğ¶ğ‘œğ‘™ğ‘™ğ‘ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘™ ğ‘¡ğ‘œ ğ¶ğ‘™ğ‘ğ‘–ğ‘š = ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ ğ‘œğ‘“ ğ·ğ‘’ğ‘ğ‘¡ ğ‘¡ğ‘œ ğ‘…ğ‘’ğ‘ğ‘ğ‘¦ Ã— (1 + ğ¿ğ‘†)\n\nClose Factor #short CF: the maximum proportion of the debt that is allowed to be repaid in a single fixed spread liquidation\nğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ ğ‘œğ‘“ ğ·ğ‘’ğ‘ğ‘¡ ğ‘¡ğ‘œ ğ‘…ğ‘’ğ‘ğ‘ğ‘¦ &lt; ğ¶ğ¹ Ã— ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ ğ‘œğ‘“ ğ·ğ‘’ğ‘ğ‘¡ğ‘ ",
		"tags": ["short", "short", "short", "short", "short", "short", "note"]
},

{
		"title": "DF L1",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l1/",
		"content": "#disclaimer Not examrelevant!\n\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/financial-markets/\">Financial Markets</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/decentralised-finance/\">Decentralised Finance</a>",
		"tags": ["disclaimer", "note"]
},

{
		"title": "DF L2",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l2/",
		"content": "&lt;![[Ethereum and DeFi Glossary.pdf]]\nQuiz\n\nA valid signed transaction of an account can be used to computer\n\nthe private key of the account\nthe address of the account [true]\n(both are true)\n(both are false)\n\nRunning a node in the Ethereum network\n\nwill earn you money\nwill cost you proof-of-work mining energy\nneeds an excellent internet connection (because you constantly need to be connected to 5'000 other nodes)\n(none of the above) [true]\n\nAn Ethereum smart contract can be programmed to\n\ninteract with a normal (not Ethereum) computer program through remote procedure calls.\nautomatically run every hour.\n(both are ture)\n(both are false) [true]\n\nLayer 2 protocols\n\nare not realy (only exist in reseach)\nare considered illegal (by the Ethereum foundation)\nhave been co-invented at ETH Zurich [true]\n(none of the above)\n\nIgnore fees, how many bananas do you get when you send 10 apples to a CPMM that holds a liquidity of 30 apples and 56 bananas?\n\nHow to calculate?\n\nconstant product = 30 [apples] * 56 [bananas] = 168\nand afterwards there has to be the same again thus 40 (30 + 10 new) [apples] * x [bananas] = 168\nsolve for x\n\nalternative: calculate ratio after adding 56 [bananas] / 40 [apples] = 7 / 5 =&gt; now multiply with number of apples and you get bananas 7 [bananas] / 5 [apples] * 10 [apples] = 14 [bananas]",
		"tags": [ "note"]
},

{
		"title": "DF L3",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l3/",
		"content": "DF and CF\nDF stack\n\nExample where smart contract on blockchain uses external data\n\nOracle\n\nReasons for need of oracles for blockchains\n\nblockchain is isolated DB\nblockchains lack\n\naccess to real-world data\nno API-query possible\ncannot browse the internet\n\nSolution: transactions\nDefinition\n\nGeneral: System that connects a blockchain with other systems.\nSpecific: Actors relaying data on-chain.\n\nDesign\nChallenges\n\nminers (provider of data) can lie/cheat\nnetwork providing data for miners can lie/cheat\nsource or oracle outage\n=&gt; have multiple miners and sources to prevent outage\n=&gt; have consensus so possibility of false data is minimised\n\nCensorship\n\ncan happen on multiple layers e.g. application, transaction, consensus\n\nMixers\n\nbreaks connection to person who put it in =&gt; but observations/analysis of transaction can help with finding out who gave/took coins\n(in best case) just fixed values e.g. 1 ETH possible, so less\n\nImplications\n\nConfirmation latency: slows down transaction confirmations\nDenial of Service: A lot of (fake) transactions can slow node down or even completely take it down\n\nproposer/builder separation\nattack nodes who apply censorship\n\nfor censorship, nodes have to put in work to extract information but then cannot do transactions and don't earn anything bc. transaction with a censored value is not allowed =&gt; DDoS attack possible to spam node with censored coins\n\nQuiz\n\nWhich of the following DeFi applications is most likely to require external oracle data?\n\nToken management contracts, such as ERC20\nBetting on real world events [correct]\nUniswap, Curve, and other Automated Market Maker Decentralised Exchanges\nOn-chain games that do not require randomness\n\nIs the context of blockchain oracles, which of the following statements is NOT TRUE?\n\nBecause block generation is centralised process, incorporating an oracle into the consensus protocol does not work because miners may lie or cheat.\nOracles have to receive very concise and short data representations to minimise blockchain fees.\nFor each oracle update, a minimum subset of all nodes in the oracle committee should send a report to the miner. [correct bc. one node is enough]\nMultiple sources /website (redundancy) are required due to website outages and data corruption possibilities\n\nWhat is the anonymity set of Tronado Cach pool with 1000 deposits\n\n100\n1000 [correct]\n999\n1001\n\nWhat are the computational implications if a miner censors a transaction, what is correct?\n\nNo implication bc. the miner doesn't need to verify the transaction.\nNo implications bc. the miner doesn't need to execute the transaction.\nThe minder must spend computational resources to execute the transaction but cannot claim transaction fees. [correct]\nThe miner must spend computational resources but is paid the regular transaction fees.\n\nAssumed an oracle committee has five nodes (A,B,C,D,E) and it's agreed to report the median value. Node E is a malicious node and E observes the following values from the other four nodes (A:1000, B: 1010, C: 1020, D: 1030). What are the upper and lower bounds of the aggregated value to which E can manipulate.\n\n1000 - 1005\n1010-1020 [correct bc. median is middle number and you can choose a number between (including borders) 1010 to 1020 and it will be chosen]\n1000 - 1030\nno upper/lower bounds",
		"tags": [ "note"]
},

{
		"title": "DF L4",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l4/",
		"content": "Decentralised Exchange\n(Example LOB Dex)\n\n(Dis) advantages:\n\n+ No KYC/AML\n+ no fees paid to the exchange\n+ no impermanent loss\n- fees for deposit, withdraw, trade creation/cancel\n- slow execution\n- not fully decentralised (mediating server)\n\ntrading volume: around 70 billion (recent months)\nWhy?\n\nSystems Architecture\nAutomated market maker\n#short AMM\n\nLiquidity pool idea: Let a smart contract do the market making. liquidity provider (LP) token:\nformula xâˆ—y=k where x = asset X quantity, y = asset Y quantity, k = constant\nproperties\n\ninstant liquidity, irrespective of the trade size\npurchase of asset X increases price of X and decreases the price of Y\nratio of asset X and Y sets the price\nknown as constant product ( #short CP) AMM\n\n(dis)advantages\n\nno order book maintenance: but arbitrage required\n\nsimple implementation for CP AMM: low gas costs\n\ndanger of impermanent loss/coin de-peg: total loss of funds possible\n\nhigh slippage for low liquidity markets\n\nusers vulnerable to sandwich attacks\n\nExample:\n\nSlippage\n\n(un)expected increase or decrease in price based on trading volume and available liquidity\neffects\n\nworse/better execution price\n\npossible to introduce a slippage protection by configuring a threshold to prevent unacceptable slippage\n\nImpermanent loss\n#short IL\n\nimpermanent == not permanet: realised upon withdraw only\ncan result in total loss\n\ntrading fees may compensate\nliquidity mining may compensate\nsimilar to a de-peg of stablecoin\n\nExchange Transaction propagation\nStablecoin AMM pros/cons\n\nbetter prices for bigger volumes i.e. more liquidity\n\nexample shows significant differences among exchanges\n\npotentially higher gas costs\n\ndanger of a de-peg of a stablecoin\n\npegged/stablecoin prices move in expectation together\n\nexchange rate should ideally remain 1:1\ndefault CP AMM is not optimised for such cases\n\nWhat if a coin gets\n\nde-pug\n\nas bank run in CeFi: no money returned\n&quot;bank run&quot; in DeFi\n\npool may get blacklisted\nfirst come, first served\npool formula penalises destabilising a pool\nincreasingly worse price for late-comers\n\nblacklisted\n\ne.g. USDT and USDC have built-in code to\n\nblacklist addresses\ndestroy coins\ne.g. USDT blacklisted 500+ accounts, destroyed 50M+ USDT\n\nAMM arbitrage\n\nbeginning: multiple markets with\n\nthe same assets X and Y\ndifferent prices for X and Y\n\nprices are synchronised by &quot;arbitrageurs&quot;\n\nthey gain profit from price difference: also referred to as &quot;spread&quot;\nrequires to perform at least one transaction\n\ne.g.\n\narbitrageur can also do it with a flash loan\n\nhow to detect arbitrage/profitable opportunities?\n\nBellman Ford Algorithm\n\nNegative cycle detection\nWorks among multiple markets\nUsed in traditional finance and DeFi\n\nTheorem Solver (SMT tools aim to solve the satisfiability modulo theories ( #short SMT) problem)\n\nNeeds to encode the DeFi model\nApply heuristics for path pruning\n\nSandwich attacks\n\nP1 changes X to Y (value of X decreases and of Y increases)\nP2 changes also X to Y (value of X decreases even more and of Y increases more)\nP1 changes Y to X (gets more X out bc. Y is more valuable then before)\n\nprotection\n\noptimised trade execution\n\n+ simple\n- limited scope\n\ntrusted third party ordering\n\n+ efficient\n- no decentralisation\n\ncommittee ordering\n\n+ fairly efficient\n- reduced decentralisation\n\ncommit &amp; reveal\n\n+ secure\n- costly &amp; delay\n\nQuiz\n\nWhich of the following properties is NOT a desired property for AMM?\n\nno pool fees [correct bc. AMM pool should have some fees]\ninstant liquidity, irrespective of the trade size\npurchase of an asset decreases the asset supply in AMM, and increases its market price\nthe expected increase or decrease in price is based on the trading volume and available liquidity\n\nWhich of the following is a property for a typical on-chain order book?\n\nno fees for order placements\nfront running resistance\nimpermanent loss [there is no impermanent loss in an order book bc. market makers can fill the orders and thus liquidity cannot just be removed; this is rather in an AMM]\nnon-custodian ( #german Verwalter/Aufseher) settlement [correct bc. swapping of assets is non-custodial meaning you own your coins with your private key, there is no custodian doing the settlement]\n\nWhich of the following statements is incorrect\n\nUnexpected slippage can only cause a worse execution price [correct]\nunexpected slippage is caused by price change after a trade has been broadcast but before it has been confirmed\ntrades can configure a slippage protection threshold to limit the total slippage (expected + unexpected)\nThe concept of slippage is typically unavoidable in financial markets\n\nWhat is TURE about impermanent loss?\n\nimpermanent loss cannot result in the total loss of funds.\nTrading fees can never compensate the impermanent loss.\nImpermanent loss is impermanent bc. it's only realised upon a withdrawal from a liquidity pool. [correct]\nImpermanent loss is only a fictive accounting phenomenon and never materialises in a loss.\n\nBack-running describes the process where an adversary attempts to execute its own transaction immediately after the victim's transaction executes. For example, given two exchange markets A and B, both trading ETH/USD at a price of 1000. If a victim's trad (with a as price of 100GWei) is expected to push exchange A's price to 1100 ETH/USD, the adversay can attempt to back-run the victim to perform arbitrage between A and Ab. Which of the following method will have the highest back-running success rate?\n\nBroadcast the back-running transaction immediately after the victim's transaction with 99GWei\nBroadcast the back-running transaction immediately after the victim's transaction, with 100GWei\nSend a private back-running transaction to private relayer services, and bribe the miners to perform the back-run\n(i) broadcast the back-running transaction immediately after the victim with 100GWei, and also (ii) send the transaction to private relayer services and bribe the miners [correct]",
		"tags": ["short", "short", "short", "short", "german", "note"]
},

{
		"title": "DF L5 Lending & Stablecoins",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l5-lending-and-stablecoins/",
		"content": "added multiple things in <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/df-definitions/\">DF Definitions</a>\n\nHow economic machine works\n#video How The Economic Machine Works by Ray Dalio\n\nTransaction: money, credit &lt;=&gt; goods, services, financial assets\n\ntransactions drive economy\nneeds buyers and sellers\n\nspecial actors\n\ncentral bank:\n\ncan print money\nsets interest rates\n\nstate: greatest buyer\n\ncredit\n\nmost important part bc. biggest and most volatile part\nneeds lenders and borrowers\n\nprincipal: amount lend\ninterest: additional amount to pay back for principal\n\ndebt is created with it\ncredit creates spending =&gt; drive economy\nwithout credit: growth can just come from more productivity\nwith credit: growth can come from more productivity and more spending through borrowing/credit =&gt; creates cycle\nbad when it supports overconsumption and cannot be paid bad e.g. big TV\ngood when it efficiently allocates resources e.g. tractor to harvest more crops\n\neconomic growth due to cycle of: (more) income =&gt; borrowing =&gt; spending =&gt; productivity =&gt; ...\ninflation when prices rise\n\ntoo much inflation causes problems =&gt; central bank rises interest rates =&gt; fewer people can borrow money =&gt; borrow less =&gt; less spending =&gt; prices go down =&gt; deflation =&gt; recession =&gt; decrease interest rates =&gt; more borrowing =&gt; inflation =&gt; ...\n\ndeflation when prices decrease\ndeleveraging\n\nworse than recession bc. lowering interest rates doesn't work (not rly. possible to go under 0%)\nbeautiful deleveraging through properly applying counter actions =&gt; debt declines same as income\n\ndeflationary (cut spending and dept + redistribution) and inflationary (printing money) actions are in balance\nincome needs to grow faster than debt grows =&gt; people are creditworthy again\ngrowth is slow but debt shrinks\n\npossible counter actions\n\ncut spending: has opposite effects bc. less spending =&gt; less income (for another person) =&gt; lower wages and unemployment =&gt; can pay back less\n\nand lenders notice that borrowers probably cannot pay back everything =&gt; don't lend anything anymore\n\ncut dept\n\nlenders don't want that and &quot;alternatives&quot; are: less paid back, over longer time frame, reduced interest rate\nalso deflationary bc. everything loses value and so borrowers still, also with less debt, won't have enough to pay back (even less)\n\nredistribution: government has to pay for unemployment and want's to set economic stimulus =&gt; needs more money generally tries to raise taxes for wealthy (bc. wealth is concentrated), but wealthy don't like that too much...\n\nrevolution/class conflict evolves =&gt; maybe army and/or (strong) political change e.g. Hitler after 1930s in Germany\n\nprint money: last alternative bc. interest rates are already lowered as much as possible\n\ninflationary and stimulates economy\nto buy financial assets and government bonds\n\njust helps those who own financial assets bc. central bank can only buy financial assets\n\ncentral bank can cooperate with central government through buying government bonds to spend money on goods and services =&gt; money for people\n\nvery risky\n\ndoesn't have to result in inflation, when credit shrinks the same amount and thus spending is not higher\n\nreflation (after deleveraging)\n\nca. 7-10 year (lost decade) (maybe just after a &quot;beatauiful&quot; deleveraging)\n\nLecture (graphics)\n\neffects one-by-one\neffects combined\n\nLending\nOn-Chain lending &amp; borrowing\n\nFlash loan\n\nflash loan should be taken and repaid in one single transaction\n\nnot directly time bound rather has to happen within one block building process\nif it cannot be paid back =&gt; entire transaction is invalid\n\nlender is secure\n\nUse cases\n\nDeFi attacks\n\nprice oracle manipulation\npump and dump (buy another coin to make them look like as more valuable/have more transactions for a short amount of time)\n\n(risk-free) arbitrage\nwashtrading\nflash mining\ncollateral swapping\nliquidation\n\nwhen liquidator doesn't have cryptocurrency upfront to repay\nonly works when liquidation completes in one transaction\ne.g.\n\nLiquidation\nin traditional finance\n\npass resolution for voluntary liquidation can be done by board of executives\nadministration of liquidation are e.g. the not paid electricity bills\ntakes a long time maybe even years\n\nFixed spread liquidation\n\ncan be completed in 1 transaction\nrepays debts of borrowing position\nacquires collateral at a discounted price from the position in return\n\ntypically discounts are e.g. 5-15% (called fixed spread) in Aave ( #disclaimerN probably meant average with it)\n\nprice oracles for getting prices: on and off chain oracles possible/depending on currency\n\nQuiz\n\nHow long does a flash loan last?\n\nDuring one block\nDuring one transaction [correct]\nFrom transaction signature until the transaction is mined\nas long as you want\n\nWhat is TRUE?\n\nLiquidations are typically done optimally.\nThe close factor is the minimum proportion of debt that can be repaid in a liquidation. [false bc. it's the maximum proportion... and you can also liquidate less]\nA flash loan has no fees\nTransaction fees for a flash loan are on the order of 100 USD, even if the loan amounts can grow beyond 1B USD. [correct]\n\nWhat can flash loans be used for?\n\nWashtrading [correct]\npumping a coin [false bc. you can just do pumping and dumping together, not individually]\ndumping a coin\nforking a blockchain\n\nWhich of the following liquidation strategies best describes an optimal fixed spread liquidation strategy?\n\nthe liquidation first performs an oracle price update, and then atomically performs the liquidation\nthe liquidator liquidates the position up to the close factor (when the close factor drops below 1, the position becomes available for liquidation)\nperform two liquidations. The first one keeps the close factor below 1, such that the second liquidation can also successfully execute [correct ]\nperform three liquidations, two keeping the CF below 1, while the last one also successfully executes\n\nWe define a borrowing position as a bad debt if it is financially rational for neither the borrowers nor the lending platform to close the position. Which of the following is not a cause for bad debt?\n\nif the collateral value falls below the value of the debt.\nif the value of excess asset used for over-liquidation cannot cover the liquidation transaction fee.\nif the debt has not been repaid for a long time. [correct bc. time component has no impact on bad dept]\nif the value of the debt grows more than the value of the collateral.",
		"tags": ["video", "disclaimerN", "note"]
},

{
		"title": "DF L6",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l6/",
		"content": "Economic models\n\nrepresents (often simplifies) an economic process\ncontains <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/df-l6/#variables\">#Variables</a>\nlogical/quantitative relationships between variables\nexample: inflation\n\nmeasuring inflation requires a behaviour model bc. it depends on behaviour of individuals e.g. what/how much food they buy =&gt; how money is used\ndifferentiate relative vs. inflation price change\n\nVariables\n\nInterest rate(s) in CeFi and DeFi\ncryptocurrency price\ncollateral ratio\nDeFi protocol fees\nblockchain transaction fees\nnumber of users\nblockchain transaction throughput\n...\n\nExogenous vs. endogenous\n\nExogenous variable == outside force\n\ndetermined outside model, imposed on model\ne.g. in MakerDAO, asset price of collateral (e.g. ETH), is independent of the MakerDAO system\n\nEndogenous variable == inside the model\n\nStablecooins\nTypes\n\nTypes\n\nReserved-based e.g. USDC by a bank\ncollateral-based: e.g. MakerDAO\nalgorithmic e.g. AMPL\n\nMakerDAO\n\nto be profitable: assumption that ETH goes up and you can get even more with this DAI =&gt; with drawn DAI get even more ETH =&gt; later change back and have more in all\n\nAmpleforth\n#short AMPL\n\nsystemic implications #ToDo don't know yet\n\nUSDC and USDT\n\ndestroys coins\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/decentralised-finance/#bank-run\">Decentralised Finance#Bank run</a>\n\nQuiz\n\nWhich stable coin is the most stable? ( #remarkN atm)\n\nUSDC [correct]\nDAI\nAMPL\nETH\n\nWhich of the following statements is False?\n\nSeveral algorithmic stablecoins have depegged.\nDAI is a collateral based stablecoin, where e.g. ETH is used as collateral\nWBTC token prices should be pegged to BTC price\nETH is more stable than USDC [correct]\n\nWhat happens in AMPL system when 1 AMPL is worth less than 1 USD\n\nThe supply of AMPL is increase (expansion)\nThe supply of AMPL is decreased (contraction) [correct: if AMPL is more scarce, it should be worth more =&gt; less difference to USD]\nno action is taken (equilibrium)\nadditional collateral is required\n\nHow does the AMPL stablecoin reduce or increase the account balances of the token holders?\n\nThe ERC20 contract controls the balances and can modify them. [correct]\nThe ERC71 contract controls the balances and can modify them.\nevery user must individually approve each account balance change before rebalancing\nAMPL rebalances the token supply through arbitrage with USDC.\n\nIf the reserve ratio of a bank is 0.2 and the total money deposited by bank customers is $500,000, how much money is held by the bank?\n\n$100,000 [correct bc. 0.2 = 100'000/500'000 or 0.2 * 500'000 = 100'000]\n$250,000\n$400,000\n$1,000,000",
		"tags": ["Variables", "short", "ToDo", "remarkN", "note"]
},

{
		"title": "Decentralised Finance",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/decentralised-finance/",
		"content": "Promises\n\nInclusivity and Access:\n\nprovide financial services to individuals globally, including those who are unbanked or underbanked\npotentially bridge the gap between traditional financial systems and individuals who lack access to banking services\n\nPermissionless Innovation:\n\nplatforms are often open-source and permissionless, allowing developers to create and deploy financial applications without requiring approval from centralized authorities =&gt; rapid innovation and the creation of diverse financial products\n\nReduced Costs:\n\neliminating intermediaries and automating processes through smart contracts\npotential to reduce transaction costs associated with traditional financial services, such as remittances, loans, and trading\n\nDecentralized Identity and Privacy:\n\nleverage decentralized identity solutions, enhancing user privacy and reducing the reliance on centralized entities for identity verification\nUsers can control access to their personal information\n\nFinancial Empowerment:\n\nempower individuals by providing them with greater control over their financial assets\nUsers have custody of their private keys and can engage in financial activities without relying on traditional intermediaries\n\nTransparency: Blockchain technology, provides transparency by allowing users to trace transactions on a public ledger =&gt; enhance trust and accountability within the financial system\nInteroperability: platforms often operate on open and interoperable blockchain networks =&gt; allows different DeFi applications to seamlessly integrate with each other, creating a more interconnected and efficient financial ecosystem\nLiquidity Provision: platforms often use decentralized exchanges and liquidity pools, allowing users to provide liquidity and earn returns =&gt; creates new opportunities for individuals to participate in the financial ecosystem\n\nBank run\n\nin CeFi\n\ndangerous if fractional reserve\nmost clients don't receive assets\n\nin DeFi\n\nevent: USDT blacklists a pool, stablecoin de-pegs\ntraders will exit pools\nthose who exit first receive the best prices\ntry to build blacklist detection bots",
		"tags": [ "note"]
},

{
		"title": "Financial Markets",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/financial-markets/",
		"content": "Some things\nWhy?\nFinancial market serves several purposes, including:\n\nRaising capital: The financial market provides a platform for companies and governments to raise funds from investors in the form of equity or debt, which can be used to finance their operations or investment projects.\nPrice discovery: The financial market facilitates the determination of the prices of financial assets, based on the supply and demand of these assets. This price discovery process helps investors and market participants make informed investment decisions.\nLiquidity: The financial market provides liquidity to investors, allowing them to easily buy and sell financial assets such as stocks, bonds, and currencies. This enables investors to quickly and easily adjust their portfolios in response to changing market conditions.\nRisk management: The financial market allows investors to hedge against risks such as market volatility, inflation, and interest rate changes, by trading financial instruments such as options, futures, and swaps.\nEconomic growth: The financial market plays a crucial role in promoting economic growth by providing capital to companies and governments, which can be used to finance new projects and create jobs. This, in turn, can lead to increased economic activity and higher standards of living for individuals.\n\nMain stakeholders\n\nInvestors: Investors are individuals or entities who provide capital to companies and governments in exchange for financial assets, such as stocks, bonds, and other securities. Investors can be individual or institutional, such as pension funds, insurance companies, and mutual funds.\nIssuers: Issuers are companies or governments that offer financial assets to investors in order to raise capital. Issuers can issue debt in the form of bonds or equity in the form of stocks.\nIntermediaries: Intermediaries are entities that facilitate the trading of financial assets between investors and issuers. Examples of intermediaries include banks, broker-dealers, and stock exchanges.\nRegulators: Regulators are government agencies that oversee the financial market to ensure that it operates fairly and efficiently. Regulators set rules and guidelines for financial institutions and investors, and monitor the market to detect and prevent fraud and misconduct.\nMarket data providers: Market data providers are entities that collect and disseminate information about the financial market, including prices, trading volume, and other market data. This information is used by investors, issuers, and regulators to make informed decisions about the market.\n\nUnderlying assumptions from Economics\n\n(1) Rational Expectations: Based on perfect information\n\nEconomic actors will not make systematic mistakes in predicting the future (risks)\nEveryone uses the Â«rightÂ» model for forecasting\nThe future can be inferred from the past and present\n\n(2) Efficient Financial Market Theory: Asset prices represent the best possible estimates of the risks attached to them\n\nThe risk characteristics from financial markets can be inferred from mathematical analysis.\nMarket discipline can be used as an efficient tool in constraining harmful risk taking. Markets are self-correcting.\n\nWhy vulnerable?\nThe financial market is vulnerable to a variety of factors and risks, including:\n\nSystemic risks: These are risks that affect the entire financial system, rather than individual institutions or investors. Systemic risks can arise from a variety of sources, such as market volatility, geopolitical events, or regulatory changes.\nMarket risks: Market risks refer to the risk of losses due to changes in market conditions, such as changes in interest rates, exchange rates, or commodity prices.\nCredit risks: Credit risks refer to the risk of default by borrowers or issuers of debt securities. This can be due to factors such as financial distress, economic downturns, or changes in the creditworthiness of borrowers.\nOperational risks: Operational risks refer to the risk of losses due to internal failures of financial institutions, such as fraud, errors, or system failures.\nLiquidity risks: Liquidity risks refer to the risk that investors will not be able to buy or sell financial assets at fair market value due to a lack of market liquidity. This can lead to losses or a decrease in portfolio value.\nCybersecurity risks: With the increasing use of technology in the financial market, cybersecurity risks have become a significant concern. Cyber attacks on financial institutions can lead to the loss of sensitive data, financial theft, and disruption of market activity.\nOverall, the financial market is vulnerable to a wide range of risks, and investors and financial institutions must take steps to manage these risks in order to protect themselves and the broader financial system.",
		"tags": [ "note"]
},

{
		"title": "Unit type",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/atoms/unit-type/",
		"content": "#source #wikipedia Unit type\n\nIn the area of mathematical logic and computer science known as type theory, a unit type is a type that allows only one value (and thus can hold no information)\n\nProgramming languages\nHaskell\n\nThe () type can be thought of as a zero-element tuple. It's a type that can only have one value, and thus it's used where you need to have a type, but you don't actually need to convey any information. Here's a couple of uses for this.\n- #stackoverflow Neil Brown on StackOverflow\n\n#stackoverflow Longer explanation, also on types and expression language, besides ()",
		"tags": ["source", "wikipedia", "stackoverflow", "stackoverflow", "note"]
},

{
		"title": "FMFP Interpreters",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/fmfp-interpreters/",
		"content": "conceptually simple: read =&gt; evaluate =&gt; print\nconcretisation less trivial:\n\nMini-Haskell interpreter\nParsing\n\nparser constructs an abstract syntax tree ( #short AST)\n\nin Haskell: element of data type\nfurther processing depend on application but in general: conversion happens between data types e.g.\n\nCompiler: AST â†’ CODE\nCalculator: AST â†’ Int\nMini-Haskell: AST â†’ AST\n\nin ghci there are additional phases such as dependency analysis, type checking, ...\n\nCombinatory parsing\n\nIdea: modular construction and composition of parser functions\n\nuses lazy &amp; higher-order programming\nuses monads to package &quot;higher-order plumbing&quot;\n\nParser type\n\nparser is a function taking a string as input\nresult is an element of type a (typically a data type like Expr)\nparser may process only part of input, leaving a remainder\n\nsupport composition: pparses first part and q continues\n\nallow multiple results from parsing via list of successes\n\ndata Parser a = Prs (String -&gt; [(a,String)])\n\nparse::Parser a -&gt; String -&gt; String -&gt; [(a,String)]\nparse (Prs p) inp = p inp\n\n-- interested in result of first complete parse\ncompleteParse :: Parser a -&gt; String -&gt; a\ncompleteParse p inp\n\t| results == [] = error &quot;Parse unsuccessful&quot;\n\t| otherwise = head results\n\twhere results = [res | (res,&quot;&quot;) &lt;- parse p inp]\n\ncomplete parse if pair with remainder &quot;&quot;\n\nprimitive parsers\n\nserving as basic building blocks\n\n-- Fails trivially ([] signifies â€˜unsuccessful parseâ€™):\nfailure :: Parser a\nfailure = Prs (\\inp -&gt; [])\n\n-- Succeeds trivially without progress:\nreturn :: a -&gt; Parser a\nreturn x = Prs (\\inp -&gt; [(x,inp)])\n\n--Succeeds trivially with progress:\nitem :: Parser Char\nitem = Prs (\\inp -&gt; case inp of\n\t\t\t\t\t\t&quot;&quot; -&gt; []\n\t\t\t\t\t\t(x:xs) -&gt; [(x,xs)])\n\n-- Parse a single character with property p\nsat :: (Char -&gt; Bool) -&gt; Parser Char\nsat p = Prs (\\inp -&gt; case inp of\n\t\t\t\t\t\t&quot;&quot; -&gt; []\n\t\t\t\t\t\t(x:xs) -&gt; if p x then [(x,xs)] else [])\n\n--Chars and Strings (including simpler definition of sat)\nsat :: (Char -&gt; Bool) -&gt; Parser Char\nsat p = item &gt;&gt;= \\x -&gt; if p x then return x else failure\n\nchar :: Char -&gt; Parser Char\nchar x = sat (==x)\n\nstring :: String -&gt; Parser String\nstring &quot;&quot; = return &quot;&quot;\nstring (x:xs) = char x &gt;&gt; string xs &gt;&gt; return (x:xs)\n\n-- Repetition\nmany :: Parser a -&gt; Parser [a] -- 0 or more repetitions of p\nmany p = many1 p ||| return []\n\nmany1 :: Parser a -&gt; Parser [a] -- 1 or more repetitions of p\nmany1 p = p &gt;&gt;= \\t -&gt; many p &gt;&gt;= \\ts -&gt; return (t:ts)\n\n-- more readable use of &gt;&gt;-\nmany1 p = do t &lt;- p\n\t\t\t ts &lt;- many p\n\t\t\t return (t:ts)\n\nnumPos :: Parser Int\nnumPos = do ts &lt;- many1 (sat isDigit)\nreturn (read ts) --- read maps numeric string to number\n\nnumNeg :: Parser Int\nnumNeg = do char â€™-â€™\n\t\t\tt &lt;- numPos\n\t\t\treturn (-t)\n\t\t\t\nnum :: Parser Int\nnum = numPos ||| numNeg -- or: numPos +++ numNeg\n\nGluing parsers together\n-- Mutual selection: Apply both first and second parser\n(|||) :: Parser a -&gt; Parser a -&gt; Parser a\np ||| q = Prs (\\s -&gt; parse p s ++ parse q s)\n\n-- Alternative selection: If first parser fails, apply second parser\n(+++) :: Parser a -&gt; Parser a -&gt; Parser a\np +++ q = Prs (\\s -&gt; case parse p s of\n[] -&gt; parse q s\n\n-- Sequencing: first parser p then parser q to results\n(&gt;&gt;) :: Parser a -&gt; Parser b -&gt; Parser b\np &gt;&gt; q = Prs (\\s -&gt; [ (u,sâ€™â€™) | (t,sâ€™) &lt;- parse p s,\n\t\t\t\t\t\t\t\t(u,sâ€™â€™) &lt;- parse q sâ€™ ])\n-- but above results of first parser (t above) is lost bc. we just use the remainder further\n-- Solution: use as second argument a â€œparser generatorâ€ that takes as input the result of the first parser\n(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b\np &gt;&gt;= g = Prs (\\s -&gt; [ (u,sâ€™â€™) | (t,sâ€™ ) &lt;- parse p s,\n\t\t\t\t\t\t\t\t (u,sâ€™â€™) &lt;- parse (g t) sâ€™ ])\n\nambiguous grammars\n\nProblem: How should 2-3+4 be parsed?\nSolution\n\ndisambiguate grammar using associativity and precedence\ngive user ability to override defaults using parentheses\ncareful: left-recursive grammars lead to non-terminating recursion\n\nConcrete\n\nparse repeated operation/atom pairs after initial atom\nobtain left associativity using fold-left over list of these pairs\nuse concrete grammar to build abstract syntax tree of type data Expr = Lit Int | Add Expr Expr | Sub Expr Expr\n\nÎ»-calculus\n\nprograms are terms\nformalising core\n\nenough to construct all others\n\nParsing Î»-terms\n\ndata type for Î»-calculus terms\n\ndata Term = Id String | Ap Term Term | Lam String Term\n\t\t\tderiving Show\n\natom = ident ||| lamb ||| paren\n\nident = do id &lt;- identifier\n\t\t\treturn (Id id)\n\nterm= do t &lt;- atom -- t\n\t\tts &lt;- many atom -- [t1 t2 ... tn]\n\t\treturn (foldl Ap t ts)-- Ap(Ap(Ap(t t1) t2) ... tn)\n\nlamb= do token &quot;%&quot;\n\t\t ids &lt;- many1 identifier -- [x1, x2, ..., xn]\n\t\t token &quot;.&quot;\n\t\t t &lt;- term -- t\n\t\t return (foldr Lam t ids) -- Lam x1 (Lam x2 (...(Lam xn t)))\n\nparen = do token &quot;(&quot;\n\t\t t &lt;- term\n\t\t token &quot;)&quot;\n\t\t return t\n\nstr2term s = completeParse term s\n\napplication t1t2 produces left recursion (prefix-syntax simpler)\nsyntax without left-recursion\n\nWe use % and . instead of \\ and -&gt;, respectively\nExplicit parentheses\nEvery parsing starts with an identifier, or symbols â€˜%â€™ or â€˜(â€™\n\nExamples\n\nSubstitution in Haskell\n\nmust respect free and bound variables\n\ne.g.\n\nHaskell implementation below (Alternative: use Haskell library Data.Set to implement free)\n\nfree :: Term -&gt; [String]\nfree (Id v) = sing v -- free (x) = {x}\nfree (Ap s t) = union (free s) (free t) -- free (M N ) = free(M ) âˆª free(N )\nfree (Lam v t) = diff (free t) (sing v) -- free (Î»x. M ) = free(M ) \\ { x }\n\nempty = []\nsing a = [a]\n\nmember [] _ = False\nmember (x:xs) a\n\t| x &lt; a = member xs a\n\t| x == a = True\n\t| otherwise = False\n\nunion [] ys = ys\nunion xs [] = xs\nunion (x:xs) (y:ys)\n\t| x &lt; y = x : union xs (y:ys)\n\t| x == y = x : union xs ys\n\t| otherwise = y : union (x:xs) ys\n\ndiff [] _ = []\ndiff xs [] = xs\ndiff (x:xs) (y:ys)\n\t| x &lt; y = x : diff xs (y:ys)\n\t| x == y = diff xs ys\n\t| otherwise = diff (x:xs) ys\n\n-- subst t v s = t[v -&gt; s]\nsubst :: Term -&gt; String -&gt; Term -&gt; Term\nsubst (Id x) v s = if x == v then s else Id x\nsubst (Ap t1 t2) v s = Ap (subst t1 v s) (subst t2 v s)\nsubst (Lam x t) v s\n\t| x == v = Lam x t\n\t| not (member (free s) x) = Lam x (subst t v s)\n\t| otherwise = Lam z (subst (subst t x (Id z)) v s)\n\twhere z = fresh (union (free t) (free s))\n\t\tfresh m = (foldr max &quot;&quot; m) ++ &quot;â€™&quot; -- returns id not in m\n\nSubstitution\nÎ²-reduction\n\nÎ²-reduction is rule for simplifying redexes: (Î»x.M)Nâ†ªM[xâ†¦N]\n\nredex is a term like (Î»x.M)N\ncontractrum is the result i.e. M[xâ†¦N]\n\ne.g. (Î»x.f(xx))Nâ†ªf(NN)\n\nEvaluation strategies\n\nt1t2 represents the first application of a function to an argument\n\nfirst evaluate t1:t1â†ªr1\nIf r1â‰ Î»x.r then throw an exception (or return application)\n\nstrategy 1: Eager\n\nevaluate t2 prior to Î²-reduction: t2â†ªr2 meaning (Î»x.r)r2â†ªr[xâ†¦r2]\nevaluation carried out under an abstraction (Î»x.t)\n\nstrategy 2: Lazy\n\napply Î²-reduction to r1t2 i.e. substitute t2 without evaluation meaning (Î»x.r)t2â†ªr[xâ†¦t2]\nno evaluation under an abstraction\nresult of Î²-reduction is then further evaluated\n\nbeta (Lam x t) tâ€™ = subst t x tâ€™\neager :: Term -&gt; Term\neager (Id x) = (Id x)\neager (Ap t tâ€™) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; eager (beta r râ€™)\n\t\t\t\t\t_ -&gt; Ap r râ€™\n\twhere r = eager t\n\t\t râ€™ = eager tâ€™\neager (Lam x t) = Lam x (eager t)\n\nlazy :: Term -&gt; Term\nlazy (Id x) = (Id x)\nlazy (Ap t tâ€™) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; lazy (beta r tâ€™)\n\t\t\t\t\t_ -&gt; Ap r tâ€™\n\twhere r = lazy t\nlazy t = t -- no evaluation under a lambda abstraction\n\neager evaluation in lazy language\n\nHaskell is lazy and doesn't fully evaluate omega, since not needed to produce result\nsolution: use strict function application f $! x is like f x but forces evaluation of its argument x (up to first constructor)\n\neager :: Term -&gt; Term\neager (Id x) = (Id x)\neager (Ap t tâ€™) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; eager ((beta $! r) $! râ€™)\n\t\t\t\t\t_ -&gt; (Ap $! r) $! râ€™\n\twhere r = eager t\n\t\t râ€™ = eager tâ€™\neager (Lam x t) = Lam x $! (eager t)\n\nMore on Haskell and interpreters",
		"tags": ["short", "note"]
},

{
		"title": "Haskell",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/haskell/",
		"content": "operators\n\nhave diff. binding strength e.g.\n\n^ binds stronger than + see ? 2 + 3^2 =&gt; 11\nnot stronger than &amp;&amp; and ||\n\norder and equality return True or False of type Bool\n\nsame as in other programming languages but\n\n/= unequal\n\nTypes\nInt\n\nInt type with at least the range {âˆ’229,â€¦,229âˆ’1}\n\nsupport for unbounded and arithmetic: Integer\n\nbool\n\nvalue: True, False\n\nChar\n\ne.g. 'a','0','\\t'\n? ord 'a' =&gt; 97 or ? chr 97 =&gt; 'a'\n\nString\n\ne.g. &quot;hello&quot;, &quot;123&quot;\n? &quot;Hello &quot; ++ &quot;there&quot; =&gt; &quot;Hello there&quot;\n\nDouble\n0.3456, -2.85e03\nTuple\n\nused to model composite objects (&quot;records&quot;)\nexample of a type constructor\n\nif T1,â€¦,Tn are types, then (T1,â€¦,Tn) is a (tuple) type\n\nList\n\nIf T is a type then [T] is a type\nempty list: []::[T]\nnon-empty list (x:xs)::[T] if x::T and xs::T\nabbreviations\n\n? [3..6] =&gt; [3,4,5,6]::Int\n`? [6..3] =&gt; []::Int\n[n, p..m] means count from n to m in steps of pâˆ’n\n\n? [7,6..3] =&gt; [7, 6, 5, 4, 3] :: [Int]\n? [0.0, 0.3 .. 1.0] =&gt; [0.0,0.3,0.6,0.8999999999999999] :: [Double]\n\nx:[y] appends an element x to a list [y]\n[x]++[y] concatenates two lists\n\nDifference lists\n\nfunction [a] -&gt; [a] that prepends a list to its argument\ne.g.\nimplementation\n\nOwn types\n\ntypes always start with a capital letter\ntype Person = String\ntype Database = [(Person,Book)]\n\nClass\n\ndefines a set of types\nelements of the class are called instances\n\nExamples\nallEqual :: Eq t =&gt; t -&gt; t -&gt; t -&gt; Bool -- where Eq is a class\n\nFunctions\n\nif argument doesn't matter use _ e.g. f a _ = a for f :: Int -&gt; Int -&gt; Int\nevaluation by\ngeneric type definition possible e.g. ownLength :: [a] -&gt; Int where a is the generic type\ndo when function has side-effects e.g. in IO\nown e.g.\n\nsumList::[Int] -&gt; Int\nsumList [] = 0 -- also handle the empty list case\nsumList (x:xs) = x + sumList xs\n\nstandard ones:\n\nlength\nappend\n[2] ++ [3,4,5] =&gt; [2,3,4,5]\n? 2 : [3,4,5] =&gt; [2,3,4,5] but ? [2] : [3,4,5] =&gt; Error\n\nHow to use\nInfix binary\nInfix binary function is also called an &quot;operator&quot; ? 7 'mod' 2\nprefix\nOperators can also be written in prefix notation: ? (+) 3 4\nExamples\n\n(e.g. for Int) +, * , ^, -, div, mod, abs\n\nevaluate by ? mod 7 2 =&gt; 1\n\nbranches\n\nif test then a else b\n\na and b have to be of same type\n\nmulti case\n\ndefined using other operators: f x y = (x || y) &amp;&amp; not (x &amp;&amp; y)\ndefined using guards\n\nf x y\n| x = not y\n| otherwise = y\n\ndefined using multiple cases (new)\n\npriority from above down\nexception, if one case is not covered but it's used\n\nf True True = False\nf True False = True\nf False True = True\nf False False = False\n\ncases can contain variables\n\nf True y = not y\nf False y = y\n\nf 0 = 1\nf 1 = 2\nf x = x*x\n\nAdvice on recursion\n\nDefining recursive functions is like riding a bicycle: it looks easy when someone else is doing it; it may seem impossible when you first try to\ndo it yourself, but becomes simple and natural with practice.â€\n- G. Hutton, Programming in Haskell\n\nHigher-order functions\n\njust higher order, if function takes function(s) as input\n\nÎ»-expression\n\nfor writing functions in-line\n\ngood for when functions are just used once and rather short\n\nInput-Output\n-- putStrin :: String -&gt; IO()\n\n-- getLine :: IO String\n\n-- read String :: t, where t is a type and it tries to convet String to this type\n\n-- show a =&gt; String of a\n\nfunc1 = do\nputStrLn &quot;Test&quot;\nn &lt;- getLine\nputStrLn (&quot;Text: &quot; ++ show (func2 (read n :: Int)))\n\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Monads#Input/Ouput</a>\n\nOther\nShell\n\nghci: open\n:load name-of-file.hs load modules from file\nreload loads last file again (e.g. after changing functions)\n\nLazy Evaluation\n\nHaskell uses Lazy evaluation\npossible problem of lazy evaluation is duplicated computation: avoided by simultaneously reducing both occurrences\nSummary: function arguments are evaluated only when needed and at most once\n\nCool applications\n\ncompute with infinite data in finite time\nimplementation of sieve of Eratosthenes\n\n2D layout\n\nspaces are important don't use TABs (in modern IDEs it should be okay, but this maybe a reason for an erroneous program)\nindentation determines separation of definitions\n\nall function definitions must start at same indentation level\nif a definition requires n &gt; 1 lines, indent lines 2 to n further\nrecommended layout\n\nPatterns\n\npurposes\n\nchecks if argument has proper form\nbinds values to variables\n\nRules\n\npatterns are inductively defined\npattern required to be linear i.e. each variable can occur at most once\nExamples: [(x,foo),_] , ((x,y),_) , 1:(2:(x,y))\nCounterexamples: (x ++ y, z) , [x,y,z,x]\n\nList comprehension\nNotation for sequential processing of list elements\n\nanalogous to set comprehension in set theory {2â‹…x|xâˆˆX}\nHaskell notation [2*x| x &lt;- xs]\ncan be augmented with guards: [2*x | x &lt;- xs, pred1(x), ...]\n\nExamples\n\n(x:xs) matches with [2,3,4] as x=2 and xs=[3,4]\n? let ([x,y,z],t) = ([1,2,3],(20,30)) in x + y =&gt; 3 :: Int\n? [2*x | x &lt;- [1,2,3,4,5]] =&gt; [2,4,6, 8, 10]\n? [n â€˜modâ€˜ 2 == 0 | n &lt;- [2,4,7]] =&gt; [True,True,False]\n? [2*x | x &lt;- [0,1,2,3,4,5,6], x â€˜modâ€˜ 2 == 0, x &gt; 3] =&gt; [8,12]\neasy quick sort^^\n\nq [] = []\nq (p:xs) = q [x | x&lt;-xs, x &lt;= p] ++ [p] ++ q [x | x&lt;-xs, x &gt; p]",
		"tags": [ "note"]
},

{
		"title": "FMFP L1",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l1/",
		"content": "Functional programming\n\nbasic concepts\n\nfunction (which are values itself) #aka first order citizens\nvalues\n\nexample programming languages: Haskell\n\nAdvantages\n\neasier to reason about bc. no state (changes) anymore\n\nno side effects\n\nreferential transparency every expression with same values evaluate to same expressions\nrecursion instead of iteration\nFlexible type system: many programming errors not possible (compile time error) e.g. 3 + TRUE, polymorphism supports reusability",
		"tags": ["aka", "note"]
},

{
		"title": "FMFP L10",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l10/",
		"content": "algebraic data types\n\ndata types defines a set of terms for each type instance e.g. Tree Int correspons to {Leaf, Node 0 Leaf Leaf, ...}\nalgebraic here means the smallest set S where LeafâˆˆS and xâˆˆaâˆ§t1âˆˆSâˆ§t2âˆˆSâŸ¹(NodeÂ xt1t2)âˆˆS\nIntuition: set S is built in steps\n\nLeafâˆˆS and\n(Nodext1t2)âˆˆS, where t1 and t2 in S in earlier steps\n\nStructural induction",
		"tags": [ "note"]
},

{
		"title": "WS L1",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l1/",
		"content": "Definitions\n\n[!info] #Def 1.2 Grundraum ( #aka Ereignisraum) ( #english sample space)\nÎ©â‰ âˆ… ist die Menge alle mÃ¶glichen Ergebnisse des betrachteten Zufallsexperiments.\n\nDie Elemente wâˆˆÎ© heissen Elementarereigniss #aka AusgÃ¤nge des Experiments #english outcomes\nWir sagen, dass ein Ereignis A eintritt, falls das realisierte Elementarereignis Ï‰ in A liegt d.h. Ï‰âˆˆA\n\n[!info] #Def 1.4 Die Potenzmenge ( #english power set)\nvon Î©, P(Î©) oder 2Î©, ist die Menge aller Teilmengen von Î©.\n\nEin prinzipielles Ereignis ( #english event) ist eine Teilmenge AâŠ†Î©, also eine Kollektion von Elementarereignissen\nDie Klasse aller (beobachtbaren) Ereignisse bezeichnen wir mit F. Das ist eine Teilmenge der Potenzmenge von Î©\n\nFalls Î© endlich oder abzÃ¤hlbar, dann ist oft F=P(Î©), und das ist ein diskreter Wahrscheinlichkeitsraum.\nFalls Î© Ã¼berabzÃ¤hlbar, muss F eine echte Teilklasse von P(Î©) sein\nIn jedem Fall muss F gewisse Axiome erfÃ¼llen\n\n[!Info] #Def 1.5 Ïƒ-Algebra (manchmal Ïƒ-field)\nEin Mengensystem FâŠ†P(Î©) nennt man eine Ïƒ-Algebra, wenn\n\nÎ©âˆˆF\nfÃ¼r jedes AâˆˆF auch das Komplement AâˆâˆˆF ist\nfÃ¼r jede Folge (An)nâˆˆN mit AnâˆˆF,nâˆˆN, auch die Vereinigung âˆªnâˆˆNAnâˆˆF ist\n\n[!info] #Def 1.9 Wahrscheinlichkeitsmass ( #english probability measure)\nSei Î© ein Grundraum und sei F eine Ïƒ-Algebra. Eine Abbildung\nP:Fâ†’[0,1],mitÂ Aâ†¦P[A]heisst Wahrscheinlichkeitsmass auf (Î©,F), wenn die folgenden Axiome erfÃ¼llt sind\n\nNormiertheit: P[Î©]=1\nÏƒ-AdditivitÃ¤t: P[âˆªnâˆˆNAn]=âˆ‘n=1âˆP[An] fÃ¼r paarweis disjunkte Mengen An, d.h. Anâˆ©Am=âˆ… fÃ¼r alle nâ‰ m\n\n[!info] #Proposition 1.10\nFÃ¼r ein Wahrscheinlichkeitsmass P auf (Î©,F) und Mengen A,BâˆˆF gelten folgende Aussagen:\n\nP[Aâˆ]=1âˆ’P[A], und insbesondere P[âˆ…]=0\nMonotonie: wenn AâŠ†B, dann P[A]â‰¤P[B]\nAdditionsregel: P[A]+P[B]=P[AâˆªB]+P[Aâˆ©B]\n\n[!info] #Def 1.12 Wahrscheinlichkeitsraum\nSei Î© ein Grundraum, F eine Ïƒ-Algebra und P ein Wahrscheinlichkeitsmass auf (Î©,F). Das Tripel (Î©,F,P) heisst Wahrscheinlichkeitsmass ( #english probability space)\n\n[!info] #disclaimer 1.13 Messbarer Raum ( #english measurable space)\nAllgemein verwenden wir in der Masstheorie folgende Terminologie:\n\nFÃ¼r eine Ïƒ-Algebra A auf einer Grundmenge Î© wird das Paar (Î©,A) ein messbarer Raum genannt.\nElemente AâˆˆA, also Teilmengen AâŠ‚Î©, die wir messen wollen, heissen messbare Mengen ( #english measurable sets).\nAuf messbaren RÃ¤umen (bzw. den Ïƒ-Algebren) lassen sich Masse ( #english measures) Î¼ definieren. Diese sind im Allgemeinen nicht auf 1 nomiert. Man verlangt staddessen Î¼(âˆ…)=0.\nDas Tripel $(\\Omega,\\cal{A},\\mu) $ heisst Massraum ( #english measure space).\nIst das Mass normiert, Î¼(Î©)=1, dann ist das Mass ein Wahrscheinlichkeitsmass und der Messraum wird zum Wahrscheinlichkeitsraum.\n\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Diskrete Wahrscheinlichkeit</a>",
		"tags": ["Def", "aka", "english", "aka", "english", "Def", "english", "english", "Def", "Def", "english", "Proposition", "Def", "english", "disclaimer", "english", "english", "english", "english", "note"]
},

{
		"title": "WS L2",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l2/",
		"content": "[!info] #Def 1.22 Bedingte Wahrscheinlichkeit\nGegeben: Wahrscheinlichkeitsraum (Î©,F,P), P[B]&gt;0\nDann ist P[A|B]:=P[Aâˆ©B]P[B]\n\nP[A|A]=1\nP[A|Î©]=P[A]\nP[Aâˆ©B]=P[A|B]P[B]\nP[A|B] ist nicht definiert fÃ¼r P[B]=0\n\n[!info] #Theorem 1.25\nGegeben: Wahrscheinlichkeitsraum (Î©,F,P),P[B]&gt;0\nDann ist Pâˆ—:Fâ†’[0,1] definiert durch Aâ†¦Pâˆ—[A]:=P[A|B] wieder ein Wahrscheinlichkeitsmass auf (Î©,F)\n\nbedingte Wahrscheinlichkeit ist nicht symmetrisch in den beiden Argumenten. Insbesondere ist bei fixiertem Ereignis A die Funktion Bâ†¦P[A|B] kein Wahrscheinlichkeitsmass\nIst Î© endlich oder abzÃ¤hlbar mit F=P(Î©), dann ist P gegeben durch die Wahrscheinlichkeiten pn=P[{Ï‰n}]. Das bedingte Wahrscheinlichkeitsmass Pâˆ—[â‹…]=P[â‹…|B] ist dann durchÃ¼Ã¼pnâˆ—=Pâˆ—[{Ï‰n}]=P[{Ï‰n}|B]={pnP[B]fÃ¼rÂ Ï‰nâˆˆB,0fÃ¼rÂ Ï‰nâ‰ B,gegeben. Wir setzen alle Gewichte ausserhalb von B auf Null und skalieren die Gewichte in B mit einem festen Faktor, sodass ihre Summe wieder 1 ergibt.\n\n[!info] #Theorem 1.29 Satz von der totalen Wahrscheinlichkeit\nGegeben: B1,â€¦,BN mit P[Bn]&gt;0 fÃ¼r jedes 1â‰¤nâ‰¤N eine Partitione des Grundraums Î©, d.h. â‹ƒn=1NBn=Î© mit Bnâˆ©Bm=âˆ… fÃ¼r nâ‰ m.\nDann gilt fÃ¼r alle AâˆˆF\nP[A]=âˆ‘n=1NP[A|Bn]P[Bn]\n\n[!info] #Theorem 1.32 Satz von Bayes\nGegeben: B1,â€¦,BNâˆˆF eine Partition von Î© mit P[Bn]&gt;0 fÃ¼r alle n.\nFÃ¼r jedes Ereignis A mit P[A]&gt;0 und jedes nâˆˆ{1,â€¦,N} gilt\nP[Bn|A]=P[A|Bn]P[Bn]âˆ‘k=1NP[A|Bk]P[Bk]\n\nSpezialfall n=2 mit Î©=BâˆªBâˆ so ist\nP[B|A]=P[A|B]P[B]P[A|B]P[B]+P[A|Bâˆ]P[Bâˆ]\n\n[!info] UnabhÃ¤ngigkeit zweier Ereignisse\n(WS #Def 1.35)\nGegeben: (Î©,F,P) ein Wahrscheinlichkeitsraum\nZwei Ereignisse A und B heissen (stochastisch) unabhÃ¤ngig, falls\nP[Aâˆ©B]=P[A]P[B]\n\nFalls P[A]âˆˆ{0,1}, dann ist A unabhÃ¤ngig von jedem Ereignis\nFalls Ereignis von sich selbst unabhÃ¤ngig ist, dann muss P[A]âˆˆ{0,1} gelten. ( #disclaimerN (falls richtig) A von sich selbst unabhÃ¤ngig âŸºP[A]âˆˆ{0,1})\nA ist unabhÃ¤ngig von BâŸºA unabhÃ¤ngig von Bâˆ\n\n[!info] (WS #Proposition 1.37)\nGegeben: A,BâˆˆF zwei Ereignisse mit P[A],P[B]&gt;0\nDann sind folgende Aussagen Ã¤quivalent:\n\n(i) P[Aâˆ©B]=P[A]P[B] d.h. A und B sind unabhÃ¤ngig\n(ii) P[A|B]=P[A] d.h. Eintreten von B hat keinen Einfluss auf A\n(iii) P[B|A]=P[B] d.h. Eintreten von A hat keinen Einfluss auf B\n\n[!info] UnabhÃ¤ngigkeit (WS #Def 1.40)\nGegeben: I eine beliebige Indexmenge\nEine Familie von Ereignissen ()Ai)iâˆˆI heisst (stochastisch) unabhÃ¤ngig, wenn fÃ¼r alle endlichen Teilmengen JâŠ‚I gilt: P[â‹‚jâˆˆJAj]=âˆjâˆˆJP[Aj]\n\nfalls Menge unabhÃ¤ngig âŸ¹ Ereignisse paarweise unabhÃ¤ngig (Umkehrung gilt nicht!)\n\n[!info] Zufallsvariable (WS #Def 2.1)\nGegeben: Wahrscheinlichkeitsraum (Î©,F,P)\nEine (reellwertige) Zufallsvariable (Z.V.) ist eine Abbildung X:Î©â†’R, sodass fÃ¼r alle xâˆˆR gilt,\n{Ï‰âˆˆÎ©|X(Ï‰)â‰¤x}âˆˆF",
		"tags": ["Def", "Theorem", "Theorem", "Theorem", "Def", "disclaimerN", "Proposition", "Def", "Def", "note"]
},

{
		"title": "WS L3",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l3/",
		"content": "[!info] #Def 2.1 Zufallsvariable\nGegeben: Wahrscheinlichkeitsraum (Î©,F,P)\nEine (reelwertige) Zufallsvariable ( #short Z.V.) ist eine Abbildung X:Î©â†’R sodass fÃ¼r alle xâˆˆR gilt\n{Ï‰âˆˆÎ©|X(Ï‰)â‰¤x}âˆˆF\n\n[!info] #Remark 2.5 Messbarkeit\nWenn eine (reelwertige) Funktion die Eigenschaft (2.1) erfÃ¼llt, heisst diese Funktion messbar ( #english measurable).\nDa wir an AusgÃ¤ngen von Zufallsexperimenten interessiert sind, wollen wir Wahrscheinlichkeiten der Form\nÃ¼P[{Ï‰âˆˆÎ©|X(Ï‰)âˆˆB}]Â fÃ¼r bestimme MengenÂ BâŠ‚Rberechnen kÃ¶nnen. Z.B.\n\nFalls B={2,4,6} wenn wir die Wahrscheinlichkeit fÃ¼r einen gerade Zahl beim WÃ¼rfeln mÃ¶chten.\nWeil das Wahrscheinlichkeitsmass P auf F definiert ist, mÃ¼ssen die Urbilder aller dieser Mengen B,\n\nXâˆ’1(B):={Ï‰âˆˆÎ©|X(Ï‰)âˆˆB}in F enthalten sein.\n\nIn dieser Vorlesung verlangen wir fÃ¼r Messbarkeit, dass Xâˆ’1(B)âˆˆF fÃ¼r alle BâˆˆB(R)\n\nHierbei ist B(R) die borelsche Ïƒ-Algebra auf R\nz.B. alle offenen, abgeschlossenen und kompakten Mengen in R oder alle Intervalle der Form (a,b),[a,b],(a,b],[a,b),(âˆ’âˆ,b),(âˆ’âˆ,b],(a,âˆ),[a,âˆ) fÃ¼r a,bâˆˆR\n\n[!info] #Def 2.10 Verteilungsfunktion\nGegeben: reelwertige Zufallsvariable X, Wahrscheinlichkeitsraum (Î©,F,P)\nDie (kumulative) Verteilungsfunktion von X ( #english cumulative distribution function) ( #short cdf) ist die Funktion FX:Râ†’[0,1], definiert durch\nFX(x):=P[Xâ‰¤x]\n\n[!info] #Theorem 2.13 Eigenschaften von Verteilungsfunktionen\nGegeben: Zufallsvariable X, Wahrscheinlichkeitsraum (Î©,F,P)\nDie Verteilungsfunktion FX:Râ†’[0,1] von X erfÃ¼llt folgende Eigenschaften:\n\n(i) FX ist monoton wachsend\n(ii) FX ist rechtsstetig d.h. fÃ¼r alle xâˆˆR gilt FX(x)=limhâ†’0FX(x+h)\n(iii) Es gelten die Grenzwerte limxâ†’âˆ’âˆFX(x)=0 und limxâ†’âˆFX(x)=1\nI also found\nwikipedia\n\nP(Xâ‰¤x)=FX(x)\nP(a&lt;Xâ‰¤b)=FX(b)âˆ’FX(a)\nP(X=b)=FX(b)âˆ’limxâ†’bâˆ’FX(x)\n\nMath Stackexchange\n\nP(a&lt;X&lt;b)=P(X&lt;b)âˆ’P(Xâ‰¤a)=limxâ†’bâˆ’FX(x)âˆ’FX(a)\n\n[!info] #Def 2.16 Gemeinsame Verteilungsfunktion\nGegeben: Zufallsvariablen X1,â€¦,Xn\nDie gemeinsame Verteilungsfunktion von X1,â€¦,Xn ist die Abbildung F:Rnâ†’[0,1] definiert durch\n(x1,â€¦,xn)â†¦F(x1,â€¦,xn)=P[X1â‰¤x1,â€¦,Xnâ‰¤xn]\n\n[!info] #Def 2.18 <a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">UnabhÃ¤ngigkeit</a> von Zufallsvariablen\nGegeben: Zufallsvariablen X1,â€¦,Xn auf Wahrscheinlicheitsraum (Î©,F,P). Dann heissen X1,â€¦Xn unabhÃ¤ngig, wenn fÃ¼r alle x1,â€¦,xnâˆˆR gilt\nP[X1â‰¤x1,â€¦,Xnâ‰¤xn]=P[X1â‰¤x1]âˆ—â‹¯âˆ—P[Xnâ‰¤xn]\n#Remark 2.19 X1,â€¦,Xn sind genau dann unabhÃ¤ngig, wenn fÃ¼r alle Intervalle IâŠ‚R,â€¦,InâŠ‚R die Ereignisse {X1âˆˆI1},â€¦{XnâˆˆIn} unabhÃ¤ngig sind.\nWenn wir eine Menge unabhÃ¤ngiger Zufallsvariablen haben und disjunkte Gruppen solcher Zufallsvariablen bilden, dann sind diese Gruppen auch wiederum unabhÃ¤ngig voneinander.\n\n[!info] #Theorem 2.21 Gruppierung von Zufallsvariablen\nGegeben: unabhÃ¤ngige Zufallsvariablen X1,â€¦Xn, Indexe 1â‰¤i1&lt;i2&lt;â‹¯&lt;ikâ‰¤n, Abbildungen Ï†1,â€¦,Ï†k\nDann sind\nY1:=Ï†1(X1,â€¦,Xi1),Y2:=Ï†2(X1,â€¦,Xi2),â€¦,Yk:=Ï†k(X1,â€¦,Xik)unabhÃ¤ngig.\n\n[!info] #Def 2.22. UnabhÃ¤ngig und identisch verteilt\nEine Folge von Zufallsvariablen X1,X2 heisst\n\nunabhÃ¤ngig falls X1,â€¦,Xn fÃ¼r alle nâˆˆN unabhÃ¤ngig sind.\nunabhÃ¤ngig und identisch verteilt ( #short u.i.v.) ( #english independent and identically distributed ( #short i.i.d.)) falls sie unabhÃ¤ngig ist und die Zufallsvariablen dieselbe Verteilungsfunktion haben d.h. fÃ¼r alle k,lâˆˆN gilt FXk=FXl",
		"tags": ["Def", "short", "Remark", "english", "Def", "english", "short", "Theorem", "Def", "Def", "Remark", "Theorem", "Def", "short", "english", "short", "note"]
},

{
		"title": "WS L4",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l4/",
		"content": "Beweis zu Satz 2.13\n\nExistenzsatz von Kolmogorov und Folgen von i.i.d. Bernoulli Zufallsvariablen\n\n[!info] #Def 2.24 Bernoulli\nGegeben: pâˆˆ[0,1].\nEine Zufallsvariable X heisst Bernoulli Zufallsvariable mit Parameter p, wenn gilt\nP[X=0]=1âˆ’pÂ undÂ P[X=1]=pWir schreiben Xâˆ¼Ber(p).\n\n[!info] #Theorem 2.26 Existenz von Kolmogorov\nEs existiert ein Wahrscheinlichkeitsraum (Î©,F,P) und eine unendliche Folge von i.i.d. Bernoulli Zufallsvariablen X1,X2,â€¦ auf (Î©,F,P) mit Parameter 12\n\n[!info] #Theorem 2.27.\nEine Zufallsvariable U heisst gleichverteilt auf [0,1], wir schreiben Uâˆ¼U([0,1]), falls ihre Verteilungsfunktion gegeben ist durch\nFU(x)={0x&lt;0x0â‰¤xâ‰¤11x&gt;1\n\nKonstruktion von gleichverteilten Zufallsvariablen auf [0,1]\n\n[!info] #Theorem 2.28\nDie Abbildung X:Î©â†’[0,1] definiert in Gleichung (2.3) ist eine gleichverteilte Zufallsvariable auf [0,1].\n\n[!Info]- Beweis\nEs ist schnell sichtbar, dass fÃ¼r alle Ï‰âˆˆÎ© gilt, X(Ï‰)âˆˆ[0,1]. Somit gilt fÃ¼r x&lt;0, dass FX(x)=P[Xâ‰¤x]=0 und fÃ¼r xâ‰¥1, dass FX(x)=1\nSei also xâˆˆ[0,1) und sei {xn}nâˆˆN ihre eindeutige BinÃ¤rdarstellung wie in Lemma 2.29. Dann gilt\n{X&gt;x}={X1&gt;x1}âˆª{{X1=x1}âˆ©{X2&gt;x2}}âˆªâ€¦Also entweder ist die erste Ziffer grÃ¶sser oder die erste Ziffer ist gleich und die zweite ist grÃ¶sser usw.\n\n[!info] #Lemma 2.29 BinÃ¤rdarstellung\nJedes xâˆˆ[0,1) kann eindeutig in der Form\nx=âˆ‘n=1âˆ2âˆ’nxndargestellt werden, wobei fÃ¼r alle nâˆˆN gilt,xnâˆˆ{0,1}, und fÃ¼r jedes NâˆˆN gibt es ein k&gt;N, sodass xk=0 (als odie Folge &quot;endet&quot; nicht in unendlich vielen 1-en.) Die Folge {xn}nâˆˆN heisst BinÃ¤rdarstellung von x und wir schreiben x=(.x1x2â€¦)2\n\nKonstruktion von Zufallsvariablen mit beliebiger Verteilungsfunktion F\nDa wir die Gleichverteilung auf [0,1] haben, wÃ¼rden wir nun gerne Zufallsvariablen mit beliebiger Verteilungsfunktion konstruieren kÃ¶nnen.\nGegeben: F:Râ†’[0,1] eine Funktion, die die Eigenschaften (i)-(iii) aus Satz 2.13 erfÃ¼llt.\nFalls F streng monoton steigend und stetig ist, dann ist F bijektiv und es existiert eine Umkehrfunktion Fâˆ’1. FÃ¼r jedes Î±âˆˆ[0,1] ist x:=Fâˆ’1(Î±) die eindeutige reelle Zahl, fÃ¼r die F(x)=Î± gilt.\nAllgemein kann die sogenannte verallgmeinerte inverse Verteilungsfunktion oder Quantil-Funktion fÃ¼r F definiert werden.\n\n[!info] #Def 2.30 Verallgemeinerte inverse Verteilungsfunktion\nDie Verallgemeinerte inverse Verteilungsfunktion von F ist eine Abbildung Fâˆ’1:(0,1)â†’R definiert durch\nFâˆ’1(Î±)=inf{xâˆˆR|F(x)â‰¥Î±}\nNach Definition des Infimums und unter Verwendung der Rechtsstetigkeit von F gilt fÃ¼r jedes xâˆˆR und Î±âˆˆ(0,1), dass\nFâˆ’1(Î±)â‰¤xâŸºÎ±â‰¤F(x)\nMithile der verallgemeinerten inversen Verteilungsfunktion kÃ¶nnen wir nun Zufallsvariablen mit beliebigen Verteilungsfunktionen konstruieren.\n\n[!info] #Theorem 2.31. Inversionsmethode\nGegeben: F:Râ†’[0,1] eine Abbildung mit den Eigenschaften (i)-(iii) aus Satz 2.13, Uâˆ¼U([0,1])\nDann hat die Zufallsvariable X:=Fâˆ’1(U) die Verteiungsfunktion F.\n\n[!info]- Beweis\nP[Xâ‰¤x]=P[Fâˆ’1(U)â‰¤x]=P[Uâ‰¤F(x)]=F(x)â—»\n#disclaimer 2.33\nWir bemerken, dass X=Fâˆ’1(U) strenggenommen nur auf einer Menge mit Wahrscheinlichkeit 1 (da P[Uâˆˆ(0,1)]=1) aber nicht unbedingt auf ganz Î© definiert ist. Wir beheben das Problem mittels folgender Definition\nX(Ï‰){Fâˆ’1(U(Ï‰))U(Ï‰)âˆˆ(0,1)0sonstDabei spielt 0 selbst keine Rolle und es kann jede beliebe reelle Zahl genommen werden.\n\nallgemeine Folgen von unabhÃ¤ngigen Zufallsvariablen\n\n[!info] #Theorem 2.35.\nGegeben: Folge von Funktionen F1,F2 auf Râ†’[0,1], die die Eigenschaften (i)-(iii) aus Satz 2.13 erfÃ¼llen.\nDann existiert ein Wahrscheinlichkeitsraum (Î©,F,P) und eine Folge von Zufallsvariablen X1,X2,â€¦ auf diesem Wahrscheinlichkeitsraum, sodass\n\nfÃ¼r jedes k gilt, Xk hat Verteilungsfunktion Fk und\nX1,X2,â€¦ sind unabhÃ¤ngig.\nDieser Satz erlaubt es uns, direkt mit Zufallsvariablen zu arbeiten, ohne den Wahrscheinlichkeitsraum (Î©,F,P) genauer zu definieren.\nZ.B. kÃ¶nnen wir fÃ¼r zwei Verteilungsfunktionen F und G stets annehmen, dass X und Y existieren, die unabhÃ¤ngig sind und Verteilungsfunktionen F und G besitzen",
		"tags": ["Def", "Theorem", "Theorem", "Theorem", "Lemma", "Def", "Theorem", "disclaimer", "Theorem", "note"]
},

{
		"title": "WS L5",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l5/",
		"content": "[!info] #Theorem 3.3. Wahrscheinlichkeit eines Punktes\nGegeben: Zufallsvariable X:Î©â†’R mit Verteilungsfunktion F.\nFÃ¼r jedes xâˆˆR gilt P[X=x]=F(x)âˆ’F(xâˆ’)\n\nInterpretation: Sei xâˆˆR fixiert\n\nWenn F in einem Punkt xâˆˆR nicht stetig ist, dann ist die &quot;SprunghÃ¶he&quot; F(x)âˆ’F(xâˆ’) gleich der Wahrscheinlichkeit, dass X=x\nFalls F stetig in einem Punkt xâˆˆR ist, dann gilt P[X=x]=0\n\n[!info] #Def 3.4.\nGegeben: Ereignis AâˆˆF\nWir sagen A tritt P-fast sicher ( #short P-f.s.) ein, falls P[A]=1 ( #english P-almost surely ( #short P-a.s.))\n\nAbkÃ¼rzung falls Wahrscheinlichkeitsmass P klar ist und schreiben nur &quot;fast sicher ( #short f.s.)&quot;\n#disclaimer 3.5. Erweiterung der Notation auf allgemeine Mengen AâŠ‚Î© (nicht unbedingt AâˆˆF). Wir sagen, dass A fast sicher eintritt, falls ein Ereignis Aâ€²âˆˆF existiert, sodass Aâ€²âŠ‚A und P[Aâ€²]=1\ne.g. Wir schreiben Xâ‰¤Y P-f.s., falls P[Xâ‰¤Y]=1\nWenn wir mit stetigen ZV arbeiten, ist es oft restriktiv die Ungleichung X(Ï‰)â‰¤Y(Ï‰) fÃ¼r alle Ï‰âˆˆÎ© zu fordern. Deshalb fordern wir die Ungleichung nur auf einer Menge mit Mass 1.\n\nDiskrete Zufallsvariablen\n\n[!info] #Def 3.7. Diskrete Zufallsvariablen\nEine ZV X:Î©â†’R heisst diskret, falls eine endliche oder abzÃ¤hlbare Menge WâŠ‚R existiert, sodass P[XâˆˆW]=1, wenn also die Werte von X fast sicher in W liegen.\n\n#disclaimer 3.8.\ngegeben: endlicher oder abzÃ¤hlbarer Grundraum Î©\nDann ist jede ZV X:Î©â†’R diskret. In der Tat ist das Bild\n\nX(Î©)={xâˆˆR|âˆƒÏ‰âˆˆÎ©:X(Ï‰)=x}endlich oder abÃ¤hlbar und wir haben P[XâˆˆW]=1 mit W=X(Î©)\n\n[!info] #Def 3.9. Gewichtsfunktion\nFÃ¼r eine diskrete ZV X mit Wertebereich W(X)={x1,x2,â€¦} und den dazugehÃ¶rigen Wahrscheinlichkeiten {p1,p2,â€¦} definieren wir die Gewichtsfunktion ( #short probability mass function ( #short pmf)) oder diskrete Dichte von X als\npX:W(X)â†’[0,1]Â mitÂ pX(xk):=P[X=xk]=pkDie Zahlenfolge {pX(xk)}xkâˆˆW(X) nennen wir auch Verteilung von X\n\n[!info] #Proposition 3.10.\nDie Gewichtsfunktion pX einer diskreten ZV X hat folgende Eigenschaften:\n\nFÃ¼r alle xkâˆˆW(X) gilt pX(xk)âˆˆ[0,1]\nDie Wahrscheinlichkeiten addieren sich zu 1,\n\nâˆ‘xkâˆˆW(X)pX(xk)=P[XâˆˆW(X)]=1\n\n[!info] #disclaimer 3.11.\nUmgekehrt, wenn wir eine Folge von Zahlen (p(x)xâˆˆW) mit Werten in [0,1] haben, sodass âˆ‘xâˆˆWp(x)=1, dann gibt es nach Satz 2.35 einen Wahrscheinlichkeitsraum (Î©,F,P) und eine ZV X mit zugehÃ¶riger Verteilung (p(x))xâˆˆW.\nDiese Bebachtung ist in der Praxis wichtig, den sie erlaubt uns zu schreiben: &quot;Sei X eine diskrete ZV mit Verteilung (p(x))xâˆˆW.&quot;\n\nZusammenhang Verteilungs- und Gewichtsfunktion\n\n[!info] #Theorem 3.12.\nSei X eine diskrete ZV mit Werten in W und Gewichtsfunktionen pX. Dann ist die Verteilungsfunktion von X gegeben durch\nFX(x)=P[Xâ‰¤x]=âˆ‘yâ‰¤x,yâˆˆWpX(y)\nInsbesondere ist FX also durch pX vollstÃ¤ndig festgelegt. Mit dem gleichen Argument erhÃ¤lt man auch fÃ¼r jede messbare Teilmenge BâŠ†W, P[XâˆˆB]=âˆ‘xâˆˆBpX(x)\n#disclaimer 3.13\nGleichung (3.1) drÃ¼ckt die Verteilungsfunktion FX in Bezug auf pX als eine stÃ¼ckweise konstante Funktion aus.\nUmgekehrt ist eine ZV mit einer stÃ¼ckweisen konstankten Verteilungsfunktion FX diskret. W und pX sind dann gegeben durch W={Â Sprungstelle vonÂ FX} und Ã¶p(x)=\"SprunghÃ¶he im PunktÂ xâˆˆW\n\n[!info] #Theorem 3.19. Summe unabhÃ¤ngiger Bernoulli-ZV\nGegeben: pâˆˆ[0,1], nâˆˆN, unabhÃ¤ngige X1,â€¦,Xnâˆ¼Ber(p)\nDann gilt Sn:=X1+â‹¯+Xnâˆ¼Bin(n,p)\n\n[!info] #Theorem 3.23\nGegeben: unendliche Folge von unabhÃ¤ngigen Bernoulli-ZV X1,X2,â€¦ mit Parameter p\nDann ist T:=inf{nâ‰¥1|Xn=1} eine geometrisch verteilte ZV mit Parameter p.\n\n#disclaimer 3.24. Sei z.B. Tâˆ¼Geom(p), dann ist T&gt;n, wenn die ersten n Bernoulli-Expiremente fehlschlagen. Daher gilt P[T&gt;n]=(1âˆ’p)n",
		"tags": ["Theorem", "Def", "short", "english", "short", "short", "disclaimer", "Def", "disclaimer", "Def", "short", "short", "Proposition", "disclaimer", "Theorem", "disclaimer", "Theorem", "Theorem", "disclaimer", "note"]
},

{
		"title": "WS L6",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l6/",
		"content": "[!info] #Theorem 3.25 GedÃ¤chtnislosigkeit der geometrischen Verteilung\nGegeben: Tâˆ¼Geom(p), pâˆˆ(0,1)\nDann gilt fÃ¼r alle nâ‰¥0 und alle kâ‰¥1\nP[Tâ‰¥n+k|T&gt;n]=P[Tâ‰¥k]\nWenn wir also nach n Schritten immer noch auf den ersten Erfolg warten, dann ist die verbleibende Wartezeit wiederum Geom(p) verteilt.\n\n[!info]- Beweis\nP[Tâ‰¥n+k|T&gt;n]=P[{Tâ‰¥n+k}âˆ©{T&gt;n}]P[T&gt;n]=P[Tâ‰¥n+k]P[T&gt;n]=(1âˆ’p)n+kâˆ’1(1âˆ’p)n=(1âˆ’p)kâˆ’1=P[Tâ‰¥k]\n\n[!info] #Example 3.26 negativbinomiale Verteilung\nGegeben: Zufallsvariable X\nX hat eine negativbinomaile Verteilung mit Parameter râˆˆN und pâˆˆ[0,1], wir schreiben XâˆˆNBin(r,p), wenn fÃ¼r alle kâˆˆ{r,r+1,r+2,â€¦} gilt:\nP[X=k]=(kâˆ’1râˆ’1)pr(1âˆ’p)kâˆ’rDas ist eine Verallgemeinerung der geometrischen Verteilung und beschreibt die Wartezeit bis zum r -ten Erfolg in einer unendlichen Folge von Bernoulli-Experimenten. Die geometrische Verteilung erhÃ¤lt man als Spezialfall fÃ¼r r=1\n\n[!info] #Theorem 3.27\nGegeben: unendliche Folge von unabhÃ¤ngigen Bernoulli-Zufallsvariablen X1,X2 mit Parameter p\nDann hat\nTr=inf{nâ‰¥1|âˆ‘l=1nXl=r}eine negativbinomiale Verteilung mit Parametern r und p\n\n#disclaimer 3.28 Sind die Zufallsvariaben X1,â€¦,Xrâˆ¼Geom(p) und unabhÃ¤ngig, so ist ihre Summe X=X1+â‹¯+Xrâˆ¼NBin(r,p)\n\n[!info] #Example 3.29 Hypergeometrische Verteilung\nEine Zufallsvariable X heisst hypgergeometrische verteilt mit Parametern nâˆˆN und m,râˆˆ{1,â€¦,n}, wir schreiben Xâˆ¼H(n,r,m), wenn fÃ¼r alle kâˆˆ{0,1,â€¦,min(m,r)} gilt\nP[X=k]=(rk)(nâˆ’rmâˆ’k)(nm)Diese Gewichtsfunktion kommt wie folgt zustande\n#Theorem 3.30 Seien in einer Urne n GegenstÃ¤nde, davon r vom Typ 1 und nâˆ’r vom Typ 2. Es werden m GegenstÃ¤nde ohne ZurÃ¼cklegen gezogen. Sei X nun die Anzahl der gezogenen GegenstÃ¤nde vom Typ 1. Dann ist X hypergeometrisch mit den Parametern von oben verteilt.\n\n[!info]- Beweis\n\n#Example 3.31 Lotto\nIm Schweizer Lotto, wo 6 aus 42 zahlen richtig getippt werden sollen, ist die Anzahl der richtigen getippten Zahlen bei einem einzelnen Tipp hypergeometrisch verteilt mit Parametern n=42,r=6,m=6.\n\n[!info] Poisson-Verteilung\nGegeben: positive reelle Zahl Î»&gt;0\nEine Zufallsvariable X heisst Poisson-verteilt mit Parameter Î», wir schreiben Xâˆ¼Poisson(Î»), wenn sie Werte N annimt und fÃ¼r alle kâˆˆN0 gilt\nP[X=k]=Î»kk!eâˆ’Î»\n\n[!info] #Theorem 3.34 Poisson-Approximation der Binomialverteilung\nGegeben: Î»&gt;0\nFÃ¼r jedes nâ‰¥1 betrachten wir n Zufallsvariablen Xnâˆ¼Bin(n,Î»). Sei Nâˆ¼Poisson(Î»). Dann gilt fÃ¼r alle kâˆˆN\nlimnâ†’âˆP[Xn=k]=P[N=k]\n#disclaimer 3.35 Diese Art von Konvergenz wird Konvergenz in Verteilung ( #english lish convergence in distribution, convergence in law)oder schwache Konvergenz ( #english weak convergence) genannt. Intuitiv besagt sie, dass Xn und N sehr Ã¤hnliche wahrscheinlichkeitstheoretische Eigenschaften fÃ¼r grosse n haben.\n#Example 3.36\n\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Stetige Zufallsvariablen</a>",
		"tags": ["Theorem", "Example", "Theorem", "disclaimer", "Example", "Theorem", "Example", "Theorem", "disclaimer", "english", "english", "Example", "note"]
},

{
		"title": "WS L7 Normalverteilung",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l7-normalverteilung/",
		"content": "<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Normalverteilung</a>\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Erwartungswert</a>",
		"tags": [ "note"]
},

{
		"title": "home page",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "",
		"tags": [ "note","gardenEntry"]
}
]