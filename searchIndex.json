[
{
		"title": "DF Definitions",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-definitions/",
		"content": "more definition in [[Ethereum and DeFi Glossary.pdf]]\npegged cryptocurrency: cryptocurrency whose value is linked to a specific bank-issued currency, financial instrument or tradable commodity\n\ne.g. pay back to buy BTC and holds it for you\n\nKnow your customer ( #short KYC): means verifying who you are when joining a crypto exchange\nAnti-money laundering ( #short AML): helping to break criminal networks and minimise the impact of illicit transactions on affected economies.\nwashtrading: occurs when an investor buys and sells the same or a similar security investment at the same time (e.g. can be done by using flash loans)\n(Fractional) reserve: bank's reserve ratio = (money held by bank) / (money deposited by bank customers)\nExchange traded fund ( #short ETF): security/asset\n\ntracking an index/sector/commodity\ntradable on an exchange\ntypically, lower fees than buying individual stocks\nEFT types: bond, stock, industry, commodity, currency, inverse, etc\ne.g. SPDR S&amp;P 500 ETF tracks the S&amp;P 500 index\n\ndecentralised autonomous organisation ( #short DAO): e.g. <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/df-l6/#maker-dao-pasted-image-20240405232329-png\">MakerDAO</a>\n\nLending\n\ncollateral: assets that serve as a security deposit\nOver-collateralisation: Borrower has to provide value(collateral assets) &gt; value(granted loan)\nUnder-collateralisation: value(collateral) &lt; value(debt)\nLiquidation: selling collateral from the borrower\n\nE.g., if value(collateral) &lt;= 150% x value(debt)\nAnyone can liquidate the debt position\n\nHealth factor\n\n0 &lt; liquidation threshold &lt; 1\nliquidation threshold provides a &quot;secure&quot; margin\nwhen health factor &lt; 1 =&gt; borrowing position becomes liquidatable\ne.g.\n\nLiquidation Spread #short LS: bonus, or discount, that a liquidator can collect when liquidating collateral\n\n𝑉𝑎𝑙𝑢𝑒 𝑜𝑓 𝐶𝑜𝑙𝑙𝑎𝑡𝑒𝑟𝑎𝑙 𝑡𝑜 𝐶𝑙𝑎𝑖𝑚 = 𝑉𝑎𝑙𝑢𝑒 𝑜𝑓 𝐷𝑒𝑏𝑡 𝑡𝑜 𝑅𝑒𝑝𝑎𝑦 × (1 + 𝐿𝑆)\n\nClose Factor #short CF: the maximum proportion of the debt that is allowed to be repaid in a single fixed spread liquidation\n𝑉𝑎𝑙𝑢𝑒 𝑜𝑓 𝐷𝑒𝑏𝑡 𝑡𝑜 𝑅𝑒𝑝𝑎𝑦 &lt; 𝐶𝐹 × 𝑇𝑜𝑡𝑎𝑙 𝑉𝑎𝑙𝑢𝑒 𝑜𝑓 𝐷𝑒𝑏𝑡𝑠",
		"tags": ["short", "short", "short", "short", "short", "short", "note"]
},

{
		"title": "DF L1",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l1/",
		"content": "#disclaimer Not examrelevant!\n\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/financial-markets/\">Financial Markets</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/decentralised-finance/\">Decentralised Finance</a>",
		"tags": ["disclaimer", "note"]
},

{
		"title": "DF L2",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l2/",
		"content": "&lt;![[Ethereum and DeFi Glossary.pdf]]\nQuiz\n\nA valid signed transaction of an account can be used to computer\n\nthe private key of the account\nthe address of the account [true]\n(both are true)\n(both are false)\n\nRunning a node in the Ethereum network\n\nwill earn you money\nwill cost you proof-of-work mining energy\nneeds an excellent internet connection (because you constantly need to be connected to 5'000 other nodes)\n(none of the above) [true]\n\nAn Ethereum smart contract can be programmed to\n\ninteract with a normal (not Ethereum) computer program through remote procedure calls.\nautomatically run every hour.\n(both are ture)\n(both are false) [true]\n\nLayer 2 protocols\n\nare not realy (only exist in reseach)\nare considered illegal (by the Ethereum foundation)\nhave been co-invented at ETH Zurich [true]\n(none of the above)\n\nIgnore fees, how many bananas do you get when you send 10 apples to a CPMM that holds a liquidity of 30 apples and 56 bananas?\n\nHow to calculate?\n\nconstant product = 30 [apples] * 56 [bananas] = 168\nand afterwards there has to be the same again thus 40 (30 + 10 new) [apples] * x [bananas] = 168\nsolve for x\n\nalternative: calculate ratio after adding 56 [bananas] / 40 [apples] = 7 / 5 =&gt; now multiply with number of apples and you get bananas 7 [bananas] / 5 [apples] * 10 [apples] = 14 [bananas]",
		"tags": [ "note"]
},

{
		"title": "DF L3",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l3/",
		"content": "DF and CF\nDF stack\n\nExample where smart contract on blockchain uses external data\n\nOracle\n\nReasons for need of oracles for blockchains\n\nblockchain is isolated DB\nblockchains lack\n\naccess to real-world data\nno API-query possible\ncannot browse the internet\n\nSolution: transactions\nDefinition\n\nGeneral: System that connects a blockchain with other systems.\nSpecific: Actors relaying data on-chain.\n\nDesign\nChallenges\n\nminers (provider of data) can lie/cheat\nnetwork providing data for miners can lie/cheat\nsource or oracle outage\n=&gt; have multiple miners and sources to prevent outage\n=&gt; have consensus so possibility of false data is minimised\n\nCensorship\n\ncan happen on multiple layers e.g. application, transaction, consensus\n\nMixers\n\nbreaks connection to person who put it in =&gt; but observations/analysis of transaction can help with finding out who gave/took coins\n(in best case) just fixed values e.g. 1 ETH possible, so less\n\nImplications\n\nConfirmation latency: slows down transaction confirmations\nDenial of Service: A lot of (fake) transactions can slow node down or even completely take it down\n\nproposer/builder separation\nattack nodes who apply censorship\n\nfor censorship, nodes have to put in work to extract information but then cannot do transactions and don't earn anything bc. transaction with a censored value is not allowed =&gt; DDoS attack possible to spam node with censored coins\n\nQuiz\n\nWhich of the following DeFi applications is most likely to require external oracle data?\n\nToken management contracts, such as ERC20\nBetting on real world events [correct]\nUniswap, Curve, and other Automated Market Maker Decentralised Exchanges\nOn-chain games that do not require randomness\n\nIs the context of blockchain oracles, which of the following statements is NOT TRUE?\n\nBecause block generation is centralised process, incorporating an oracle into the consensus protocol does not work because miners may lie or cheat.\nOracles have to receive very concise and short data representations to minimise blockchain fees.\nFor each oracle update, a minimum subset of all nodes in the oracle committee should send a report to the miner. [correct bc. one node is enough]\nMultiple sources /website (redundancy) are required due to website outages and data corruption possibilities\n\nWhat is the anonymity set of Tronado Cach pool with 1000 deposits\n\n100\n1000 [correct]\n999\n1001\n\nWhat are the computational implications if a miner censors a transaction, what is correct?\n\nNo implication bc. the miner doesn't need to verify the transaction.\nNo implications bc. the miner doesn't need to execute the transaction.\nThe minder must spend computational resources to execute the transaction but cannot claim transaction fees. [correct]\nThe miner must spend computational resources but is paid the regular transaction fees.\n\nAssumed an oracle committee has five nodes (A,B,C,D,E) and it's agreed to report the median value. Node E is a malicious node and E observes the following values from the other four nodes (A:1000, B: 1010, C: 1020, D: 1030). What are the upper and lower bounds of the aggregated value to which E can manipulate.\n\n1000 - 1005\n1010-1020 [correct bc. median is middle number and you can choose a number between (including borders) 1010 to 1020 and it will be chosen]\n1000 - 1030\nno upper/lower bounds",
		"tags": [ "note"]
},

{
		"title": "DF L4",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l4/",
		"content": "Decentralised Exchange\n(Example LOB Dex)\n\n(Dis) advantages:\n\n+ No KYC/AML\n+ no fees paid to the exchange\n+ no impermanent loss\n- fees for deposit, withdraw, trade creation/cancel\n- slow execution\n- not fully decentralised (mediating server)\n\ntrading volume: around 70 billion (recent months)\nWhy?\n\nSystems Architecture\nAutomated market maker\n#short AMM\n\nLiquidity pool idea: Let a smart contract do the market making. liquidity provider (LP) token:\nformula x∗y=k where x = asset X quantity, y = asset Y quantity, k = constant\nproperties\n\ninstant liquidity, irrespective of the trade size\npurchase of asset X increases price of X and decreases the price of Y\nratio of asset X and Y sets the price\nknown as constant product ( #short CP) AMM\n\n(dis)advantages\n\nno order book maintenance: but arbitrage required\n\nsimple implementation for CP AMM: low gas costs\n\ndanger of impermanent loss/coin de-peg: total loss of funds possible\n\nhigh slippage for low liquidity markets\n\nusers vulnerable to sandwich attacks\n\nExample:\n\nSlippage\n\n(un)expected increase or decrease in price based on trading volume and available liquidity\neffects\n\nworse/better execution price\n\npossible to introduce a slippage protection by configuring a threshold to prevent unacceptable slippage\n\nImpermanent loss\n#short IL\n\nimpermanent == not permanet: realised upon withdraw only\ncan result in total loss\n\ntrading fees may compensate\nliquidity mining may compensate\nsimilar to a de-peg of stablecoin\n\nExchange Transaction propagation\nStablecoin AMM pros/cons\n\nbetter prices for bigger volumes i.e. more liquidity\n\nexample shows significant differences among exchanges\n\npotentially higher gas costs\n\ndanger of a de-peg of a stablecoin\n\npegged/stablecoin prices move in expectation together\n\nexchange rate should ideally remain 1:1\ndefault CP AMM is not optimised for such cases\n\nWhat if a coin gets\n\nde-pug\n\nas bank run in CeFi: no money returned\n&quot;bank run&quot; in DeFi\n\npool may get blacklisted\nfirst come, first served\npool formula penalises destabilising a pool\nincreasingly worse price for late-comers\n\nblacklisted\n\ne.g. USDT and USDC have built-in code to\n\nblacklist addresses\ndestroy coins\ne.g. USDT blacklisted 500+ accounts, destroyed 50M+ USDT\n\nAMM arbitrage\n\nbeginning: multiple markets with\n\nthe same assets X and Y\ndifferent prices for X and Y\n\nprices are synchronised by &quot;arbitrageurs&quot;\n\nthey gain profit from price difference: also referred to as &quot;spread&quot;\nrequires to perform at least one transaction\n\ne.g.\n\narbitrageur can also do it with a flash loan\n\nhow to detect arbitrage/profitable opportunities?\n\nBellman Ford Algorithm\n\nNegative cycle detection\nWorks among multiple markets\nUsed in traditional finance and DeFi\n\nTheorem Solver (SMT tools aim to solve the satisfiability modulo theories ( #short SMT) problem)\n\nNeeds to encode the DeFi model\nApply heuristics for path pruning\n\nSandwich attacks\n\nP1 changes X to Y (value of X decreases and of Y increases)\nP2 changes also X to Y (value of X decreases even more and of Y increases more)\nP1 changes Y to X (gets more X out bc. Y is more valuable then before)\n\nprotection\n\noptimised trade execution\n\n+ simple\n- limited scope\n\ntrusted third party ordering\n\n+ efficient\n- no decentralisation\n\ncommittee ordering\n\n+ fairly efficient\n- reduced decentralisation\n\ncommit &amp; reveal\n\n+ secure\n- costly &amp; delay\n\nQuiz\n\nWhich of the following properties is NOT a desired property for AMM?\n\nno pool fees [correct bc. AMM pool should have some fees]\ninstant liquidity, irrespective of the trade size\npurchase of an asset decreases the asset supply in AMM, and increases its market price\nthe expected increase or decrease in price is based on the trading volume and available liquidity\n\nWhich of the following is a property for a typical on-chain order book?\n\nno fees for order placements\nfront running resistance\nimpermanent loss [there is no impermanent loss in an order book bc. market makers can fill the orders and thus liquidity cannot just be removed; this is rather in an AMM]\nnon-custodian ( #german Verwalter/Aufseher) settlement [correct bc. swapping of assets is non-custodial meaning you own your coins with your private key, there is no custodian doing the settlement]\n\nWhich of the following statements is incorrect\n\nUnexpected slippage can only cause a worse execution price [correct]\nunexpected slippage is caused by price change after a trade has been broadcast but before it has been confirmed\ntrades can configure a slippage protection threshold to limit the total slippage (expected + unexpected)\nThe concept of slippage is typically unavoidable in financial markets\n\nWhat is TURE about impermanent loss?\n\nimpermanent loss cannot result in the total loss of funds.\nTrading fees can never compensate the impermanent loss.\nImpermanent loss is impermanent bc. it's only realised upon a withdrawal from a liquidity pool. [correct]\nImpermanent loss is only a fictive accounting phenomenon and never materialises in a loss.\n\nBack-running describes the process where an adversary attempts to execute its own transaction immediately after the victim's transaction executes. For example, given two exchange markets A and B, both trading ETH/USD at a price of 1000. If a victim's trad (with a as price of 100GWei) is expected to push exchange A's price to 1100 ETH/USD, the adversay can attempt to back-run the victim to perform arbitrage between A and Ab. Which of the following method will have the highest back-running success rate?\n\nBroadcast the back-running transaction immediately after the victim's transaction with 99GWei\nBroadcast the back-running transaction immediately after the victim's transaction, with 100GWei\nSend a private back-running transaction to private relayer services, and bribe the miners to perform the back-run\n(i) broadcast the back-running transaction immediately after the victim with 100GWei, and also (ii) send the transaction to private relayer services and bribe the miners [correct]",
		"tags": ["short", "short", "short", "short", "german", "note"]
},

{
		"title": "DF L5 Lending & Stablecoins",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l5-lending-and-stablecoins/",
		"content": "added multiple things in <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/df-definitions/\">DF Definitions</a>\n\nHow economic machine works\n#video How The Economic Machine Works by Ray Dalio\n\nTransaction: money, credit &lt;=&gt; goods, services, financial assets\n\ntransactions drive economy\nneeds buyers and sellers\n\nspecial actors\n\ncentral bank:\n\ncan print money\nsets interest rates\n\nstate: greatest buyer\n\ncredit\n\nmost important part bc. biggest and most volatile part\nneeds lenders and borrowers\n\nprincipal: amount lend\ninterest: additional amount to pay back for principal\n\ndebt is created with it\ncredit creates spending =&gt; drive economy\nwithout credit: growth can just come from more productivity\nwith credit: growth can come from more productivity and more spending through borrowing/credit =&gt; creates cycle\nbad when it supports overconsumption and cannot be paid bad e.g. big TV\ngood when it efficiently allocates resources e.g. tractor to harvest more crops\n\neconomic growth due to cycle of: (more) income =&gt; borrowing =&gt; spending =&gt; productivity =&gt; ...\ninflation when prices rise\n\ntoo much inflation causes problems =&gt; central bank rises interest rates =&gt; fewer people can borrow money =&gt; borrow less =&gt; less spending =&gt; prices go down =&gt; deflation =&gt; recession =&gt; decrease interest rates =&gt; more borrowing =&gt; inflation =&gt; ...\n\ndeflation when prices decrease\ndeleveraging\n\nworse than recession bc. lowering interest rates doesn't work (not rly. possible to go under 0%)\nbeautiful deleveraging through properly applying counter actions =&gt; debt declines same as income\n\ndeflationary (cut spending and dept + redistribution) and inflationary (printing money) actions are in balance\nincome needs to grow faster than debt grows =&gt; people are creditworthy again\ngrowth is slow but debt shrinks\n\npossible counter actions\n\ncut spending: has opposite effects bc. less spending =&gt; less income (for another person) =&gt; lower wages and unemployment =&gt; can pay back less\n\nand lenders notice that borrowers probably cannot pay back everything =&gt; don't lend anything anymore\n\ncut dept\n\nlenders don't want that and &quot;alternatives&quot; are: less paid back, over longer time frame, reduced interest rate\nalso deflationary bc. everything loses value and so borrowers still, also with less debt, won't have enough to pay back (even less)\n\nredistribution: government has to pay for unemployment and want's to set economic stimulus =&gt; needs more money generally tries to raise taxes for wealthy (bc. wealth is concentrated), but wealthy don't like that too much...\n\nrevolution/class conflict evolves =&gt; maybe army and/or (strong) political change e.g. Hitler after 1930s in Germany\n\nprint money: last alternative bc. interest rates are already lowered as much as possible\n\ninflationary and stimulates economy\nto buy financial assets and government bonds\n\njust helps those who own financial assets bc. central bank can only buy financial assets\n\ncentral bank can cooperate with central government through buying government bonds to spend money on goods and services =&gt; money for people\n\nvery risky\n\ndoesn't have to result in inflation, when credit shrinks the same amount and thus spending is not higher\n\nreflation (after deleveraging)\n\nca. 7-10 year (lost decade) (maybe just after a &quot;beatauiful&quot; deleveraging)\n\nLecture (graphics)\n\neffects one-by-one\neffects combined\n\nLending\nOn-Chain lending &amp; borrowing\n\nFlash loan\n\nflash loan should be taken and repaid in one single transaction\n\nnot directly time bound rather has to happen within one block building process\nif it cannot be paid back =&gt; entire transaction is invalid\n\nlender is secure\n\nUse cases\n\nDeFi attacks\n\nprice oracle manipulation\npump and dump (buy another coin to make them look like as more valuable/have more transactions for a short amount of time)\n\n(risk-free) arbitrage\nwashtrading\nflash mining\ncollateral swapping\nliquidation\n\nwhen liquidator doesn't have cryptocurrency upfront to repay\nonly works when liquidation completes in one transaction\ne.g.\n\nLiquidation\nin traditional finance\n\npass resolution for voluntary liquidation can be done by board of executives\nadministration of liquidation are e.g. the not paid electricity bills\ntakes a long time maybe even years\n\nFixed spread liquidation\n\ncan be completed in 1 transaction\nrepays debts of borrowing position\nacquires collateral at a discounted price from the position in return\n\ntypically discounts are e.g. 5-15% (called fixed spread) in Aave ( #disclaimerN probably meant average with it)\n\nprice oracles for getting prices: on and off chain oracles possible/depending on currency\n\nQuiz\n\nHow long does a flash loan last?\n\nDuring one block\nDuring one transaction [correct]\nFrom transaction signature until the transaction is mined\nas long as you want\n\nWhat is TRUE?\n\nLiquidations are typically done optimally.\nThe close factor is the minimum proportion of debt that can be repaid in a liquidation. [false bc. it's the maximum proportion... and you can also liquidate less]\nA flash loan has no fees\nTransaction fees for a flash loan are on the order of 100 USD, even if the loan amounts can grow beyond 1B USD. [correct]\n\nWhat can flash loans be used for?\n\nWashtrading [correct]\npumping a coin [false bc. you can just do pumping and dumping together, not individually]\ndumping a coin\nforking a blockchain\n\nWhich of the following liquidation strategies best describes an optimal fixed spread liquidation strategy?\n\nthe liquidation first performs an oracle price update, and then atomically performs the liquidation\nthe liquidator liquidates the position up to the close factor (when the close factor drops below 1, the position becomes available for liquidation)\nperform two liquidations. The first one keeps the close factor below 1, such that the second liquidation can also successfully execute [correct ]\nperform three liquidations, two keeping the CF below 1, while the last one also successfully executes\n\nWe define a borrowing position as a bad debt if it is financially rational for neither the borrowers nor the lending platform to close the position. Which of the following is not a cause for bad debt?\n\nif the collateral value falls below the value of the debt.\nif the value of excess asset used for over-liquidation cannot cover the liquidation transaction fee.\nif the debt has not been repaid for a long time. [correct bc. time component has no impact on bad dept]\nif the value of the debt grows more than the value of the collateral.",
		"tags": ["video", "disclaimerN", "note"]
},

{
		"title": "DF L6",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/df-l6/",
		"content": "Economic models\n\nrepresents (often simplifies) an economic process\ncontains <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/df-l6/#variables\">#Variables</a>\nlogical/quantitative relationships between variables\nexample: inflation\n\nmeasuring inflation requires a behaviour model bc. it depends on behaviour of individuals e.g. what/how much food they buy =&gt; how money is used\ndifferentiate relative vs. inflation price change\n\nVariables\n\nInterest rate(s) in CeFi and DeFi\ncryptocurrency price\ncollateral ratio\nDeFi protocol fees\nblockchain transaction fees\nnumber of users\nblockchain transaction throughput\n...\n\nExogenous vs. endogenous\n\nExogenous variable == outside force\n\ndetermined outside model, imposed on model\ne.g. in MakerDAO, asset price of collateral (e.g. ETH), is independent of the MakerDAO system\n\nEndogenous variable == inside the model\n\nStablecooins\nTypes\n\nTypes\n\nReserved-based e.g. USDC by a bank\ncollateral-based: e.g. MakerDAO\nalgorithmic e.g. AMPL\n\nMakerDAO\n\nto be profitable: assumption that ETH goes up and you can get even more with this DAI =&gt; with drawn DAI get even more ETH =&gt; later change back and have more in all\n\nAmpleforth\n#short AMPL\n\nsystemic implications #ToDo don't know yet\n\nUSDC and USDT\n\ndestroys coins\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/semester4/df/decentralised-finance/#bank-run\">Decentralised Finance#Bank run</a>\n\nQuiz\n\nWhich stable coin is the most stable? ( #remarkN atm)\n\nUSDC [correct]\nDAI\nAMPL\nETH\n\nWhich of the following statements is False?\n\nSeveral algorithmic stablecoins have depegged.\nDAI is a collateral based stablecoin, where e.g. ETH is used as collateral\nWBTC token prices should be pegged to BTC price\nETH is more stable than USDC [correct]\n\nWhat happens in AMPL system when 1 AMPL is worth less than 1 USD\n\nThe supply of AMPL is increase (expansion)\nThe supply of AMPL is decreased (contraction) [correct: if AMPL is more scarce, it should be worth more =&gt; less difference to USD]\nno action is taken (equilibrium)\nadditional collateral is required\n\nHow does the AMPL stablecoin reduce or increase the account balances of the token holders?\n\nThe ERC20 contract controls the balances and can modify them. [correct]\nThe ERC71 contract controls the balances and can modify them.\nevery user must individually approve each account balance change before rebalancing\nAMPL rebalances the token supply through arbitrage with USDC.\n\nIf the reserve ratio of a bank is 0.2 and the total money deposited by bank customers is $500,000, how much money is held by the bank?\n\n$100,000 [correct bc. 0.2 = 100'000/500'000 or 0.2 * 500'000 = 100'000]\n$250,000\n$400,000\n$1,000,000",
		"tags": ["Variables", "short", "ToDo", "remarkN", "note"]
},

{
		"title": "Decentralised Finance",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/decentralised-finance/",
		"content": "Promises\n\nInclusivity and Access:\n\nprovide financial services to individuals globally, including those who are unbanked or underbanked\npotentially bridge the gap between traditional financial systems and individuals who lack access to banking services\n\nPermissionless Innovation:\n\nplatforms are often open-source and permissionless, allowing developers to create and deploy financial applications without requiring approval from centralized authorities =&gt; rapid innovation and the creation of diverse financial products\n\nReduced Costs:\n\neliminating intermediaries and automating processes through smart contracts\npotential to reduce transaction costs associated with traditional financial services, such as remittances, loans, and trading\n\nDecentralized Identity and Privacy:\n\nleverage decentralized identity solutions, enhancing user privacy and reducing the reliance on centralized entities for identity verification\nUsers can control access to their personal information\n\nFinancial Empowerment:\n\nempower individuals by providing them with greater control over their financial assets\nUsers have custody of their private keys and can engage in financial activities without relying on traditional intermediaries\n\nTransparency: Blockchain technology, provides transparency by allowing users to trace transactions on a public ledger =&gt; enhance trust and accountability within the financial system\nInteroperability: platforms often operate on open and interoperable blockchain networks =&gt; allows different DeFi applications to seamlessly integrate with each other, creating a more interconnected and efficient financial ecosystem\nLiquidity Provision: platforms often use decentralized exchanges and liquidity pools, allowing users to provide liquidity and earn returns =&gt; creates new opportunities for individuals to participate in the financial ecosystem\n\nBank run\n\nin CeFi\n\ndangerous if fractional reserve\nmost clients don't receive assets\n\nin DeFi\n\nevent: USDT blacklists a pool, stablecoin de-pegs\ntraders will exit pools\nthose who exit first receive the best prices\ntry to build blacklist detection bots",
		"tags": [ "note"]
},

{
		"title": "Financial Markets",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/df/financial-markets/",
		"content": "Some things\nWhy?\nFinancial market serves several purposes, including:\n\nRaising capital: The financial market provides a platform for companies and governments to raise funds from investors in the form of equity or debt, which can be used to finance their operations or investment projects.\nPrice discovery: The financial market facilitates the determination of the prices of financial assets, based on the supply and demand of these assets. This price discovery process helps investors and market participants make informed investment decisions.\nLiquidity: The financial market provides liquidity to investors, allowing them to easily buy and sell financial assets such as stocks, bonds, and currencies. This enables investors to quickly and easily adjust their portfolios in response to changing market conditions.\nRisk management: The financial market allows investors to hedge against risks such as market volatility, inflation, and interest rate changes, by trading financial instruments such as options, futures, and swaps.\nEconomic growth: The financial market plays a crucial role in promoting economic growth by providing capital to companies and governments, which can be used to finance new projects and create jobs. This, in turn, can lead to increased economic activity and higher standards of living for individuals.\n\nMain stakeholders\n\nInvestors: Investors are individuals or entities who provide capital to companies and governments in exchange for financial assets, such as stocks, bonds, and other securities. Investors can be individual or institutional, such as pension funds, insurance companies, and mutual funds.\nIssuers: Issuers are companies or governments that offer financial assets to investors in order to raise capital. Issuers can issue debt in the form of bonds or equity in the form of stocks.\nIntermediaries: Intermediaries are entities that facilitate the trading of financial assets between investors and issuers. Examples of intermediaries include banks, broker-dealers, and stock exchanges.\nRegulators: Regulators are government agencies that oversee the financial market to ensure that it operates fairly and efficiently. Regulators set rules and guidelines for financial institutions and investors, and monitor the market to detect and prevent fraud and misconduct.\nMarket data providers: Market data providers are entities that collect and disseminate information about the financial market, including prices, trading volume, and other market data. This information is used by investors, issuers, and regulators to make informed decisions about the market.\n\nUnderlying assumptions from Economics\n\n(1) Rational Expectations: Based on perfect information\n\nEconomic actors will not make systematic mistakes in predicting the future (risks)\nEveryone uses the «right» model for forecasting\nThe future can be inferred from the past and present\n\n(2) Efficient Financial Market Theory: Asset prices represent the best possible estimates of the risks attached to them\n\nThe risk characteristics from financial markets can be inferred from mathematical analysis.\nMarket discipline can be used as an efficient tool in constraining harmful risk taking. Markets are self-correcting.\n\nWhy vulnerable?\nThe financial market is vulnerable to a variety of factors and risks, including:\n\nSystemic risks: These are risks that affect the entire financial system, rather than individual institutions or investors. Systemic risks can arise from a variety of sources, such as market volatility, geopolitical events, or regulatory changes.\nMarket risks: Market risks refer to the risk of losses due to changes in market conditions, such as changes in interest rates, exchange rates, or commodity prices.\nCredit risks: Credit risks refer to the risk of default by borrowers or issuers of debt securities. This can be due to factors such as financial distress, economic downturns, or changes in the creditworthiness of borrowers.\nOperational risks: Operational risks refer to the risk of losses due to internal failures of financial institutions, such as fraud, errors, or system failures.\nLiquidity risks: Liquidity risks refer to the risk that investors will not be able to buy or sell financial assets at fair market value due to a lack of market liquidity. This can lead to losses or a decrease in portfolio value.\nCybersecurity risks: With the increasing use of technology in the financial market, cybersecurity risks have become a significant concern. Cyber attacks on financial institutions can lead to the loss of sensitive data, financial theft, and disruption of market activity.\nOverall, the financial market is vulnerable to a wide range of risks, and investors and financial institutions must take steps to manage these risks in order to protect themselves and the broader financial system.",
		"tags": [ "note"]
},

{
		"title": "Unit type",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/atoms/unit-type/",
		"content": "#source #wikipedia Unit type\n\nIn the area of mathematical logic and computer science known as type theory, a unit type is a type that allows only one value (and thus can hold no information)\n\nProgramming languages\nHaskell\n\nThe () type can be thought of as a zero-element tuple. It's a type that can only have one value, and thus it's used where you need to have a type, but you don't actually need to convey any information. Here's a couple of uses for this.\n- #stackoverflow Neil Brown on StackOverflow\n\n#stackoverflow Longer explanation, also on types and expression language, besides ()",
		"tags": ["source", "wikipedia", "stackoverflow", "stackoverflow", "note"]
},

{
		"title": "FMFP Interpreters",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/fmfp-interpreters/",
		"content": "conceptually simple: read =&gt; evaluate =&gt; print\nconcretisation less trivial:\n\nMini-Haskell interpreter\nParsing\n\nparser constructs an abstract syntax tree ( #short AST)\n\nin Haskell: element of data type\nfurther processing depend on application but in general: conversion happens between data types e.g.\n\nCompiler: AST → CODE\nCalculator: AST → Int\nMini-Haskell: AST → AST\n\nin ghci there are additional phases such as dependency analysis, type checking, ...\n\nCombinatory parsing\n\nIdea: modular construction and composition of parser functions\n\nuses lazy &amp; higher-order programming\nuses monads to package &quot;higher-order plumbing&quot;\n\nParser type\n\nparser is a function taking a string as input\nresult is an element of type a (typically a data type like Expr)\nparser may process only part of input, leaving a remainder\n\nsupport composition: pparses first part and q continues\n\nallow multiple results from parsing via list of successes\n\ndata Parser a = Prs (String -&gt; [(a,String)])\n\nparse::Parser a -&gt; String -&gt; String -&gt; [(a,String)]\nparse (Prs p) inp = p inp\n\n-- interested in result of first complete parse\ncompleteParse :: Parser a -&gt; String -&gt; a\ncompleteParse p inp\n\t| results == [] = error &quot;Parse unsuccessful&quot;\n\t| otherwise = head results\n\twhere results = [res | (res,&quot;&quot;) &lt;- parse p inp]\n\ncomplete parse if pair with remainder &quot;&quot;\n\nprimitive parsers\n\nserving as basic building blocks\n\n-- Fails trivially ([] signifies ‘unsuccessful parse’):\nfailure :: Parser a\nfailure = Prs (\\inp -&gt; [])\n\n-- Succeeds trivially without progress:\nreturn :: a -&gt; Parser a\nreturn x = Prs (\\inp -&gt; [(x,inp)])\n\n--Succeeds trivially with progress:\nitem :: Parser Char\nitem = Prs (\\inp -&gt; case inp of\n\t\t\t\t\t\t&quot;&quot; -&gt; []\n\t\t\t\t\t\t(x:xs) -&gt; [(x,xs)])\n\n-- Parse a single character with property p\nsat :: (Char -&gt; Bool) -&gt; Parser Char\nsat p = Prs (\\inp -&gt; case inp of\n\t\t\t\t\t\t&quot;&quot; -&gt; []\n\t\t\t\t\t\t(x:xs) -&gt; if p x then [(x,xs)] else [])\n\n--Chars and Strings (including simpler definition of sat)\nsat :: (Char -&gt; Bool) -&gt; Parser Char\nsat p = item &gt;&gt;= \\x -&gt; if p x then return x else failure\n\nchar :: Char -&gt; Parser Char\nchar x = sat (==x)\n\nstring :: String -&gt; Parser String\nstring &quot;&quot; = return &quot;&quot;\nstring (x:xs) = char x &gt;&gt; string xs &gt;&gt; return (x:xs)\n\n-- Repetition\nmany :: Parser a -&gt; Parser [a] -- 0 or more repetitions of p\nmany p = many1 p ||| return []\n\nmany1 :: Parser a -&gt; Parser [a] -- 1 or more repetitions of p\nmany1 p = p &gt;&gt;= \\t -&gt; many p &gt;&gt;= \\ts -&gt; return (t:ts)\n\n-- more readable use of &gt;&gt;-\nmany1 p = do t &lt;- p\n\t\t\t ts &lt;- many p\n\t\t\t return (t:ts)\n\nnumPos :: Parser Int\nnumPos = do ts &lt;- many1 (sat isDigit)\nreturn (read ts) --- read maps numeric string to number\n\nnumNeg :: Parser Int\nnumNeg = do char ’-’\n\t\t\tt &lt;- numPos\n\t\t\treturn (-t)\n\t\t\t\nnum :: Parser Int\nnum = numPos ||| numNeg -- or: numPos +++ numNeg\n\nGluing parsers together\n-- Mutual selection: Apply both first and second parser\n(|||) :: Parser a -&gt; Parser a -&gt; Parser a\np ||| q = Prs (\\s -&gt; parse p s ++ parse q s)\n\n-- Alternative selection: If first parser fails, apply second parser\n(+++) :: Parser a -&gt; Parser a -&gt; Parser a\np +++ q = Prs (\\s -&gt; case parse p s of\n[] -&gt; parse q s\n\n-- Sequencing: first parser p then parser q to results\n(&gt;&gt;) :: Parser a -&gt; Parser b -&gt; Parser b\np &gt;&gt; q = Prs (\\s -&gt; [ (u,s’’) | (t,s’) &lt;- parse p s,\n\t\t\t\t\t\t\t\t(u,s’’) &lt;- parse q s’ ])\n-- but above results of first parser (t above) is lost bc. we just use the remainder further\n-- Solution: use as second argument a “parser generator” that takes as input the result of the first parser\n(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b\np &gt;&gt;= g = Prs (\\s -&gt; [ (u,s’’) | (t,s’ ) &lt;- parse p s,\n\t\t\t\t\t\t\t\t (u,s’’) &lt;- parse (g t) s’ ])\n\nambiguous grammars\n\nProblem: How should 2-3+4 be parsed?\nSolution\n\ndisambiguate grammar using associativity and precedence\ngive user ability to override defaults using parentheses\ncareful: left-recursive grammars lead to non-terminating recursion\n\nConcrete\n\nparse repeated operation/atom pairs after initial atom\nobtain left associativity using fold-left over list of these pairs\nuse concrete grammar to build abstract syntax tree of type data Expr = Lit Int | Add Expr Expr | Sub Expr Expr\n\nλ-calculus\n\nprograms are terms\nformalising core\n\nenough to construct all others\n\nParsing λ-terms\n\ndata type for λ-calculus terms\n\ndata Term = Id String | Ap Term Term | Lam String Term\n\t\t\tderiving Show\n\natom = ident ||| lamb ||| paren\n\nident = do id &lt;- identifier\n\t\t\treturn (Id id)\n\nterm= do t &lt;- atom -- t\n\t\tts &lt;- many atom -- [t1 t2 ... tn]\n\t\treturn (foldl Ap t ts)-- Ap(Ap(Ap(t t1) t2) ... tn)\n\nlamb= do token &quot;%&quot;\n\t\t ids &lt;- many1 identifier -- [x1, x2, ..., xn]\n\t\t token &quot;.&quot;\n\t\t t &lt;- term -- t\n\t\t return (foldr Lam t ids) -- Lam x1 (Lam x2 (...(Lam xn t)))\n\nparen = do token &quot;(&quot;\n\t\t t &lt;- term\n\t\t token &quot;)&quot;\n\t\t return t\n\nstr2term s = completeParse term s\n\napplication t1t2 produces left recursion (prefix-syntax simpler)\nsyntax without left-recursion\n\nWe use % and . instead of \\ and -&gt;, respectively\nExplicit parentheses\nEvery parsing starts with an identifier, or symbols ‘%’ or ‘(’\n\nExamples\n\nSubstitution in Haskell\n\nmust respect free and bound variables\n\ne.g.\n\nHaskell implementation below (Alternative: use Haskell library Data.Set to implement free)\n\nfree :: Term -&gt; [String]\nfree (Id v) = sing v -- free (x) = {x}\nfree (Ap s t) = union (free s) (free t) -- free (M N ) = free(M ) ∪ free(N )\nfree (Lam v t) = diff (free t) (sing v) -- free (λx. M ) = free(M ) \\ { x }\n\nempty = []\nsing a = [a]\n\nmember [] _ = False\nmember (x:xs) a\n\t| x &lt; a = member xs a\n\t| x == a = True\n\t| otherwise = False\n\nunion [] ys = ys\nunion xs [] = xs\nunion (x:xs) (y:ys)\n\t| x &lt; y = x : union xs (y:ys)\n\t| x == y = x : union xs ys\n\t| otherwise = y : union (x:xs) ys\n\ndiff [] _ = []\ndiff xs [] = xs\ndiff (x:xs) (y:ys)\n\t| x &lt; y = x : diff xs (y:ys)\n\t| x == y = diff xs ys\n\t| otherwise = diff (x:xs) ys\n\n-- subst t v s = t[v -&gt; s]\nsubst :: Term -&gt; String -&gt; Term -&gt; Term\nsubst (Id x) v s = if x == v then s else Id x\nsubst (Ap t1 t2) v s = Ap (subst t1 v s) (subst t2 v s)\nsubst (Lam x t) v s\n\t| x == v = Lam x t\n\t| not (member (free s) x) = Lam x (subst t v s)\n\t| otherwise = Lam z (subst (subst t x (Id z)) v s)\n\twhere z = fresh (union (free t) (free s))\n\t\tfresh m = (foldr max &quot;&quot; m) ++ &quot;’&quot; -- returns id not in m\n\nSubstitution\nβ-reduction\n\nβ-reduction is rule for simplifying redexes: (λx.M)N↪M[x↦N]\n\nredex is a term like (λx.M)N\ncontractrum is the result i.e. M[x↦N]\n\ne.g. (λx.f(xx))N↪f(NN)\n\nEvaluation strategies\n\nt1t2 represents the first application of a function to an argument\n\nfirst evaluate t1:t1↪r1\nIf r1≠λx.r then throw an exception (or return application)\n\nstrategy 1: Eager\n\nevaluate t2 prior to β-reduction: t2↪r2 meaning (λx.r)r2↪r[x↦r2]\nevaluation carried out under an abstraction (λx.t)\n\nstrategy 2: Lazy\n\napply β-reduction to r1t2 i.e. substitute t2 without evaluation meaning (λx.r)t2↪r[x↦t2]\nno evaluation under an abstraction\nresult of β-reduction is then further evaluated\n\nbeta (Lam x t) t’ = subst t x t’\neager :: Term -&gt; Term\neager (Id x) = (Id x)\neager (Ap t t’) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; eager (beta r r’)\n\t\t\t\t\t_ -&gt; Ap r r’\n\twhere r = eager t\n\t\t r’ = eager t’\neager (Lam x t) = Lam x (eager t)\n\nlazy :: Term -&gt; Term\nlazy (Id x) = (Id x)\nlazy (Ap t t’) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; lazy (beta r t’)\n\t\t\t\t\t_ -&gt; Ap r t’\n\twhere r = lazy t\nlazy t = t -- no evaluation under a lambda abstraction\n\neager evaluation in lazy language\n\nHaskell is lazy and doesn't fully evaluate omega, since not needed to produce result\nsolution: use strict function application f $! x is like f x but forces evaluation of its argument x (up to first constructor)\n\neager :: Term -&gt; Term\neager (Id x) = (Id x)\neager (Ap t t’) = case r of\n\t\t\t\t\t(Lam _ _) -&gt; eager ((beta $! r) $! r’)\n\t\t\t\t\t_ -&gt; (Ap $! r) $! r’\n\twhere r = eager t\n\t\t r’ = eager t’\neager (Lam x t) = Lam x $! (eager t)\n\nMore on Haskell and interpreters",
		"tags": ["short", "note"]
},

{
		"title": "Haskell",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/haskell/",
		"content": "operators\n\nhave diff. binding strength e.g.\n\n^ binds stronger than + see ? 2 + 3^2 =&gt; 11\nnot stronger than &amp;&amp; and ||\n\norder and equality return True or False of type Bool\n\nsame as in other programming languages but\n\n/= unequal\n\nTypes\nInt\n\nInt type with at least the range {−229,…,229−1}\n\nsupport for unbounded and arithmetic: Integer\n\nbool\n\nvalue: True, False\n\nChar\n\ne.g. 'a','0','\\t'\n? ord 'a' =&gt; 97 or ? chr 97 =&gt; 'a'\n\nString\n\ne.g. &quot;hello&quot;, &quot;123&quot;\n? &quot;Hello &quot; ++ &quot;there&quot; =&gt; &quot;Hello there&quot;\n\nDouble\n0.3456, -2.85e03\nTuple\n\nused to model composite objects (&quot;records&quot;)\nexample of a type constructor\n\nif T1,…,Tn are types, then (T1,…,Tn) is a (tuple) type\n\nList\n\nIf T is a type then [T] is a type\nempty list: []::[T]\nnon-empty list (x:xs)::[T] if x::T and xs::T\nabbreviations\n\n? [3..6] =&gt; [3,4,5,6]::Int\n`? [6..3] =&gt; []::Int\n[n, p..m] means count from n to m in steps of p−n\n\n? [7,6..3] =&gt; [7, 6, 5, 4, 3] :: [Int]\n? [0.0, 0.3 .. 1.0] =&gt; [0.0,0.3,0.6,0.8999999999999999] :: [Double]\n\nx:[y] appends an element x to a list [y]\n[x]++[y] concatenates two lists\n\nDifference lists\n\nfunction [a] -&gt; [a] that prepends a list to its argument\ne.g.\nimplementation\n\nOwn types\n\ntypes always start with a capital letter\ntype Person = String\ntype Database = [(Person,Book)]\n\nClass\n\ndefines a set of types\nelements of the class are called instances\n\nExamples\nallEqual :: Eq t =&gt; t -&gt; t -&gt; t -&gt; Bool -- where Eq is a class\n\nFunctions\n\nif argument doesn't matter use _ e.g. f a _ = a for f :: Int -&gt; Int -&gt; Int\nevaluation by\ngeneric type definition possible e.g. ownLength :: [a] -&gt; Int where a is the generic type\ndo when function has side-effects e.g. in IO\nown e.g.\n\nsumList::[Int] -&gt; Int\nsumList [] = 0 -- also handle the empty list case\nsumList (x:xs) = x + sumList xs\n\nstandard ones:\n\nlength\nappend\n[2] ++ [3,4,5] =&gt; [2,3,4,5]\n? 2 : [3,4,5] =&gt; [2,3,4,5] but ? [2] : [3,4,5] =&gt; Error\n\nHow to use\nInfix binary\nInfix binary function is also called an &quot;operator&quot; ? 7 'mod' 2\nprefix\nOperators can also be written in prefix notation: ? (+) 3 4\nExamples\n\n(e.g. for Int) +, * , ^, -, div, mod, abs\n\nevaluate by ? mod 7 2 =&gt; 1\n\nbranches\n\nif test then a else b\n\na and b have to be of same type\n\nmulti case\n\ndefined using other operators: f x y = (x || y) &amp;&amp; not (x &amp;&amp; y)\ndefined using guards\n\nf x y\n| x = not y\n| otherwise = y\n\ndefined using multiple cases (new)\n\npriority from above down\nexception, if one case is not covered but it's used\n\nf True True = False\nf True False = True\nf False True = True\nf False False = False\n\ncases can contain variables\n\nf True y = not y\nf False y = y\n\nf 0 = 1\nf 1 = 2\nf x = x*x\n\nAdvice on recursion\n\nDefining recursive functions is like riding a bicycle: it looks easy when someone else is doing it; it may seem impossible when you first try to\ndo it yourself, but becomes simple and natural with practice.”\n- G. Hutton, Programming in Haskell\n\nHigher-order functions\n\njust higher order, if function takes function(s) as input\n\nλ-expression\n\nfor writing functions in-line\n\ngood for when functions are just used once and rather short\n\nInput-Output\n-- putStrin :: String -&gt; IO()\n\n-- getLine :: IO String\n\n-- read String :: t, where t is a type and it tries to convet String to this type\n\n-- show a =&gt; String of a\n\nfunc1 = do\nputStrLn &quot;Test&quot;\nn &lt;- getLine\nputStrLn (&quot;Text: &quot; ++ show (func2 (read n :: Int)))\n\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Monads#Input/Ouput</a>\n\nOther\nShell\n\nghci: open\n:load name-of-file.hs load modules from file\nreload loads last file again (e.g. after changing functions)\n\nLazy Evaluation\n\nHaskell uses Lazy evaluation\npossible problem of lazy evaluation is duplicated computation: avoided by simultaneously reducing both occurrences\nSummary: function arguments are evaluated only when needed and at most once\n\nCool applications\n\ncompute with infinite data in finite time\nimplementation of sieve of Eratosthenes\n\n2D layout\n\nspaces are important don't use TABs (in modern IDEs it should be okay, but this maybe a reason for an erroneous program)\nindentation determines separation of definitions\n\nall function definitions must start at same indentation level\nif a definition requires n &gt; 1 lines, indent lines 2 to n further\nrecommended layout\n\nPatterns\n\npurposes\n\nchecks if argument has proper form\nbinds values to variables\n\nRules\n\npatterns are inductively defined\npattern required to be linear i.e. each variable can occur at most once\nExamples: [(x,foo),_] , ((x,y),_) , 1:(2:(x,y))\nCounterexamples: (x ++ y, z) , [x,y,z,x]\n\nList comprehension\nNotation for sequential processing of list elements\n\nanalogous to set comprehension in set theory {2⋅x|x∈X}\nHaskell notation [2*x| x &lt;- xs]\ncan be augmented with guards: [2*x | x &lt;- xs, pred1(x), ...]\n\nExamples\n\n(x:xs) matches with [2,3,4] as x=2 and xs=[3,4]\n? let ([x,y,z],t) = ([1,2,3],(20,30)) in x + y =&gt; 3 :: Int\n? [2*x | x &lt;- [1,2,3,4,5]] =&gt; [2,4,6, 8, 10]\n? [n ‘mod‘ 2 == 0 | n &lt;- [2,4,7]] =&gt; [True,True,False]\n? [2*x | x &lt;- [0,1,2,3,4,5,6], x ‘mod‘ 2 == 0, x &gt; 3] =&gt; [8,12]\neasy quick sort^^\n\nq [] = []\nq (p:xs) = q [x | x&lt;-xs, x &lt;= p] ++ [p] ++ q [x | x&lt;-xs, x &gt; p]",
		"tags": [ "note"]
},

{
		"title": "FMFP L1",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l1/",
		"content": "Functional programming\n\nbasic concepts\n\nfunction (which are values itself) #aka first order citizens\nvalues\n\nexample programming languages: Haskell\n\nAdvantages\n\neasier to reason about bc. no state (changes) anymore\n\nno side effects\n\nreferential transparency every expression with same values evaluate to same expressions\nrecursion instead of iteration\nFlexible type system: many programming errors not possible (compile time error) e.g. 3 + TRUE, polymorphism supports reusability",
		"tags": ["aka", "note"]
},

{
		"title": "FMFP L10",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/fmfp/lectures/fmfp-l10/",
		"content": "algebraic data types\n\ndata types defines a set of terms for each type instance e.g. Tree Int correspons to {Leaf, Node 0 Leaf Leaf, ...}\nalgebraic here means the smallest set S where Leaf∈S and x∈a∧t1∈S∧t2∈S⟹(Node xt1t2)∈S\nIntuition: set S is built in steps\n\nLeaf∈S and\n(Nodext1t2)∈S, where t1 and t2 in S in earlier steps\n\nStructural induction",
		"tags": [ "note"]
},

{
		"title": "WS L1",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l1/",
		"content": "Definitions\n\n[!info] #Def 1.2 Grundraum ( #aka Ereignisraum) ( #english sample space)\nΩ≠∅ ist die Menge alle möglichen Ergebnisse des betrachteten Zufallsexperiments.\n\nDie Elemente w∈Ω heissen Elementarereigniss #aka Ausgänge des Experiments #english outcomes\nWir sagen, dass ein Ereignis A eintritt, falls das realisierte Elementarereignis ω in A liegt d.h. ω∈A\n\n[!info] #Def 1.4 Die Potenzmenge ( #english power set)\nvon Ω, P(Ω) oder 2Ω, ist die Menge aller Teilmengen von Ω.\n\nEin prinzipielles Ereignis ( #english event) ist eine Teilmenge A⊆Ω, also eine Kollektion von Elementarereignissen\nDie Klasse aller (beobachtbaren) Ereignisse bezeichnen wir mit F. Das ist eine Teilmenge der Potenzmenge von Ω\n\nFalls Ω endlich oder abzählbar, dann ist oft F=P(Ω), und das ist ein diskreter Wahrscheinlichkeitsraum.\nFalls Ω überabzählbar, muss F eine echte Teilklasse von P(Ω) sein\nIn jedem Fall muss F gewisse Axiome erfüllen\n\n[!Info] #Def 1.5 σ-Algebra (manchmal σ-field)\nEin Mengensystem F⊆P(Ω) nennt man eine σ-Algebra, wenn\n\nΩ∈F\nfür jedes A∈F auch das Komplement A∁∈F ist\nfür jede Folge (An)n∈N mit An∈F,n∈N, auch die Vereinigung ∪n∈NAn∈F ist\n\n[!info] #Def 1.9 Wahrscheinlichkeitsmass ( #english probability measure)\nSei Ω ein Grundraum und sei F eine σ-Algebra. Eine Abbildung\nP:F→[0,1],mit A↦P[A]heisst Wahrscheinlichkeitsmass auf (Ω,F), wenn die folgenden Axiome erfüllt sind\n\nNormiertheit: P[Ω]=1\nσ-Additivität: P[∪n∈NAn]=∑n=1∞P[An] für paarweis disjunkte Mengen An, d.h. An∩Am=∅ für alle n≠m\n\n[!info] #Proposition 1.10\nFür ein Wahrscheinlichkeitsmass P auf (Ω,F) und Mengen A,B∈F gelten folgende Aussagen:\n\nP[A∁]=1−P[A], und insbesondere P[∅]=0\nMonotonie: wenn A⊆B, dann P[A]≤P[B]\nAdditionsregel: P[A]+P[B]=P[A∪B]+P[A∩B]\n\n[!info] #Def 1.12 Wahrscheinlichkeitsraum\nSei Ω ein Grundraum, F eine σ-Algebra und P ein Wahrscheinlichkeitsmass auf (Ω,F). Das Tripel (Ω,F,P) heisst Wahrscheinlichkeitsmass ( #english probability space)\n\n[!info] #disclaimer 1.13 Messbarer Raum ( #english measurable space)\nAllgemein verwenden wir in der Masstheorie folgende Terminologie:\n\nFür eine σ-Algebra A auf einer Grundmenge Ω wird das Paar (Ω,A) ein messbarer Raum genannt.\nElemente A∈A, also Teilmengen A⊂Ω, die wir messen wollen, heissen messbare Mengen ( #english measurable sets).\nAuf messbaren Räumen (bzw. den σ-Algebren) lassen sich Masse ( #english measures) μ definieren. Diese sind im Allgemeinen nicht auf 1 nomiert. Man verlangt staddessen μ(∅)=0.\nDas Tripel $(\\Omega,\\cal{A},\\mu) $ heisst Massraum ( #english measure space).\nIst das Mass normiert, μ(Ω)=1, dann ist das Mass ein Wahrscheinlichkeitsmass und der Messraum wird zum Wahrscheinlichkeitsraum.\n\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Diskrete Wahrscheinlichkeit</a>",
		"tags": ["Def", "aka", "english", "aka", "english", "Def", "english", "english", "Def", "Def", "english", "Proposition", "Def", "english", "disclaimer", "english", "english", "english", "english", "note"]
},

{
		"title": "WS L2",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l2/",
		"content": "[!info] #Def 1.22 Bedingte Wahrscheinlichkeit\nGegeben: Wahrscheinlichkeitsraum (Ω,F,P), P[B]&gt;0\nDann ist P[A|B]:=P[A∩B]P[B]\n\nP[A|A]=1\nP[A|Ω]=P[A]\nP[A∩B]=P[A|B]P[B]\nP[A|B] ist nicht definiert für P[B]=0\n\n[!info] #Theorem 1.25\nGegeben: Wahrscheinlichkeitsraum (Ω,F,P),P[B]&gt;0\nDann ist P∗:F→[0,1] definiert durch A↦P∗[A]:=P[A|B] wieder ein Wahrscheinlichkeitsmass auf (Ω,F)\n\nbedingte Wahrscheinlichkeit ist nicht symmetrisch in den beiden Argumenten. Insbesondere ist bei fixiertem Ereignis A die Funktion B↦P[A|B] kein Wahrscheinlichkeitsmass\nIst Ω endlich oder abzählbar mit F=P(Ω), dann ist P gegeben durch die Wahrscheinlichkeiten pn=P[{ωn}]. Das bedingte Wahrscheinlichkeitsmass P∗[⋅]=P[⋅|B] ist dann durchüüpn∗=P∗[{ωn}]=P[{ωn}|B]={pnP[B]für ωn∈B,0für ωn≠B,gegeben. Wir setzen alle Gewichte ausserhalb von B auf Null und skalieren die Gewichte in B mit einem festen Faktor, sodass ihre Summe wieder 1 ergibt.\n\n[!info] #Theorem 1.29 Satz von der totalen Wahrscheinlichkeit\nGegeben: B1,…,BN mit P[Bn]&gt;0 für jedes 1≤n≤N eine Partitione des Grundraums Ω, d.h. ⋃n=1NBn=Ω mit Bn∩Bm=∅ für n≠m.\nDann gilt für alle A∈F\nP[A]=∑n=1NP[A|Bn]P[Bn]\n\n[!info] #Theorem 1.32 Satz von Bayes\nGegeben: B1,…,BN∈F eine Partition von Ω mit P[Bn]&gt;0 für alle n.\nFür jedes Ereignis A mit P[A]&gt;0 und jedes n∈{1,…,N} gilt\nP[Bn|A]=P[A|Bn]P[Bn]∑k=1NP[A|Bk]P[Bk]\n\nSpezialfall n=2 mit Ω=B∪B∁ so ist\nP[B|A]=P[A|B]P[B]P[A|B]P[B]+P[A|B∁]P[B∁]\n\n[!info] Unabhängigkeit zweier Ereignisse\n(WS #Def 1.35)\nGegeben: (Ω,F,P) ein Wahrscheinlichkeitsraum\nZwei Ereignisse A und B heissen (stochastisch) unabhängig, falls\nP[A∩B]=P[A]P[B]\n\nFalls P[A]∈{0,1}, dann ist A unabhängig von jedem Ereignis\nFalls Ereignis von sich selbst unabhängig ist, dann muss P[A]∈{0,1} gelten. ( #disclaimerN (falls richtig) A von sich selbst unabhängig ⟺P[A]∈{0,1})\nA ist unabhängig von B⟺A unabhängig von B∁\n\n[!info] (WS #Proposition 1.37)\nGegeben: A,B∈F zwei Ereignisse mit P[A],P[B]&gt;0\nDann sind folgende Aussagen äquivalent:\n\n(i) P[A∩B]=P[A]P[B] d.h. A und B sind unabhängig\n(ii) P[A|B]=P[A] d.h. Eintreten von B hat keinen Einfluss auf A\n(iii) P[B|A]=P[B] d.h. Eintreten von A hat keinen Einfluss auf B\n\n[!info] Unabhängigkeit (WS #Def 1.40)\nGegeben: I eine beliebige Indexmenge\nEine Familie von Ereignissen ()Ai)i∈I heisst (stochastisch) unabhängig, wenn für alle endlichen Teilmengen J⊂I gilt: P[⋂j∈JAj]=∏j∈JP[Aj]\n\nfalls Menge unabhängig ⟹ Ereignisse paarweise unabhängig (Umkehrung gilt nicht!)\n\n[!info] Zufallsvariable (WS #Def 2.1)\nGegeben: Wahrscheinlichkeitsraum (Ω,F,P)\nEine (reellwertige) Zufallsvariable (Z.V.) ist eine Abbildung X:Ω→R, sodass für alle x∈R gilt,\n{ω∈Ω|X(ω)≤x}∈F",
		"tags": ["Def", "Theorem", "Theorem", "Theorem", "Def", "disclaimerN", "Proposition", "Def", "Def", "note"]
},

{
		"title": "WS L3",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l3/",
		"content": "[!info] #Def 2.1 Zufallsvariable\nGegeben: Wahrscheinlichkeitsraum (Ω,F,P)\nEine (reelwertige) Zufallsvariable ( #short Z.V.) ist eine Abbildung X:Ω→R sodass für alle x∈R gilt\n{ω∈Ω|X(ω)≤x}∈F\n\n[!info] #Remark 2.5 Messbarkeit\nWenn eine (reelwertige) Funktion die Eigenschaft (2.1) erfüllt, heisst diese Funktion messbar ( #english measurable).\nDa wir an Ausgängen von Zufallsexperimenten interessiert sind, wollen wir Wahrscheinlichkeiten der Form\nüP[{ω∈Ω|X(ω)∈B}] für bestimme Mengen B⊂Rberechnen können. Z.B.\n\nFalls B={2,4,6} wenn wir die Wahrscheinlichkeit für einen gerade Zahl beim Würfeln möchten.\nWeil das Wahrscheinlichkeitsmass P auf F definiert ist, müssen die Urbilder aller dieser Mengen B,\n\nX−1(B):={ω∈Ω|X(ω)∈B}in F enthalten sein.\n\nIn dieser Vorlesung verlangen wir für Messbarkeit, dass X−1(B)∈F für alle B∈B(R)\n\nHierbei ist B(R) die borelsche σ-Algebra auf R\nz.B. alle offenen, abgeschlossenen und kompakten Mengen in R oder alle Intervalle der Form (a,b),[a,b],(a,b],[a,b),(−∞,b),(−∞,b],(a,∞),[a,∞) für a,b∈R\n\n[!info] #Def 2.10 Verteilungsfunktion\nGegeben: reelwertige Zufallsvariable X, Wahrscheinlichkeitsraum (Ω,F,P)\nDie (kumulative) Verteilungsfunktion von X ( #english cumulative distribution function) ( #short cdf) ist die Funktion FX:R→[0,1], definiert durch\nFX(x):=P[X≤x]\n\n[!info] #Theorem 2.13 Eigenschaften von Verteilungsfunktionen\nGegeben: Zufallsvariable X, Wahrscheinlichkeitsraum (Ω,F,P)\nDie Verteilungsfunktion FX:R→[0,1] von X erfüllt folgende Eigenschaften:\n\n(i) FX ist monoton wachsend\n(ii) FX ist rechtsstetig d.h. für alle x∈R gilt FX(x)=limh→0FX(x+h)\n(iii) Es gelten die Grenzwerte limx→−∞FX(x)=0 und limx→∞FX(x)=1\nI also found\nwikipedia\n\nP(X≤x)=FX(x)\nP(a&lt;X≤b)=FX(b)−FX(a)\nP(X=b)=FX(b)−limx→b−FX(x)\n\nMath Stackexchange\n\nP(a&lt;X&lt;b)=P(X&lt;b)−P(X≤a)=limx→b−FX(x)−FX(a)\n\n[!info] #Def 2.16 Gemeinsame Verteilungsfunktion\nGegeben: Zufallsvariablen X1,…,Xn\nDie gemeinsame Verteilungsfunktion von X1,…,Xn ist die Abbildung F:Rn→[0,1] definiert durch\n(x1,…,xn)↦F(x1,…,xn)=P[X1≤x1,…,Xn≤xn]\n\n[!info] #Def 2.18 <a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Unabhängigkeit</a> von Zufallsvariablen\nGegeben: Zufallsvariablen X1,…,Xn auf Wahrscheinlicheitsraum (Ω,F,P). Dann heissen X1,…Xn unabhängig, wenn für alle x1,…,xn∈R gilt\nP[X1≤x1,…,Xn≤xn]=P[X1≤x1]∗⋯∗P[Xn≤xn]\n#Remark 2.19 X1,…,Xn sind genau dann unabhängig, wenn für alle Intervalle I⊂R,…,In⊂R die Ereignisse {X1∈I1},…{Xn∈In} unabhängig sind.\nWenn wir eine Menge unabhängiger Zufallsvariablen haben und disjunkte Gruppen solcher Zufallsvariablen bilden, dann sind diese Gruppen auch wiederum unabhängig voneinander.\n\n[!info] #Theorem 2.21 Gruppierung von Zufallsvariablen\nGegeben: unabhängige Zufallsvariablen X1,…Xn, Indexe 1≤i1&lt;i2&lt;⋯&lt;ik≤n, Abbildungen φ1,…,φk\nDann sind\nY1:=φ1(X1,…,Xi1),Y2:=φ2(X1,…,Xi2),…,Yk:=φk(X1,…,Xik)unabhängig.\n\n[!info] #Def 2.22. Unabhängig und identisch verteilt\nEine Folge von Zufallsvariablen X1,X2 heisst\n\nunabhängig falls X1,…,Xn für alle n∈N unabhängig sind.\nunabhängig und identisch verteilt ( #short u.i.v.) ( #english independent and identically distributed ( #short i.i.d.)) falls sie unabhängig ist und die Zufallsvariablen dieselbe Verteilungsfunktion haben d.h. für alle k,l∈N gilt FXk=FXl",
		"tags": ["Def", "short", "Remark", "english", "Def", "english", "short", "Theorem", "Def", "Def", "Remark", "Theorem", "Def", "short", "english", "short", "note"]
},

{
		"title": "WS L4",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l4/",
		"content": "Beweis zu Satz 2.13\n\nExistenzsatz von Kolmogorov und Folgen von i.i.d. Bernoulli Zufallsvariablen\n\n[!info] #Def 2.24 Bernoulli\nGegeben: p∈[0,1].\nEine Zufallsvariable X heisst Bernoulli Zufallsvariable mit Parameter p, wenn gilt\nP[X=0]=1−p und P[X=1]=pWir schreiben X∼Ber(p).\n\n[!info] #Theorem 2.26 Existenz von Kolmogorov\nEs existiert ein Wahrscheinlichkeitsraum (Ω,F,P) und eine unendliche Folge von i.i.d. Bernoulli Zufallsvariablen X1,X2,… auf (Ω,F,P) mit Parameter 12\n\n[!info] #Theorem 2.27.\nEine Zufallsvariable U heisst gleichverteilt auf [0,1], wir schreiben U∼U([0,1]), falls ihre Verteilungsfunktion gegeben ist durch\nFU(x)={0x&lt;0x0≤x≤11x&gt;1\n\nKonstruktion von gleichverteilten Zufallsvariablen auf [0,1]\n\n[!info] #Theorem 2.28\nDie Abbildung X:Ω→[0,1] definiert in Gleichung (2.3) ist eine gleichverteilte Zufallsvariable auf [0,1].\n\n[!Info]- Beweis\nEs ist schnell sichtbar, dass für alle ω∈Ω gilt, X(ω)∈[0,1]. Somit gilt für x&lt;0, dass FX(x)=P[X≤x]=0 und für x≥1, dass FX(x)=1\nSei also x∈[0,1) und sei {xn}n∈N ihre eindeutige Binärdarstellung wie in Lemma 2.29. Dann gilt\n{X&gt;x}={X1&gt;x1}∪{{X1=x1}∩{X2&gt;x2}}∪…Also entweder ist die erste Ziffer grösser oder die erste Ziffer ist gleich und die zweite ist grösser usw.\n\n[!info] #Lemma 2.29 Binärdarstellung\nJedes x∈[0,1) kann eindeutig in der Form\nx=∑n=1∞2−nxndargestellt werden, wobei für alle n∈N gilt,xn∈{0,1}, und für jedes N∈N gibt es ein k&gt;N, sodass xk=0 (als odie Folge &quot;endet&quot; nicht in unendlich vielen 1-en.) Die Folge {xn}n∈N heisst Binärdarstellung von x und wir schreiben x=(.x1x2…)2\n\nKonstruktion von Zufallsvariablen mit beliebiger Verteilungsfunktion F\nDa wir die Gleichverteilung auf [0,1] haben, würden wir nun gerne Zufallsvariablen mit beliebiger Verteilungsfunktion konstruieren können.\nGegeben: F:R→[0,1] eine Funktion, die die Eigenschaften (i)-(iii) aus Satz 2.13 erfüllt.\nFalls F streng monoton steigend und stetig ist, dann ist F bijektiv und es existiert eine Umkehrfunktion F−1. Für jedes α∈[0,1] ist x:=F−1(α) die eindeutige reelle Zahl, für die F(x)=α gilt.\nAllgemein kann die sogenannte verallgmeinerte inverse Verteilungsfunktion oder Quantil-Funktion für F definiert werden.\n\n[!info] #Def 2.30 Verallgemeinerte inverse Verteilungsfunktion\nDie Verallgemeinerte inverse Verteilungsfunktion von F ist eine Abbildung F−1:(0,1)→R definiert durch\nF−1(α)=inf{x∈R|F(x)≥α}\nNach Definition des Infimums und unter Verwendung der Rechtsstetigkeit von F gilt für jedes x∈R und α∈(0,1), dass\nF−1(α)≤x⟺α≤F(x)\nMithile der verallgemeinerten inversen Verteilungsfunktion können wir nun Zufallsvariablen mit beliebigen Verteilungsfunktionen konstruieren.\n\n[!info] #Theorem 2.31. Inversionsmethode\nGegeben: F:R→[0,1] eine Abbildung mit den Eigenschaften (i)-(iii) aus Satz 2.13, U∼U([0,1])\nDann hat die Zufallsvariable X:=F−1(U) die Verteiungsfunktion F.\n\n[!info]- Beweis\nP[X≤x]=P[F−1(U)≤x]=P[U≤F(x)]=F(x)◻\n#disclaimer 2.33\nWir bemerken, dass X=F−1(U) strenggenommen nur auf einer Menge mit Wahrscheinlichkeit 1 (da P[U∈(0,1)]=1) aber nicht unbedingt auf ganz Ω definiert ist. Wir beheben das Problem mittels folgender Definition\nX(ω){F−1(U(ω))U(ω)∈(0,1)0sonstDabei spielt 0 selbst keine Rolle und es kann jede beliebe reelle Zahl genommen werden.\n\nallgemeine Folgen von unabhängigen Zufallsvariablen\n\n[!info] #Theorem 2.35.\nGegeben: Folge von Funktionen F1,F2 auf R→[0,1], die die Eigenschaften (i)-(iii) aus Satz 2.13 erfüllen.\nDann existiert ein Wahrscheinlichkeitsraum (Ω,F,P) und eine Folge von Zufallsvariablen X1,X2,… auf diesem Wahrscheinlichkeitsraum, sodass\n\nfür jedes k gilt, Xk hat Verteilungsfunktion Fk und\nX1,X2,… sind unabhängig.\nDieser Satz erlaubt es uns, direkt mit Zufallsvariablen zu arbeiten, ohne den Wahrscheinlichkeitsraum (Ω,F,P) genauer zu definieren.\nZ.B. können wir für zwei Verteilungsfunktionen F und G stets annehmen, dass X und Y existieren, die unabhängig sind und Verteilungsfunktionen F und G besitzen",
		"tags": ["Def", "Theorem", "Theorem", "Theorem", "Lemma", "Def", "Theorem", "disclaimer", "Theorem", "note"]
},

{
		"title": "WS L5",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l5/",
		"content": "[!info] #Theorem 3.3. Wahrscheinlichkeit eines Punktes\nGegeben: Zufallsvariable X:Ω→R mit Verteilungsfunktion F.\nFür jedes x∈R gilt P[X=x]=F(x)−F(x−)\n\nInterpretation: Sei x∈R fixiert\n\nWenn F in einem Punkt x∈R nicht stetig ist, dann ist die &quot;Sprunghöhe&quot; F(x)−F(x−) gleich der Wahrscheinlichkeit, dass X=x\nFalls F stetig in einem Punkt x∈R ist, dann gilt P[X=x]=0\n\n[!info] #Def 3.4.\nGegeben: Ereignis A∈F\nWir sagen A tritt P-fast sicher ( #short P-f.s.) ein, falls P[A]=1 ( #english P-almost surely ( #short P-a.s.))\n\nAbkürzung falls Wahrscheinlichkeitsmass P klar ist und schreiben nur &quot;fast sicher ( #short f.s.)&quot;\n#disclaimer 3.5. Erweiterung der Notation auf allgemeine Mengen A⊂Ω (nicht unbedingt A∈F). Wir sagen, dass A fast sicher eintritt, falls ein Ereignis A′∈F existiert, sodass A′⊂A und P[A′]=1\ne.g. Wir schreiben X≤Y P-f.s., falls P[X≤Y]=1\nWenn wir mit stetigen ZV arbeiten, ist es oft restriktiv die Ungleichung X(ω)≤Y(ω) für alle ω∈Ω zu fordern. Deshalb fordern wir die Ungleichung nur auf einer Menge mit Mass 1.\n\nDiskrete Zufallsvariablen\n\n[!info] #Def 3.7. Diskrete Zufallsvariablen\nEine ZV X:Ω→R heisst diskret, falls eine endliche oder abzählbare Menge W⊂R existiert, sodass P[X∈W]=1, wenn also die Werte von X fast sicher in W liegen.\n\n#disclaimer 3.8.\ngegeben: endlicher oder abzählbarer Grundraum Ω\nDann ist jede ZV X:Ω→R diskret. In der Tat ist das Bild\n\nX(Ω)={x∈R|∃ω∈Ω:X(ω)=x}endlich oder abählbar und wir haben P[X∈W]=1 mit W=X(Ω)\n\n[!info] #Def 3.9. Gewichtsfunktion\nFür eine diskrete ZV X mit Wertebereich W(X)={x1,x2,…} und den dazugehörigen Wahrscheinlichkeiten {p1,p2,…} definieren wir die Gewichtsfunktion ( #short probability mass function ( #short pmf)) oder diskrete Dichte von X als\npX:W(X)→[0,1] mit pX(xk):=P[X=xk]=pkDie Zahlenfolge {pX(xk)}xk∈W(X) nennen wir auch Verteilung von X\n\n[!info] #Proposition 3.10.\nDie Gewichtsfunktion pX einer diskreten ZV X hat folgende Eigenschaften:\n\nFür alle xk∈W(X) gilt pX(xk)∈[0,1]\nDie Wahrscheinlichkeiten addieren sich zu 1,\n\n∑xk∈W(X)pX(xk)=P[X∈W(X)]=1\n\n[!info] #disclaimer 3.11.\nUmgekehrt, wenn wir eine Folge von Zahlen (p(x)x∈W) mit Werten in [0,1] haben, sodass ∑x∈Wp(x)=1, dann gibt es nach Satz 2.35 einen Wahrscheinlichkeitsraum (Ω,F,P) und eine ZV X mit zugehöriger Verteilung (p(x))x∈W.\nDiese Bebachtung ist in der Praxis wichtig, den sie erlaubt uns zu schreiben: &quot;Sei X eine diskrete ZV mit Verteilung (p(x))x∈W.&quot;\n\nZusammenhang Verteilungs- und Gewichtsfunktion\n\n[!info] #Theorem 3.12.\nSei X eine diskrete ZV mit Werten in W und Gewichtsfunktionen pX. Dann ist die Verteilungsfunktion von X gegeben durch\nFX(x)=P[X≤x]=∑y≤x,y∈WpX(y)\nInsbesondere ist FX also durch pX vollständig festgelegt. Mit dem gleichen Argument erhält man auch für jede messbare Teilmenge B⊆W, P[X∈B]=∑x∈BpX(x)\n#disclaimer 3.13\nGleichung (3.1) drückt die Verteilungsfunktion FX in Bezug auf pX als eine stückweise konstante Funktion aus.\nUmgekehrt ist eine ZV mit einer stückweisen konstankten Verteilungsfunktion FX diskret. W und pX sind dann gegeben durch W={ Sprungstelle von FX} und öp(x)=\"Sprunghöhe im Punkt x∈W\n\n[!info] #Theorem 3.19. Summe unabhängiger Bernoulli-ZV\nGegeben: p∈[0,1], n∈N, unabhängige X1,…,Xn∼Ber(p)\nDann gilt Sn:=X1+⋯+Xn∼Bin(n,p)\n\n[!info] #Theorem 3.23\nGegeben: unendliche Folge von unabhängigen Bernoulli-ZV X1,X2,… mit Parameter p\nDann ist T:=inf{n≥1|Xn=1} eine geometrisch verteilte ZV mit Parameter p.\n\n#disclaimer 3.24. Sei z.B. T∼Geom(p), dann ist T&gt;n, wenn die ersten n Bernoulli-Expiremente fehlschlagen. Daher gilt P[T&gt;n]=(1−p)n",
		"tags": ["Theorem", "Def", "short", "english", "short", "short", "disclaimer", "Def", "disclaimer", "Def", "short", "short", "Proposition", "disclaimer", "Theorem", "disclaimer", "Theorem", "Theorem", "disclaimer", "note"]
},

{
		"title": "WS L6",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l6/",
		"content": "[!info] #Theorem 3.25 Gedächtnislosigkeit der geometrischen Verteilung\nGegeben: T∼Geom(p), p∈(0,1)\nDann gilt für alle n≥0 und alle k≥1\nP[T≥n+k|T&gt;n]=P[T≥k]\nWenn wir also nach n Schritten immer noch auf den ersten Erfolg warten, dann ist die verbleibende Wartezeit wiederum Geom(p) verteilt.\n\n[!info]- Beweis\nP[T≥n+k|T&gt;n]=P[{T≥n+k}∩{T&gt;n}]P[T&gt;n]=P[T≥n+k]P[T&gt;n]=(1−p)n+k−1(1−p)n=(1−p)k−1=P[T≥k]\n\n[!info] #Example 3.26 negativbinomiale Verteilung\nGegeben: Zufallsvariable X\nX hat eine negativbinomaile Verteilung mit Parameter r∈N und p∈[0,1], wir schreiben X∈NBin(r,p), wenn für alle k∈{r,r+1,r+2,…} gilt:\nP[X=k]=(k−1r−1)pr(1−p)k−rDas ist eine Verallgemeinerung der geometrischen Verteilung und beschreibt die Wartezeit bis zum r -ten Erfolg in einer unendlichen Folge von Bernoulli-Experimenten. Die geometrische Verteilung erhält man als Spezialfall für r=1\n\n[!info] #Theorem 3.27\nGegeben: unendliche Folge von unabhängigen Bernoulli-Zufallsvariablen X1,X2 mit Parameter p\nDann hat\nTr=inf{n≥1|∑l=1nXl=r}eine negativbinomiale Verteilung mit Parametern r und p\n\n#disclaimer 3.28 Sind die Zufallsvariaben X1,…,Xr∼Geom(p) und unabhängig, so ist ihre Summe X=X1+⋯+Xr∼NBin(r,p)\n\n[!info] #Example 3.29 Hypergeometrische Verteilung\nEine Zufallsvariable X heisst hypgergeometrische verteilt mit Parametern n∈N und m,r∈{1,…,n}, wir schreiben X∼H(n,r,m), wenn für alle k∈{0,1,…,min(m,r)} gilt\nP[X=k]=(rk)(n−rm−k)(nm)Diese Gewichtsfunktion kommt wie folgt zustande\n#Theorem 3.30 Seien in einer Urne n Gegenstände, davon r vom Typ 1 und n−r vom Typ 2. Es werden m Gegenstände ohne Zurücklegen gezogen. Sei X nun die Anzahl der gezogenen Gegenstände vom Typ 1. Dann ist X hypergeometrisch mit den Parametern von oben verteilt.\n\n[!info]- Beweis\n\n#Example 3.31 Lotto\nIm Schweizer Lotto, wo 6 aus 42 zahlen richtig getippt werden sollen, ist die Anzahl der richtigen getippten Zahlen bei einem einzelnen Tipp hypergeometrisch verteilt mit Parametern n=42,r=6,m=6.\n\n[!info] Poisson-Verteilung\nGegeben: positive reelle Zahl λ&gt;0\nEine Zufallsvariable X heisst Poisson-verteilt mit Parameter λ, wir schreiben X∼Poisson(λ), wenn sie Werte N annimt und für alle k∈N0 gilt\nP[X=k]=λkk!e−λ\n\n[!info] #Theorem 3.34 Poisson-Approximation der Binomialverteilung\nGegeben: λ&gt;0\nFür jedes n≥1 betrachten wir n Zufallsvariablen Xn∼Bin(n,λ). Sei N∼Poisson(λ). Dann gilt für alle k∈N\nlimn→∞P[Xn=k]=P[N=k]\n#disclaimer 3.35 Diese Art von Konvergenz wird Konvergenz in Verteilung ( #english lish convergence in distribution, convergence in law)oder schwache Konvergenz ( #english weak convergence) genannt. Intuitiv besagt sie, dass Xn und N sehr ähnliche wahrscheinlichkeitstheoretische Eigenschaften für grosse n haben.\n#Example 3.36\n\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Stetige Zufallsvariablen</a>",
		"tags": ["Theorem", "Example", "Theorem", "disclaimer", "Example", "Theorem", "Example", "Theorem", "disclaimer", "english", "english", "Example", "note"]
},

{
		"title": "WS L7 Normalverteilung",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/semester4/ws/lectures/ws-l7-normalverteilung/",
		"content": "<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Normalverteilung</a>\n<a class=\"internal-link is-unresolved\" href=\"/404\" target=\"\">Erwartungswert</a>",
		"tags": [ "note"]
},

{
		"title": "home page",
		"date":"Mon Apr 15 2024 21:08:18 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "",
		"tags": [ "note","gardenEntry"]
}
]